{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 25002,
     "status": "ok",
     "timestamp": 1721528435814,
     "user": {
      "displayName": "Tianya Zhang",
      "userId": "17355879093490206686"
     },
     "user_tz": 240
    },
    "id": "7eHOmmb9DKUH",
    "outputId": "8535e118-2074-453e-8f23-3ffa6b3d18d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "# prompt: mount google drive\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1084,
     "status": "ok",
     "timestamp": 1721536095181,
     "user": {
      "displayName": "Tianya Zhang",
      "userId": "17355879093490206686"
     },
     "user_tz": 240
    },
    "id": "vvLruyWJCu_O",
    "outputId": "04b61706-1f9a-400a-ed3e-e018ab0f1d1e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive/Hierarchical LSTM for Traffic Prediction/Bigscity-LibCity\n"
     ]
    }
   ],
   "source": [
    "# prompt: change dir to /content/drive/MyDrive/Hierarchical LSTM for Traffic Prediction/Bigscity-LibCity\n",
    "\n",
    "%cd /content/drive/MyDrive/Hierarchical\\ LSTM\\ for\\ Traffic\\ Prediction/Bigscity-LibCity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zovMcW-qLVws"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "hidden_sizes = [64, 128, 256]\n",
    "num_layers = [2, 3, 4]\n",
    "natt_hops = [2, 3, 4]\n",
    "\n",
    "for hs in hidden_sizes:\n",
    "    for nl in num_layers:\n",
    "        for nh in natt_hops:\n",
    "            # Create the config dictionary with the current hyperparameters\n",
    "            config = {\n",
    "                \"input_window\": 48,\n",
    "                \"output_window\": 6,\n",
    "                \"device\": \"cuda:0\",\n",
    "                \"hidden_size\": hs,  # Use the current hs value\n",
    "                \"num_layers\": nl,   # Use the current nl value\n",
    "                \"dropout\": 0.1,\n",
    "                \"natt_hops\": nh,   # Use the current nh value\n",
    "                \"nfc\": 512,\n",
    "                \"max_up_len\": 80\n",
    "            }\n",
    "\n",
    "            # Create a filename based on the model's hyperparameters\n",
    "            filename = f\"HierAttnLstm_{config['hidden_size']}_{config['num_layers']}_{config['natt_hops']}.json\"\n",
    "\n",
    "            # Save the configuration as a JSON file\n",
    "            with open(filename, 'w') as f:\n",
    "                json.dump(config, f, indent=4)\n",
    "\n",
    "            print(f\"Configuration saved to {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21555,
     "status": "ok",
     "timestamp": 1721536121499,
     "user": {
      "displayName": "Tianya Zhang",
      "userId": "17355879093490206686"
     },
     "user_tz": 240
    },
    "id": "GuG1qXKqDP41",
    "outputId": "aab621d2-934b-41da-8f74-7aac7dc8970d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch==2.2.2 in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
      "Requirement already satisfied: torchvision==0.17.2 in /usr/local/lib/python3.10/dist-packages (0.17.2)\n",
      "Requirement already satisfied: torchaudio==2.2.2 in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2) (3.15.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2) (4.12.2)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2) (1.13.0)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2) (3.3)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2) (2023.6.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2) (2.2.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision==0.17.2) (1.25.2)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision==0.17.2) (9.4.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.2.2) (12.5.82)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.2.2) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.2.2) (1.3.0)\n",
      "Requirement already satisfied: ray in /usr/local/lib/python3.10/dist-packages (2.32.0)\n",
      "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from ray) (8.1.7)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from ray) (3.15.4)\n",
      "Requirement already satisfied: jsonschema in /usr/local/lib/python3.10/dist-packages (from ray) (4.19.2)\n",
      "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ray) (1.0.8)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from ray) (24.1)\n",
      "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /usr/local/lib/python3.10/dist-packages (from ray) (3.20.3)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from ray) (6.0.1)\n",
      "Requirement already satisfied: aiosignal in /usr/local/lib/python3.10/dist-packages (from ray) (1.3.1)\n",
      "Requirement already satisfied: frozenlist in /usr/local/lib/python3.10/dist-packages (from ray) (1.4.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from ray) (2.31.0)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray) (23.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray) (2023.12.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray) (0.19.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->ray) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->ray) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->ray) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->ray) (2024.7.4)\n",
      "Requirement already satisfied: torchdiffeq in /usr/local/lib/python3.10/dist-packages (0.2.4)\n",
      "Requirement already satisfied: torch>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from torchdiffeq) (2.2.2)\n",
      "Requirement already satisfied: scipy>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from torchdiffeq) (1.11.4)\n",
      "Requirement already satisfied: numpy<1.28.0,>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from scipy>=1.4.0->torchdiffeq) (1.25.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->torchdiffeq) (3.15.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->torchdiffeq) (4.12.2)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->torchdiffeq) (1.13.0)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->torchdiffeq) (3.3)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->torchdiffeq) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->torchdiffeq) (2023.6.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->torchdiffeq) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->torchdiffeq) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->torchdiffeq) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->torchdiffeq) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->torchdiffeq) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->torchdiffeq) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->torchdiffeq) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->torchdiffeq) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->torchdiffeq) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->torchdiffeq) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->torchdiffeq) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->torchdiffeq) (2.2.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.5.0->torchdiffeq) (12.5.82)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.5.0->torchdiffeq) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.5.0->torchdiffeq) (1.3.0)\n",
      "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (0.8.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch==2.2.2 torchvision==0.17.2 torchaudio==2.2.2\n",
    "!pip install ray\n",
    "!pip install torchdiffeq\n",
    "!pip install einops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1002,
     "status": "ok",
     "timestamp": 1721530172933,
     "user": {
      "displayName": "Tianya Zhang",
      "userId": "17355879093490206686"
     },
     "user_tz": 240
    },
    "id": "e1vEU-86hoM2",
    "outputId": "157943b2-7c5b-410d-f9be-6927816d3b09"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python run_model.py --task traffic_state_pred --model HierAttnLstm --dataset PEMS_BAY --config_file HierAttnLstm_64_2_2\n",
      "python run_model.py --task traffic_state_pred --model HierAttnLstm --dataset PEMS_BAY --config_file HierAttnLstm_64_2_3\n",
      "python run_model.py --task traffic_state_pred --model HierAttnLstm --dataset PEMS_BAY --config_file HierAttnLstm_64_2_4\n",
      "python run_model.py --task traffic_state_pred --model HierAttnLstm --dataset PEMS_BAY --config_file HierAttnLstm_64_3_2\n",
      "python run_model.py --task traffic_state_pred --model HierAttnLstm --dataset PEMS_BAY --config_file HierAttnLstm_64_3_3\n",
      "python run_model.py --task traffic_state_pred --model HierAttnLstm --dataset PEMS_BAY --config_file HierAttnLstm_64_3_4\n",
      "python run_model.py --task traffic_state_pred --model HierAttnLstm --dataset PEMS_BAY --config_file HierAttnLstm_64_4_2\n",
      "python run_model.py --task traffic_state_pred --model HierAttnLstm --dataset PEMS_BAY --config_file HierAttnLstm_64_4_3\n",
      "python run_model.py --task traffic_state_pred --model HierAttnLstm --dataset PEMS_BAY --config_file HierAttnLstm_64_4_4\n",
      "python run_model.py --task traffic_state_pred --model HierAttnLstm --dataset PEMS_BAY --config_file HierAttnLstm_128_2_2\n",
      "python run_model.py --task traffic_state_pred --model HierAttnLstm --dataset PEMS_BAY --config_file HierAttnLstm_128_2_3\n",
      "python run_model.py --task traffic_state_pred --model HierAttnLstm --dataset PEMS_BAY --config_file HierAttnLstm_128_2_4\n",
      "python run_model.py --task traffic_state_pred --model HierAttnLstm --dataset PEMS_BAY --config_file HierAttnLstm_128_3_2\n",
      "python run_model.py --task traffic_state_pred --model HierAttnLstm --dataset PEMS_BAY --config_file HierAttnLstm_128_3_3\n",
      "python run_model.py --task traffic_state_pred --model HierAttnLstm --dataset PEMS_BAY --config_file HierAttnLstm_128_3_4\n",
      "python run_model.py --task traffic_state_pred --model HierAttnLstm --dataset PEMS_BAY --config_file HierAttnLstm_128_4_2\n",
      "python run_model.py --task traffic_state_pred --model HierAttnLstm --dataset PEMS_BAY --config_file HierAttnLstm_128_4_3\n",
      "python run_model.py --task traffic_state_pred --model HierAttnLstm --dataset PEMS_BAY --config_file HierAttnLstm_128_4_4\n",
      "python run_model.py --task traffic_state_pred --model HierAttnLstm --dataset PEMS_BAY --config_file HierAttnLstm_256_2_2\n",
      "python run_model.py --task traffic_state_pred --model HierAttnLstm --dataset PEMS_BAY --config_file HierAttnLstm_256_2_3\n",
      "python run_model.py --task traffic_state_pred --model HierAttnLstm --dataset PEMS_BAY --config_file HierAttnLstm_256_2_4\n",
      "python run_model.py --task traffic_state_pred --model HierAttnLstm --dataset PEMS_BAY --config_file HierAttnLstm_256_3_2\n",
      "python run_model.py --task traffic_state_pred --model HierAttnLstm --dataset PEMS_BAY --config_file HierAttnLstm_256_3_3\n",
      "python run_model.py --task traffic_state_pred --model HierAttnLstm --dataset PEMS_BAY --config_file HierAttnLstm_256_3_4\n",
      "python run_model.py --task traffic_state_pred --model HierAttnLstm --dataset PEMS_BAY --config_file HierAttnLstm_256_4_2\n",
      "python run_model.py --task traffic_state_pred --model HierAttnLstm --dataset PEMS_BAY --config_file HierAttnLstm_256_4_3\n",
      "python run_model.py --task traffic_state_pred --model HierAttnLstm --dataset PEMS_BAY --config_file HierAttnLstm_256_4_4\n"
     ]
    }
   ],
   "source": [
    "hidden_sizes = [64, 128, 256]\n",
    "num_layers = [2, 3, 4]\n",
    "natt_hops = [2, 3, 4]\n",
    "\n",
    "for hs in hidden_sizes:\n",
    "    for nl in num_layers:\n",
    "        for nh in natt_hops:\n",
    "            cmd = f\"python run_model.py --task traffic_state_pred --model HierAttnLstm --dataset PEMS_BAY --config_file HierAttnLstm_{hs}_{nl}_{nh}\"\n",
    "            print(cmd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "W25dnSfpiR9e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-21 04:29:28,979 - INFO - Log directory: ./libcity/log\n",
      "2024-07-21 04:29:28,980 - INFO - Begin pipeline, task=traffic_state_pred, model_name=HierAttnLstm, dataset_name=PEMS_BAY, exp_id=47171\n",
      "2024-07-21 04:29:28,981 - INFO - {'task': 'traffic_state_pred', 'model': 'HierAttnLstm', 'dataset': 'PEMS_BAY', 'saved_model': True, 'train': True, 'seed': 0, 'input_window': 48, 'output_window': 6, 'device': device(type='cuda', index=0), 'hidden_size': 64, 'num_layers': 2, 'dropout': 0.1, 'natt_hops': 2, 'nfc': 512, 'max_up_len': 80, 'dataset_class': 'TrafficStatePointDataset', 'executor': 'TrafficStateExecutor', 'evaluator': 'TrafficStateEvaluator', 'batch_size': 32, 'cache_dataset': True, 'num_workers': 0, 'pad_with_last_sample': True, 'train_rate': 0.7, 'eval_rate': 0.1, 'scaler': 'minmax01', 'load_external': False, 'normal_external': False, 'ext_scaler': 'none', 'add_time_in_day': False, 'add_day_in_week': False, 'robustness_test': False, 'noise_type': 'gaussian', 'disturb_rate': 0.5, 'noise_mean': [5], 'noise_SD': [10], 'gpu': True, 'gpu_id': 0, 'max_epoch': 100, 'train_loss': 'none', 'epoch': 0, 'learner': 'adam', 'learning_rate': 0.01, 'weight_decay': 0, 'lr_epsilon': 1e-08, 'lr_beta1': 0.9, 'lr_beta2': 0.999, 'lr_alpha': 0.99, 'lr_momentum': 0, 'lr_decay': False, 'lr_scheduler': 'multisteplr', 'lr_decay_ratio': 0.1, 'steps': [5, 20, 40, 70], 'step_size': 10, 'lr_T_max': 30, 'lr_eta_min': 0, 'lr_patience': 10, 'lr_threshold': 0.0001, 'clip_grad_norm': False, 'max_grad_norm': 1.0, 'use_early_stop': True, 'patience': 10, 'log_level': 'INFO', 'log_every': 1, 'load_best_epoch': True, 'hyper_tune': False, 'metrics': ['MAE', 'MAPE', 'MSE', 'RMSE', 'masked_MAE', 'masked_MAPE', 'masked_MSE', 'masked_RMSE', 'R2', 'EVAR'], 'evaluator_mode': 'single', 'save_mode': ['csv'], 'geo': {'including_types': ['Point'], 'Point': {}}, 'rel': {'including_types': ['geo'], 'geo': {'cost': 'num'}}, 'dyna': {'including_types': ['state'], 'state': {'entity_id': 'geo_id', 'traffic_speed': 'num'}}, 'data_col': ['traffic_speed'], 'weight_col': 'cost', 'data_files': ['PEMS_BAY'], 'geo_file': 'PEMS_BAY', 'rel_file': 'PEMS_BAY', 'output_dim': 1, 'time_intervals': 300, 'init_weight_inf_or_zero': 'inf', 'set_weight_link_or_dist': 'dist', 'calculate_weight_adj': True, 'weight_adj_epsilon': 0.1, 'exp_id': 47171}\n",
      "self.scaler_type  minmax01\n",
      "2024-07-21 04:29:29,791 - INFO - Loaded file PEMS_BAY.geo, num_nodes=325\n",
      "2024-07-21 04:29:30,604 - INFO - set_weight_link_or_dist: dist\n",
      "2024-07-21 04:29:30,604 - INFO - init_weight_inf_or_zero: inf\n",
      "2024-07-21 04:29:30,618 - INFO - Loaded file PEMS_BAY.rel, shape=(325, 325)\n",
      "2024-07-21 04:29:30,618 - INFO - Start Calculate the weight by Gauss kernel!\n",
      "2024-07-21 04:29:30,622 - INFO - Loading file PEMS_BAY.dyna\n",
      "2024-07-21 04:29:48,960 - INFO - Loaded file PEMS_BAY.dyna, shape=(52116, 325, 1)\n",
      "2024-07-21 04:29:57,952 - INFO - Dataset created\n",
      "2024-07-21 04:29:57,952 - INFO - x shape: (52063, 48, 325, 1), y shape: (52063, 6, 325, 1)\n",
      "2024-07-21 04:29:57,967 - INFO - train\tx: (36444, 48, 325, 1), y: (36444, 6, 325, 1)\n",
      "2024-07-21 04:29:57,967 - INFO - eval\tx: (5206, 48, 325, 1), y: (5206, 6, 325, 1)\n",
      "2024-07-21 04:29:57,967 - INFO - test\tx: (10413, 48, 325, 1), y: (10413, 6, 325, 1)\n",
      "2024-07-21 04:38:04,377 - INFO - Saved at ./libcity/cache/dataset_cache/point_based_PEMS_BAY_48_6_0.7_0.1_minmax01_32_False_False_False_True.npz\n",
      "2024-07-21 04:38:05,216 - INFO - MinMax01Scaler max: 85.1, min: 0.0\n",
      "2024-07-21 04:38:05,216 - INFO - NoneScaler\n",
      "2024-07-21 04:38:10.949159: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-07-21 04:38:10.991280: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-21 04:38:10.991328: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-21 04:38:10.992763: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-07-21 04:38:10.999391: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-21 04:38:12.217923: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-07-21 04:38:13,464 - INFO - HierAttnLstm(\n",
      "  (lstm_cells): ModuleList(\n",
      "    (0): LSTMCell(325, 64)\n",
      "    (1): LSTMCell(64, 64)\n",
      "  )\n",
      "  (hidden_state_pooling): ModuleList(\n",
      "    (0): SelfAttentionPooling(\n",
      "      (W): Linear(in_features=64, out_features=1, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (cell_state_pooling): ModuleList(\n",
      "    (0): SelfAttentionPooling(\n",
      "      (W): Linear(in_features=64, out_features=1, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (self_attention): SelfAttention(\n",
      "    (ut_dense): Sequential(\n",
      "      (0): Linear(in_features=64, out_features=64, bias=True)\n",
      "      (1): Tanh()\n",
      "    )\n",
      "    (et_dense): Linear(in_features=64, out_features=2, bias=True)\n",
      "    (softmax): Softmax(dim=-1)\n",
      "  )\n",
      "  (fc_layer): Sequential(\n",
      "    (0): Linear(in_features=128, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=325, bias=True)\n",
      "  )\n",
      ")\n",
      "2024-07-21 04:38:13,465 - INFO - lstm_cells.0.weight_ih\ttorch.Size([256, 325])\tcuda:0\tTrue\n",
      "2024-07-21 04:38:13,465 - INFO - lstm_cells.0.weight_hh\ttorch.Size([256, 64])\tcuda:0\tTrue\n",
      "2024-07-21 04:38:13,466 - INFO - lstm_cells.0.bias_ih\ttorch.Size([256])\tcuda:0\tTrue\n",
      "2024-07-21 04:38:13,466 - INFO - lstm_cells.0.bias_hh\ttorch.Size([256])\tcuda:0\tTrue\n",
      "2024-07-21 04:38:13,466 - INFO - lstm_cells.1.weight_ih\ttorch.Size([256, 64])\tcuda:0\tTrue\n",
      "2024-07-21 04:38:13,466 - INFO - lstm_cells.1.weight_hh\ttorch.Size([256, 64])\tcuda:0\tTrue\n",
      "2024-07-21 04:38:13,466 - INFO - lstm_cells.1.bias_ih\ttorch.Size([256])\tcuda:0\tTrue\n",
      "2024-07-21 04:38:13,466 - INFO - lstm_cells.1.bias_hh\ttorch.Size([256])\tcuda:0\tTrue\n",
      "2024-07-21 04:38:13,467 - INFO - hidden_state_pooling.0.W.weight\ttorch.Size([1, 64])\tcuda:0\tTrue\n",
      "2024-07-21 04:38:13,467 - INFO - hidden_state_pooling.0.W.bias\ttorch.Size([1])\tcuda:0\tTrue\n",
      "2024-07-21 04:38:13,467 - INFO - cell_state_pooling.0.W.weight\ttorch.Size([1, 64])\tcuda:0\tTrue\n",
      "2024-07-21 04:38:13,467 - INFO - cell_state_pooling.0.W.bias\ttorch.Size([1])\tcuda:0\tTrue\n",
      "2024-07-21 04:38:13,467 - INFO - self_attention.ut_dense.0.weight\ttorch.Size([64, 64])\tcuda:0\tTrue\n",
      "2024-07-21 04:38:13,467 - INFO - self_attention.ut_dense.0.bias\ttorch.Size([64])\tcuda:0\tTrue\n",
      "2024-07-21 04:38:13,467 - INFO - self_attention.et_dense.weight\ttorch.Size([2, 64])\tcuda:0\tTrue\n",
      "2024-07-21 04:38:13,468 - INFO - self_attention.et_dense.bias\ttorch.Size([2])\tcuda:0\tTrue\n",
      "2024-07-21 04:38:13,468 - INFO - fc_layer.0.weight\ttorch.Size([512, 128])\tcuda:0\tTrue\n",
      "2024-07-21 04:38:13,468 - INFO - fc_layer.0.bias\ttorch.Size([512])\tcuda:0\tTrue\n",
      "2024-07-21 04:38:13,468 - INFO - fc_layer.2.weight\ttorch.Size([325, 512])\tcuda:0\tTrue\n",
      "2024-07-21 04:38:13,468 - INFO - fc_layer.2.bias\ttorch.Size([325])\tcuda:0\tTrue\n",
      "2024-07-21 04:38:13,468 - INFO - Total parameter numbers: 370569\n",
      "2024-07-21 04:38:13,469 - INFO - You select `adam` optimizer.\n",
      "2024-07-21 04:38:13,469 - WARNING - Received none train loss func and will use the loss func defined in the model.\n",
      "2024-07-21 04:38:13,470 - INFO - Start training ...\n",
      "2024-07-21 04:38:13,470 - INFO - num_batches:1139\n",
      "2024-07-21 04:41:55,148 - INFO - epoch complete!\n",
      "2024-07-21 04:41:55,149 - INFO - evaluating now!\n",
      "2024-07-21 04:42:04,204 - INFO - Epoch [0/100] train_loss: 4.9602, val_loss: 3.9873, lr: 0.010000, 230.73s\n",
      "2024-07-21 04:42:04,230 - INFO - Saved model at 0\n",
      "2024-07-21 04:42:04,231 - INFO - Val loss decrease from inf to 3.9873, saving to ./libcity/cache/47171/model_cache/HierAttnLstm_PEMS_BAY_epoch0.tar\n",
      "2024-07-21 04:45:45,452 - INFO - epoch complete!\n",
      "2024-07-21 04:45:45,453 - INFO - evaluating now!\n",
      "2024-07-21 04:45:54,543 - INFO - Epoch [1/100] train_loss: 3.2426, val_loss: 3.2901, lr: 0.010000, 230.31s\n",
      "2024-07-21 04:45:54,571 - INFO - Saved model at 1\n",
      "2024-07-21 04:45:54,571 - INFO - Val loss decrease from 3.9873 to 3.2901, saving to ./libcity/cache/47171/model_cache/HierAttnLstm_PEMS_BAY_epoch1.tar\n",
      "2024-07-21 04:49:34,461 - INFO - epoch complete!\n",
      "2024-07-21 04:49:34,461 - INFO - evaluating now!\n",
      "2024-07-21 04:49:43,432 - INFO - Epoch [2/100] train_loss: 3.0549, val_loss: 3.3386, lr: 0.010000, 228.86s\n",
      "2024-07-21 04:53:23,744 - INFO - epoch complete!\n",
      "2024-07-21 04:53:23,744 - INFO - evaluating now!\n",
      "2024-07-21 04:53:32,657 - INFO - Epoch [3/100] train_loss: 2.9503, val_loss: 3.3150, lr: 0.010000, 229.22s\n",
      "2024-07-21 04:57:12,708 - INFO - epoch complete!\n",
      "2024-07-21 04:57:12,709 - INFO - evaluating now!\n",
      "2024-07-21 04:57:21,767 - INFO - Epoch [4/100] train_loss: 2.8508, val_loss: 3.0863, lr: 0.010000, 229.11s\n",
      "2024-07-21 04:57:21,794 - INFO - Saved model at 4\n",
      "2024-07-21 04:57:21,794 - INFO - Val loss decrease from 3.2901 to 3.0863, saving to ./libcity/cache/47171/model_cache/HierAttnLstm_PEMS_BAY_epoch4.tar\n",
      "2024-07-21 05:01:00,162 - INFO - epoch complete!\n",
      "2024-07-21 05:01:00,163 - INFO - evaluating now!\n",
      "2024-07-21 05:01:09,143 - INFO - Epoch [5/100] train_loss: 2.7579, val_loss: 2.8537, lr: 0.010000, 227.35s\n",
      "2024-07-21 05:01:09,171 - INFO - Saved model at 5\n",
      "2024-07-21 05:01:09,171 - INFO - Val loss decrease from 3.0863 to 2.8537, saving to ./libcity/cache/47171/model_cache/HierAttnLstm_PEMS_BAY_epoch5.tar\n",
      "2024-07-21 05:04:48,422 - INFO - epoch complete!\n",
      "2024-07-21 05:04:48,422 - INFO - evaluating now!\n",
      "2024-07-21 05:04:57,386 - INFO - Epoch [6/100] train_loss: 2.6794, val_loss: 2.7409, lr: 0.010000, 228.21s\n",
      "2024-07-21 05:04:57,412 - INFO - Saved model at 6\n",
      "2024-07-21 05:04:57,413 - INFO - Val loss decrease from 2.8537 to 2.7409, saving to ./libcity/cache/47171/model_cache/HierAttnLstm_PEMS_BAY_epoch6.tar\n",
      "2024-07-21 05:08:37,629 - INFO - epoch complete!\n",
      "2024-07-21 05:08:37,630 - INFO - evaluating now!\n",
      "2024-07-21 05:08:46,787 - INFO - Epoch [7/100] train_loss: 2.6176, val_loss: 2.7181, lr: 0.010000, 229.37s\n",
      "2024-07-21 05:08:46,814 - INFO - Saved model at 7\n",
      "2024-07-21 05:08:46,814 - INFO - Val loss decrease from 2.7409 to 2.7181, saving to ./libcity/cache/47171/model_cache/HierAttnLstm_PEMS_BAY_epoch7.tar\n",
      "2024-07-21 05:12:26,571 - INFO - epoch complete!\n",
      "2024-07-21 05:12:26,571 - INFO - evaluating now!\n",
      "2024-07-21 05:12:35,737 - INFO - Epoch [8/100] train_loss: 2.5422, val_loss: 2.6741, lr: 0.010000, 228.92s\n",
      "2024-07-21 05:12:35,766 - INFO - Saved model at 8\n",
      "2024-07-21 05:12:35,766 - INFO - Val loss decrease from 2.7181 to 2.6741, saving to ./libcity/cache/47171/model_cache/HierAttnLstm_PEMS_BAY_epoch8.tar\n",
      "2024-07-21 05:16:15,239 - INFO - epoch complete!\n",
      "2024-07-21 05:16:15,240 - INFO - evaluating now!\n",
      "2024-07-21 05:16:24,283 - INFO - Epoch [9/100] train_loss: 2.7712, val_loss: 2.6270, lr: 0.010000, 228.52s\n",
      "2024-07-21 05:16:24,310 - INFO - Saved model at 9\n",
      "2024-07-21 05:16:24,311 - INFO - Val loss decrease from 2.6741 to 2.6270, saving to ./libcity/cache/47171/model_cache/HierAttnLstm_PEMS_BAY_epoch9.tar\n",
      "2024-07-21 05:20:02,877 - INFO - epoch complete!\n",
      "2024-07-21 05:20:02,878 - INFO - evaluating now!\n",
      "2024-07-21 05:20:11,873 - INFO - Epoch [10/100] train_loss: 2.5392, val_loss: 2.6271, lr: 0.010000, 227.56s\n",
      "2024-07-21 05:23:51,861 - INFO - epoch complete!\n",
      "2024-07-21 05:23:51,862 - INFO - evaluating now!\n",
      "2024-07-21 05:24:00,865 - INFO - Epoch [11/100] train_loss: 2.5011, val_loss: 2.6786, lr: 0.010000, 228.99s\n",
      "2024-07-21 05:27:39,203 - INFO - epoch complete!\n",
      "2024-07-21 05:27:39,203 - INFO - evaluating now!\n",
      "2024-07-21 05:27:48,221 - INFO - Epoch [12/100] train_loss: 2.4905, val_loss: 2.6718, lr: 0.010000, 227.36s\n",
      "2024-07-21 05:31:26,899 - INFO - epoch complete!\n",
      "2024-07-21 05:31:26,900 - INFO - evaluating now!\n",
      "2024-07-21 05:31:35,870 - INFO - Epoch [13/100] train_loss: 2.5625, val_loss: 2.6777, lr: 0.010000, 227.65s\n",
      "2024-07-21 05:35:15,366 - INFO - epoch complete!\n",
      "2024-07-21 05:35:15,366 - INFO - evaluating now!\n",
      "2024-07-21 05:35:24,339 - INFO - Epoch [14/100] train_loss: 2.4978, val_loss: 2.6117, lr: 0.010000, 228.47s\n",
      "2024-07-21 05:35:24,366 - INFO - Saved model at 14\n",
      "2024-07-21 05:35:24,366 - INFO - Val loss decrease from 2.6270 to 2.6117, saving to ./libcity/cache/47171/model_cache/HierAttnLstm_PEMS_BAY_epoch14.tar\n",
      "2024-07-21 05:39:03,133 - INFO - epoch complete!\n",
      "2024-07-21 05:39:03,133 - INFO - evaluating now!\n",
      "2024-07-21 05:39:12,124 - INFO - Epoch [15/100] train_loss: 2.7396, val_loss: 2.7866, lr: 0.010000, 227.76s\n",
      "2024-07-21 05:42:50,989 - INFO - epoch complete!\n",
      "2024-07-21 05:42:50,989 - INFO - evaluating now!\n",
      "2024-07-21 05:42:59,958 - INFO - Epoch [16/100] train_loss: 2.5726, val_loss: 2.7497, lr: 0.010000, 227.83s\n",
      "2024-07-21 05:46:38,187 - INFO - epoch complete!\n",
      "2024-07-21 05:46:38,187 - INFO - evaluating now!\n",
      "2024-07-21 05:46:47,039 - INFO - Epoch [17/100] train_loss: 2.5731, val_loss: 2.7958, lr: 0.010000, 227.08s\n",
      "2024-07-21 05:50:23,108 - INFO - epoch complete!\n",
      "2024-07-21 05:50:23,109 - INFO - evaluating now!\n",
      "2024-07-21 05:50:31,858 - INFO - Epoch [18/100] train_loss: 2.5481, val_loss: 2.7353, lr: 0.010000, 224.82s\n",
      "2024-07-21 05:54:07,198 - INFO - epoch complete!\n",
      "2024-07-21 05:54:07,199 - INFO - evaluating now!\n",
      "2024-07-21 05:54:15,933 - INFO - Epoch [19/100] train_loss: 2.5395, val_loss: 2.7877, lr: 0.010000, 224.07s\n",
      "2024-07-21 05:57:50,777 - INFO - epoch complete!\n",
      "2024-07-21 05:57:50,777 - INFO - evaluating now!\n",
      "2024-07-21 05:57:59,591 - INFO - Epoch [20/100] train_loss: 2.5314, val_loss: 2.7322, lr: 0.010000, 223.66s\n",
      "2024-07-21 06:01:34,740 - INFO - epoch complete!\n",
      "2024-07-21 06:01:34,741 - INFO - evaluating now!\n",
      "2024-07-21 06:01:43,435 - INFO - Epoch [21/100] train_loss: 2.5367, val_loss: 2.8965, lr: 0.010000, 223.84s\n",
      "2024-07-21 06:05:18,024 - INFO - epoch complete!\n",
      "2024-07-21 06:05:18,025 - INFO - evaluating now!\n",
      "2024-07-21 06:05:26,872 - INFO - Epoch [22/100] train_loss: 2.5189, val_loss: 2.7949, lr: 0.010000, 223.44s\n",
      "2024-07-21 06:09:01,822 - INFO - epoch complete!\n",
      "2024-07-21 06:09:01,822 - INFO - evaluating now!\n",
      "2024-07-21 06:09:10,622 - INFO - Epoch [23/100] train_loss: 2.5206, val_loss: 2.7500, lr: 0.010000, 223.75s\n",
      "2024-07-21 06:12:44,837 - INFO - epoch complete!\n",
      "2024-07-21 06:12:44,838 - INFO - evaluating now!\n",
      "2024-07-21 06:12:53,656 - INFO - Epoch [24/100] train_loss: 2.5147, val_loss: 2.7148, lr: 0.010000, 223.03s\n",
      "2024-07-21 06:12:53,656 - WARNING - Early stopping at epoch: 24\n",
      "2024-07-21 06:12:53,656 - INFO - Trained totally 25 epochs, average train time is 218.251s, average eval time is 8.945s\n",
      "2024-07-21 06:12:53,672 - INFO - Loaded model at 14\n",
      "2024-07-21 06:12:53,672 - INFO - Saved model at ./libcity/cache/47171/model_cache/HierAttnLstm_PEMS_BAY.m\n",
      "2024-07-21 06:12:53,698 - INFO - Start evaluating ...\n",
      "2024-07-21 06:13:20,281 - INFO - Note that you select the single mode to evaluate!\n",
      "2024-07-21 06:13:20,290 - INFO - Evaluate result is saved at ./libcity/cache/47171/evaluate_cache/2024_07_21_06_13_20_HierAttnLstm_PEMS_BAY.csv\n",
      "2024-07-21 06:13:20,305 - INFO - \n",
      "        MAE  MAPE        MSE      RMSE  ...  masked_MSE  masked_RMSE        R2      EVAR\n",
      "1  2.602443   inf  28.395834  5.328774  ...   28.112505     5.302123  0.695569  0.698563\n",
      "2  2.602304   inf  28.393969  5.328599  ...   28.110640     5.301947  0.695584  0.698578\n",
      "3  2.628031   inf  29.175335  5.401420  ...   28.892033     5.375131  0.687204  0.690981\n",
      "4  2.634408   inf  29.365816  5.419024  ...   29.082544     5.392823  0.685159  0.689104\n",
      "5  2.655766   inf  30.059736  5.482676  ...   29.776541     5.456789  0.677716  0.682207\n",
      "6  2.669336   inf  30.503792  5.523024  ...   30.220644     5.497331  0.672952  0.677777\n",
      "\n",
      "[6 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "!python run_model.py --task traffic_state_pred --model HierAttnLstm --dataset PEMS_BAY --config_file HierAttnLstm_64_2_2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "INI6nb4CFID1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-21 06:13:24,750 - INFO - Log directory: ./libcity/log\n",
      "2024-07-21 06:13:24,753 - INFO - Begin pipeline, task=traffic_state_pred, model_name=HierAttnLstm, dataset_name=PEMS_BAY, exp_id=10961\n",
      "2024-07-21 06:13:24,754 - INFO - {'task': 'traffic_state_pred', 'model': 'HierAttnLstm', 'dataset': 'PEMS_BAY', 'saved_model': True, 'train': True, 'seed': 0, 'input_window': 48, 'output_window': 6, 'device': device(type='cuda', index=0), 'hidden_size': 64, 'num_layers': 2, 'dropout': 0.1, 'natt_hops': 3, 'nfc': 512, 'max_up_len': 80, 'dataset_class': 'TrafficStatePointDataset', 'executor': 'TrafficStateExecutor', 'evaluator': 'TrafficStateEvaluator', 'batch_size': 32, 'cache_dataset': True, 'num_workers': 0, 'pad_with_last_sample': True, 'train_rate': 0.7, 'eval_rate': 0.1, 'scaler': 'minmax01', 'load_external': False, 'normal_external': False, 'ext_scaler': 'none', 'add_time_in_day': False, 'add_day_in_week': False, 'robustness_test': False, 'noise_type': 'gaussian', 'disturb_rate': 0.5, 'noise_mean': [5], 'noise_SD': [10], 'gpu': True, 'gpu_id': 0, 'max_epoch': 100, 'train_loss': 'none', 'epoch': 0, 'learner': 'adam', 'learning_rate': 0.01, 'weight_decay': 0, 'lr_epsilon': 1e-08, 'lr_beta1': 0.9, 'lr_beta2': 0.999, 'lr_alpha': 0.99, 'lr_momentum': 0, 'lr_decay': False, 'lr_scheduler': 'multisteplr', 'lr_decay_ratio': 0.1, 'steps': [5, 20, 40, 70], 'step_size': 10, 'lr_T_max': 30, 'lr_eta_min': 0, 'lr_patience': 10, 'lr_threshold': 0.0001, 'clip_grad_norm': False, 'max_grad_norm': 1.0, 'use_early_stop': True, 'patience': 10, 'log_level': 'INFO', 'log_every': 1, 'load_best_epoch': True, 'hyper_tune': False, 'metrics': ['MAE', 'MAPE', 'MSE', 'RMSE', 'masked_MAE', 'masked_MAPE', 'masked_MSE', 'masked_RMSE', 'R2', 'EVAR'], 'evaluator_mode': 'single', 'save_mode': ['csv'], 'geo': {'including_types': ['Point'], 'Point': {}}, 'rel': {'including_types': ['geo'], 'geo': {'cost': 'num'}}, 'dyna': {'including_types': ['state'], 'state': {'entity_id': 'geo_id', 'traffic_speed': 'num'}}, 'data_col': ['traffic_speed'], 'weight_col': 'cost', 'data_files': ['PEMS_BAY'], 'geo_file': 'PEMS_BAY', 'rel_file': 'PEMS_BAY', 'output_dim': 1, 'time_intervals': 300, 'init_weight_inf_or_zero': 'inf', 'set_weight_link_or_dist': 'dist', 'calculate_weight_adj': True, 'weight_adj_epsilon': 0.1, 'exp_id': 10961}\n",
      "self.scaler_type  minmax01\n",
      "2024-07-21 06:13:24,786 - INFO - Loaded file PEMS_BAY.geo, num_nodes=325\n",
      "2024-07-21 06:13:24,796 - INFO - set_weight_link_or_dist: dist\n",
      "2024-07-21 06:13:24,796 - INFO - init_weight_inf_or_zero: inf\n",
      "2024-07-21 06:13:24,810 - INFO - Loaded file PEMS_BAY.rel, shape=(325, 325)\n",
      "2024-07-21 06:13:24,810 - INFO - Start Calculate the weight by Gauss kernel!\n",
      "2024-07-21 06:13:24,813 - INFO - Loading ./libcity/cache/dataset_cache/point_based_PEMS_BAY_48_6_0.7_0.1_minmax01_32_False_False_False_True.npz\n",
      "2024-07-21 06:13:54,159 - INFO - train\tx: (36444, 48, 325, 1), y: (36444, 6, 325, 1)\n",
      "2024-07-21 06:13:54,160 - INFO - eval\tx: (5206, 48, 325, 1), y: (5206, 6, 325, 1)\n",
      "2024-07-21 06:13:54,160 - INFO - test\tx: (10413, 48, 325, 1), y: (10413, 6, 325, 1)\n",
      "2024-07-21 06:13:54,988 - INFO - MinMax01Scaler max: 85.1, min: 0.0\n",
      "2024-07-21 06:13:54,988 - INFO - NoneScaler\n",
      "2024-07-21 06:14:00.750845: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-07-21 06:14:00.801656: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-21 06:14:00.801710: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-21 06:14:00.803072: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-07-21 06:14:00.811202: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-21 06:14:02.019733: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-07-21 06:14:03,272 - INFO - HierAttnLstm(\n",
      "  (lstm_cells): ModuleList(\n",
      "    (0): LSTMCell(325, 64)\n",
      "    (1): LSTMCell(64, 64)\n",
      "  )\n",
      "  (hidden_state_pooling): ModuleList(\n",
      "    (0): SelfAttentionPooling(\n",
      "      (W): Linear(in_features=64, out_features=1, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (cell_state_pooling): ModuleList(\n",
      "    (0): SelfAttentionPooling(\n",
      "      (W): Linear(in_features=64, out_features=1, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (self_attention): SelfAttention(\n",
      "    (ut_dense): Sequential(\n",
      "      (0): Linear(in_features=64, out_features=64, bias=True)\n",
      "      (1): Tanh()\n",
      "    )\n",
      "    (et_dense): Linear(in_features=64, out_features=3, bias=True)\n",
      "    (softmax): Softmax(dim=-1)\n",
      "  )\n",
      "  (fc_layer): Sequential(\n",
      "    (0): Linear(in_features=192, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=325, bias=True)\n",
      "  )\n",
      ")\n",
      "2024-07-21 06:14:03,273 - INFO - lstm_cells.0.weight_ih\ttorch.Size([256, 325])\tcuda:0\tTrue\n",
      "2024-07-21 06:14:03,273 - INFO - lstm_cells.0.weight_hh\ttorch.Size([256, 64])\tcuda:0\tTrue\n",
      "2024-07-21 06:14:03,273 - INFO - lstm_cells.0.bias_ih\ttorch.Size([256])\tcuda:0\tTrue\n",
      "2024-07-21 06:14:03,273 - INFO - lstm_cells.0.bias_hh\ttorch.Size([256])\tcuda:0\tTrue\n",
      "2024-07-21 06:14:03,273 - INFO - lstm_cells.1.weight_ih\ttorch.Size([256, 64])\tcuda:0\tTrue\n",
      "2024-07-21 06:14:03,273 - INFO - lstm_cells.1.weight_hh\ttorch.Size([256, 64])\tcuda:0\tTrue\n",
      "2024-07-21 06:14:03,273 - INFO - lstm_cells.1.bias_ih\ttorch.Size([256])\tcuda:0\tTrue\n",
      "2024-07-21 06:14:03,273 - INFO - lstm_cells.1.bias_hh\ttorch.Size([256])\tcuda:0\tTrue\n",
      "2024-07-21 06:14:03,274 - INFO - hidden_state_pooling.0.W.weight\ttorch.Size([1, 64])\tcuda:0\tTrue\n",
      "2024-07-21 06:14:03,274 - INFO - hidden_state_pooling.0.W.bias\ttorch.Size([1])\tcuda:0\tTrue\n",
      "2024-07-21 06:14:03,274 - INFO - cell_state_pooling.0.W.weight\ttorch.Size([1, 64])\tcuda:0\tTrue\n",
      "2024-07-21 06:14:03,274 - INFO - cell_state_pooling.0.W.bias\ttorch.Size([1])\tcuda:0\tTrue\n",
      "2024-07-21 06:14:03,274 - INFO - self_attention.ut_dense.0.weight\ttorch.Size([64, 64])\tcuda:0\tTrue\n",
      "2024-07-21 06:14:03,274 - INFO - self_attention.ut_dense.0.bias\ttorch.Size([64])\tcuda:0\tTrue\n",
      "2024-07-21 06:14:03,274 - INFO - self_attention.et_dense.weight\ttorch.Size([3, 64])\tcuda:0\tTrue\n",
      "2024-07-21 06:14:03,274 - INFO - self_attention.et_dense.bias\ttorch.Size([3])\tcuda:0\tTrue\n",
      "2024-07-21 06:14:03,274 - INFO - fc_layer.0.weight\ttorch.Size([512, 192])\tcuda:0\tTrue\n",
      "2024-07-21 06:14:03,274 - INFO - fc_layer.0.bias\ttorch.Size([512])\tcuda:0\tTrue\n",
      "2024-07-21 06:14:03,275 - INFO - fc_layer.2.weight\ttorch.Size([325, 512])\tcuda:0\tTrue\n",
      "2024-07-21 06:14:03,275 - INFO - fc_layer.2.bias\ttorch.Size([325])\tcuda:0\tTrue\n",
      "2024-07-21 06:14:03,275 - INFO - Total parameter numbers: 403402\n",
      "2024-07-21 06:14:03,275 - INFO - You select `adam` optimizer.\n",
      "2024-07-21 06:14:03,276 - WARNING - Received none train loss func and will use the loss func defined in the model.\n",
      "2024-07-21 06:14:03,276 - INFO - Start training ...\n",
      "2024-07-21 06:14:03,276 - INFO - num_batches:1139\n",
      "2024-07-21 06:17:43,870 - INFO - epoch complete!\n",
      "2024-07-21 06:17:43,871 - INFO - evaluating now!\n",
      "2024-07-21 06:17:52,966 - INFO - Epoch [0/100] train_loss: 4.5321, val_loss: 3.6423, lr: 0.010000, 229.69s\n",
      "2024-07-21 06:17:52,993 - INFO - Saved model at 0\n",
      "2024-07-21 06:17:52,994 - INFO - Val loss decrease from inf to 3.6423, saving to ./libcity/cache/10961/model_cache/HierAttnLstm_PEMS_BAY_epoch0.tar\n",
      "2024-07-21 06:21:32,991 - INFO - epoch complete!\n",
      "2024-07-21 06:21:32,992 - INFO - evaluating now!\n",
      "2024-07-21 06:21:42,082 - INFO - Epoch [1/100] train_loss: 2.9928, val_loss: 2.7517, lr: 0.010000, 229.09s\n",
      "2024-07-21 06:21:42,111 - INFO - Saved model at 1\n",
      "2024-07-21 06:21:42,111 - INFO - Val loss decrease from 3.6423 to 2.7517, saving to ./libcity/cache/10961/model_cache/HierAttnLstm_PEMS_BAY_epoch1.tar\n",
      "2024-07-21 06:25:22,955 - INFO - epoch complete!\n",
      "2024-07-21 06:25:22,956 - INFO - evaluating now!\n",
      "2024-07-21 06:25:32,097 - INFO - Epoch [2/100] train_loss: 2.6295, val_loss: 2.6804, lr: 0.010000, 229.98s\n",
      "2024-07-21 06:25:32,138 - INFO - Saved model at 2\n",
      "2024-07-21 06:25:32,138 - INFO - Val loss decrease from 2.7517 to 2.6804, saving to ./libcity/cache/10961/model_cache/HierAttnLstm_PEMS_BAY_epoch2.tar\n",
      "2024-07-21 06:29:13,718 - INFO - epoch complete!\n",
      "2024-07-21 06:29:13,719 - INFO - evaluating now!\n",
      "2024-07-21 06:29:23,076 - INFO - Epoch [3/100] train_loss: 2.5163, val_loss: 2.8172, lr: 0.010000, 230.94s\n",
      "2024-07-21 06:33:06,414 - INFO - epoch complete!\n",
      "2024-07-21 06:33:06,414 - INFO - evaluating now!\n",
      "2024-07-21 06:33:15,659 - INFO - Epoch [4/100] train_loss: 2.4507, val_loss: 2.7441, lr: 0.010000, 232.58s\n",
      "2024-07-21 06:37:04,577 - INFO - epoch complete!\n",
      "2024-07-21 06:37:04,577 - INFO - evaluating now!\n",
      "2024-07-21 06:37:13,892 - INFO - Epoch [5/100] train_loss: 2.4100, val_loss: 2.7049, lr: 0.010000, 238.23s\n",
      "2024-07-21 06:41:00,067 - INFO - epoch complete!\n",
      "2024-07-21 06:41:00,068 - INFO - evaluating now!\n",
      "2024-07-21 06:41:09,366 - INFO - Epoch [6/100] train_loss: 2.3475, val_loss: 2.5107, lr: 0.010000, 235.47s\n",
      "2024-07-21 06:41:09,395 - INFO - Saved model at 6\n",
      "2024-07-21 06:41:09,396 - INFO - Val loss decrease from 2.6804 to 2.5107, saving to ./libcity/cache/10961/model_cache/HierAttnLstm_PEMS_BAY_epoch6.tar\n",
      "2024-07-21 06:44:56,500 - INFO - epoch complete!\n",
      "2024-07-21 06:44:56,501 - INFO - evaluating now!\n",
      "2024-07-21 06:45:05,796 - INFO - Epoch [7/100] train_loss: 2.3131, val_loss: 2.5681, lr: 0.010000, 236.40s\n",
      "2024-07-21 06:48:52,118 - INFO - epoch complete!\n",
      "2024-07-21 06:48:52,119 - INFO - evaluating now!\n",
      "2024-07-21 06:49:01,297 - INFO - Epoch [8/100] train_loss: 2.2983, val_loss: 2.4446, lr: 0.010000, 235.50s\n",
      "2024-07-21 06:49:01,326 - INFO - Saved model at 8\n",
      "2024-07-21 06:49:01,326 - INFO - Val loss decrease from 2.5107 to 2.4446, saving to ./libcity/cache/10961/model_cache/HierAttnLstm_PEMS_BAY_epoch8.tar\n",
      "2024-07-21 06:52:40,764 - INFO - epoch complete!\n",
      "2024-07-21 06:52:40,765 - INFO - evaluating now!\n",
      "2024-07-21 06:52:49,733 - INFO - Epoch [9/100] train_loss: 2.2748, val_loss: 2.5585, lr: 0.010000, 228.41s\n",
      "2024-07-21 06:56:28,867 - INFO - epoch complete!\n",
      "2024-07-21 06:56:28,867 - INFO - evaluating now!\n",
      "2024-07-21 06:56:37,847 - INFO - Epoch [10/100] train_loss: 2.2719, val_loss: 2.5222, lr: 0.010000, 228.11s\n",
      "2024-07-21 07:00:16,790 - INFO - epoch complete!\n",
      "2024-07-21 07:00:16,791 - INFO - evaluating now!\n",
      "2024-07-21 07:00:25,830 - INFO - Epoch [11/100] train_loss: 2.2582, val_loss: 2.5171, lr: 0.010000, 227.98s\n",
      "2024-07-21 07:04:03,957 - INFO - epoch complete!\n",
      "2024-07-21 07:04:03,957 - INFO - evaluating now!\n",
      "2024-07-21 07:04:13,004 - INFO - Epoch [12/100] train_loss: 2.2491, val_loss: 2.4551, lr: 0.010000, 227.17s\n",
      "2024-07-21 07:07:52,132 - INFO - epoch complete!\n",
      "2024-07-21 07:07:52,133 - INFO - evaluating now!\n",
      "2024-07-21 07:08:01,223 - INFO - Epoch [13/100] train_loss: 3.7739, val_loss: 4.4520, lr: 0.010000, 228.22s\n",
      "2024-07-21 07:11:39,823 - INFO - epoch complete!\n",
      "2024-07-21 07:11:39,824 - INFO - evaluating now!\n",
      "2024-07-21 07:11:48,743 - INFO - Epoch [14/100] train_loss: 3.1554, val_loss: 3.2592, lr: 0.010000, 227.52s\n",
      "2024-07-21 07:15:28,306 - INFO - epoch complete!\n",
      "2024-07-21 07:15:28,306 - INFO - evaluating now!\n",
      "2024-07-21 07:15:37,317 - INFO - Epoch [15/100] train_loss: 2.6906, val_loss: 2.6994, lr: 0.010000, 228.57s\n",
      "2024-07-21 07:19:15,926 - INFO - epoch complete!\n",
      "2024-07-21 07:19:15,926 - INFO - evaluating now!\n",
      "2024-07-21 07:19:24,967 - INFO - Epoch [16/100] train_loss: 2.5980, val_loss: 2.7728, lr: 0.010000, 227.65s\n",
      "2024-07-21 07:23:04,211 - INFO - epoch complete!\n",
      "2024-07-21 07:23:04,211 - INFO - evaluating now!\n",
      "2024-07-21 07:23:13,233 - INFO - Epoch [17/100] train_loss: 2.5650, val_loss: 2.6573, lr: 0.010000, 228.27s\n",
      "2024-07-21 07:26:52,550 - INFO - epoch complete!\n",
      "2024-07-21 07:26:52,550 - INFO - evaluating now!\n",
      "2024-07-21 07:27:01,524 - INFO - Epoch [18/100] train_loss: 2.5512, val_loss: 2.6326, lr: 0.010000, 228.29s\n",
      "2024-07-21 07:27:01,524 - WARNING - Early stopping at epoch: 18\n",
      "2024-07-21 07:27:01,525 - INFO - Trained totally 19 epochs, average train time is 221.313s, average eval time is 9.110s\n",
      "2024-07-21 07:27:01,539 - INFO - Loaded model at 8\n",
      "2024-07-21 07:27:01,540 - INFO - Saved model at ./libcity/cache/10961/model_cache/HierAttnLstm_PEMS_BAY.m\n",
      "2024-07-21 07:27:01,566 - INFO - Start evaluating ...\n",
      "2024-07-21 07:27:28,159 - INFO - Note that you select the single mode to evaluate!\n",
      "2024-07-21 07:27:28,272 - INFO - Evaluate result is saved at ./libcity/cache/10961/evaluate_cache/2024_07_21_07_27_28_HierAttnLstm_PEMS_BAY.csv\n",
      "2024-07-21 07:27:28,286 - INFO - \n",
      "        MAE  MAPE        MSE      RMSE  ...  masked_MSE  masked_RMSE        R2      EVAR\n",
      "1  2.442927   inf  25.490889  5.048850  ...   25.208189     5.020776  0.726713  0.729766\n",
      "2  2.442815   inf  25.488800  5.048644  ...   25.206099     5.020567  0.726730  0.729784\n",
      "3  2.454597   inf  25.783329  5.077729  ...   25.500517     5.049804  0.723570  0.727048\n",
      "4  2.462519   inf  25.979618  5.097021  ...   25.696810     5.069202  0.721464  0.725324\n",
      "5  2.478591   inf  26.376793  5.135834  ...   26.094017     5.108230  0.717203  0.721697\n",
      "6  2.493376   inf  26.715023  5.168658  ...   26.432285     5.141234  0.713573  0.718784\n",
      "\n",
      "[6 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "!python run_model.py --task traffic_state_pred --model HierAttnLstm --dataset PEMS_BAY --config_file HierAttnLstm_64_2_3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "gnxXWx5_FJeA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-21 07:27:32,742 - INFO - Log directory: ./libcity/log\n",
      "2024-07-21 07:27:32,744 - INFO - Begin pipeline, task=traffic_state_pred, model_name=HierAttnLstm, dataset_name=PEMS_BAY, exp_id=89918\n",
      "2024-07-21 07:27:32,744 - INFO - {'task': 'traffic_state_pred', 'model': 'HierAttnLstm', 'dataset': 'PEMS_BAY', 'saved_model': True, 'train': True, 'seed': 0, 'input_window': 48, 'output_window': 6, 'device': device(type='cuda', index=0), 'hidden_size': 64, 'num_layers': 2, 'dropout': 0.1, 'natt_hops': 4, 'nfc': 512, 'max_up_len': 80, 'dataset_class': 'TrafficStatePointDataset', 'executor': 'TrafficStateExecutor', 'evaluator': 'TrafficStateEvaluator', 'batch_size': 32, 'cache_dataset': True, 'num_workers': 0, 'pad_with_last_sample': True, 'train_rate': 0.7, 'eval_rate': 0.1, 'scaler': 'minmax01', 'load_external': False, 'normal_external': False, 'ext_scaler': 'none', 'add_time_in_day': False, 'add_day_in_week': False, 'robustness_test': False, 'noise_type': 'gaussian', 'disturb_rate': 0.5, 'noise_mean': [5], 'noise_SD': [10], 'gpu': True, 'gpu_id': 0, 'max_epoch': 100, 'train_loss': 'none', 'epoch': 0, 'learner': 'adam', 'learning_rate': 0.01, 'weight_decay': 0, 'lr_epsilon': 1e-08, 'lr_beta1': 0.9, 'lr_beta2': 0.999, 'lr_alpha': 0.99, 'lr_momentum': 0, 'lr_decay': False, 'lr_scheduler': 'multisteplr', 'lr_decay_ratio': 0.1, 'steps': [5, 20, 40, 70], 'step_size': 10, 'lr_T_max': 30, 'lr_eta_min': 0, 'lr_patience': 10, 'lr_threshold': 0.0001, 'clip_grad_norm': False, 'max_grad_norm': 1.0, 'use_early_stop': True, 'patience': 10, 'log_level': 'INFO', 'log_every': 1, 'load_best_epoch': True, 'hyper_tune': False, 'metrics': ['MAE', 'MAPE', 'MSE', 'RMSE', 'masked_MAE', 'masked_MAPE', 'masked_MSE', 'masked_RMSE', 'R2', 'EVAR'], 'evaluator_mode': 'single', 'save_mode': ['csv'], 'geo': {'including_types': ['Point'], 'Point': {}}, 'rel': {'including_types': ['geo'], 'geo': {'cost': 'num'}}, 'dyna': {'including_types': ['state'], 'state': {'entity_id': 'geo_id', 'traffic_speed': 'num'}}, 'data_col': ['traffic_speed'], 'weight_col': 'cost', 'data_files': ['PEMS_BAY'], 'geo_file': 'PEMS_BAY', 'rel_file': 'PEMS_BAY', 'output_dim': 1, 'time_intervals': 300, 'init_weight_inf_or_zero': 'inf', 'set_weight_link_or_dist': 'dist', 'calculate_weight_adj': True, 'weight_adj_epsilon': 0.1, 'exp_id': 89918}\n",
      "self.scaler_type  minmax01\n",
      "2024-07-21 07:27:32,791 - INFO - Loaded file PEMS_BAY.geo, num_nodes=325\n",
      "2024-07-21 07:27:32,801 - INFO - set_weight_link_or_dist: dist\n",
      "2024-07-21 07:27:32,801 - INFO - init_weight_inf_or_zero: inf\n",
      "2024-07-21 07:27:32,816 - INFO - Loaded file PEMS_BAY.rel, shape=(325, 325)\n",
      "2024-07-21 07:27:32,816 - INFO - Start Calculate the weight by Gauss kernel!\n",
      "2024-07-21 07:27:32,820 - INFO - Loading ./libcity/cache/dataset_cache/point_based_PEMS_BAY_48_6_0.7_0.1_minmax01_32_False_False_False_True.npz\n",
      "2024-07-21 07:28:02,294 - INFO - train\tx: (36444, 48, 325, 1), y: (36444, 6, 325, 1)\n",
      "2024-07-21 07:28:02,295 - INFO - eval\tx: (5206, 48, 325, 1), y: (5206, 6, 325, 1)\n",
      "2024-07-21 07:28:02,295 - INFO - test\tx: (10413, 48, 325, 1), y: (10413, 6, 325, 1)\n",
      "2024-07-21 07:28:03,117 - INFO - MinMax01Scaler max: 85.1, min: 0.0\n",
      "2024-07-21 07:28:03,117 - INFO - NoneScaler\n",
      "2024-07-21 07:28:08.882538: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-07-21 07:28:08.933806: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-21 07:28:08.933863: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-21 07:28:08.935382: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-07-21 07:28:08.943405: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-21 07:28:10.149922: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-07-21 07:28:11,383 - INFO - HierAttnLstm(\n",
      "  (lstm_cells): ModuleList(\n",
      "    (0): LSTMCell(325, 64)\n",
      "    (1): LSTMCell(64, 64)\n",
      "  )\n",
      "  (hidden_state_pooling): ModuleList(\n",
      "    (0): SelfAttentionPooling(\n",
      "      (W): Linear(in_features=64, out_features=1, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (cell_state_pooling): ModuleList(\n",
      "    (0): SelfAttentionPooling(\n",
      "      (W): Linear(in_features=64, out_features=1, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (self_attention): SelfAttention(\n",
      "    (ut_dense): Sequential(\n",
      "      (0): Linear(in_features=64, out_features=64, bias=True)\n",
      "      (1): Tanh()\n",
      "    )\n",
      "    (et_dense): Linear(in_features=64, out_features=4, bias=True)\n",
      "    (softmax): Softmax(dim=-1)\n",
      "  )\n",
      "  (fc_layer): Sequential(\n",
      "    (0): Linear(in_features=256, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=325, bias=True)\n",
      "  )\n",
      ")\n",
      "2024-07-21 07:28:11,384 - INFO - lstm_cells.0.weight_ih\ttorch.Size([256, 325])\tcuda:0\tTrue\n",
      "2024-07-21 07:28:11,384 - INFO - lstm_cells.0.weight_hh\ttorch.Size([256, 64])\tcuda:0\tTrue\n",
      "2024-07-21 07:28:11,384 - INFO - lstm_cells.0.bias_ih\ttorch.Size([256])\tcuda:0\tTrue\n",
      "2024-07-21 07:28:11,384 - INFO - lstm_cells.0.bias_hh\ttorch.Size([256])\tcuda:0\tTrue\n",
      "2024-07-21 07:28:11,384 - INFO - lstm_cells.1.weight_ih\ttorch.Size([256, 64])\tcuda:0\tTrue\n",
      "2024-07-21 07:28:11,384 - INFO - lstm_cells.1.weight_hh\ttorch.Size([256, 64])\tcuda:0\tTrue\n",
      "2024-07-21 07:28:11,385 - INFO - lstm_cells.1.bias_ih\ttorch.Size([256])\tcuda:0\tTrue\n",
      "2024-07-21 07:28:11,385 - INFO - lstm_cells.1.bias_hh\ttorch.Size([256])\tcuda:0\tTrue\n",
      "2024-07-21 07:28:11,385 - INFO - hidden_state_pooling.0.W.weight\ttorch.Size([1, 64])\tcuda:0\tTrue\n",
      "2024-07-21 07:28:11,385 - INFO - hidden_state_pooling.0.W.bias\ttorch.Size([1])\tcuda:0\tTrue\n",
      "2024-07-21 07:28:11,385 - INFO - cell_state_pooling.0.W.weight\ttorch.Size([1, 64])\tcuda:0\tTrue\n",
      "2024-07-21 07:28:11,385 - INFO - cell_state_pooling.0.W.bias\ttorch.Size([1])\tcuda:0\tTrue\n",
      "2024-07-21 07:28:11,385 - INFO - self_attention.ut_dense.0.weight\ttorch.Size([64, 64])\tcuda:0\tTrue\n",
      "2024-07-21 07:28:11,385 - INFO - self_attention.ut_dense.0.bias\ttorch.Size([64])\tcuda:0\tTrue\n",
      "2024-07-21 07:28:11,386 - INFO - self_attention.et_dense.weight\ttorch.Size([4, 64])\tcuda:0\tTrue\n",
      "2024-07-21 07:28:11,386 - INFO - self_attention.et_dense.bias\ttorch.Size([4])\tcuda:0\tTrue\n",
      "2024-07-21 07:28:11,386 - INFO - fc_layer.0.weight\ttorch.Size([512, 256])\tcuda:0\tTrue\n",
      "2024-07-21 07:28:11,386 - INFO - fc_layer.0.bias\ttorch.Size([512])\tcuda:0\tTrue\n",
      "2024-07-21 07:28:11,386 - INFO - fc_layer.2.weight\ttorch.Size([325, 512])\tcuda:0\tTrue\n",
      "2024-07-21 07:28:11,386 - INFO - fc_layer.2.bias\ttorch.Size([325])\tcuda:0\tTrue\n",
      "2024-07-21 07:28:11,386 - INFO - Total parameter numbers: 436235\n",
      "2024-07-21 07:28:11,387 - INFO - You select `adam` optimizer.\n",
      "2024-07-21 07:28:11,387 - WARNING - Received none train loss func and will use the loss func defined in the model.\n",
      "2024-07-21 07:28:11,387 - INFO - Start training ...\n",
      "2024-07-21 07:28:11,388 - INFO - num_batches:1139\n",
      "2024-07-21 07:31:52,685 - INFO - epoch complete!\n",
      "2024-07-21 07:31:52,686 - INFO - evaluating now!\n",
      "2024-07-21 07:32:01,728 - INFO - Epoch [0/100] train_loss: 5.0063, val_loss: 4.6096, lr: 0.010000, 230.34s\n",
      "2024-07-21 07:32:01,759 - INFO - Saved model at 0\n",
      "2024-07-21 07:32:01,759 - INFO - Val loss decrease from inf to 4.6096, saving to ./libcity/cache/89918/model_cache/HierAttnLstm_PEMS_BAY_epoch0.tar\n",
      "2024-07-21 07:35:41,512 - INFO - epoch complete!\n",
      "2024-07-21 07:35:41,513 - INFO - evaluating now!\n",
      "2024-07-21 07:35:50,587 - INFO - Epoch [1/100] train_loss: 3.5587, val_loss: 2.9859, lr: 0.010000, 228.83s\n",
      "2024-07-21 07:35:50,616 - INFO - Saved model at 1\n",
      "2024-07-21 07:35:50,616 - INFO - Val loss decrease from 4.6096 to 2.9859, saving to ./libcity/cache/89918/model_cache/HierAttnLstm_PEMS_BAY_epoch1.tar\n",
      "2024-07-21 07:39:32,283 - INFO - epoch complete!\n",
      "2024-07-21 07:39:32,283 - INFO - evaluating now!\n",
      "2024-07-21 07:39:41,392 - INFO - Epoch [2/100] train_loss: 2.7036, val_loss: 2.6741, lr: 0.010000, 230.77s\n",
      "2024-07-21 07:39:41,426 - INFO - Saved model at 2\n",
      "2024-07-21 07:39:41,426 - INFO - Val loss decrease from 2.9859 to 2.6741, saving to ./libcity/cache/89918/model_cache/HierAttnLstm_PEMS_BAY_epoch2.tar\n",
      "2024-07-21 07:43:21,261 - INFO - epoch complete!\n",
      "2024-07-21 07:43:21,262 - INFO - evaluating now!\n",
      "2024-07-21 07:43:30,373 - INFO - Epoch [3/100] train_loss: 2.5525, val_loss: 2.8054, lr: 0.010000, 228.95s\n",
      "2024-07-21 07:47:09,995 - INFO - epoch complete!\n",
      "2024-07-21 07:47:09,996 - INFO - evaluating now!\n",
      "2024-07-21 07:47:19,079 - INFO - Epoch [4/100] train_loss: 2.4578, val_loss: 2.6074, lr: 0.010000, 228.71s\n",
      "2024-07-21 07:47:19,108 - INFO - Saved model at 4\n",
      "2024-07-21 07:47:19,109 - INFO - Val loss decrease from 2.6741 to 2.6074, saving to ./libcity/cache/89918/model_cache/HierAttnLstm_PEMS_BAY_epoch4.tar\n",
      "2024-07-21 07:50:58,670 - INFO - epoch complete!\n",
      "2024-07-21 07:50:58,671 - INFO - evaluating now!\n",
      "2024-07-21 07:51:07,798 - INFO - Epoch [5/100] train_loss: 2.3921, val_loss: 2.6084, lr: 0.010000, 228.69s\n",
      "2024-07-21 07:54:47,675 - INFO - epoch complete!\n",
      "2024-07-21 07:54:47,676 - INFO - evaluating now!\n",
      "2024-07-21 07:54:56,765 - INFO - Epoch [6/100] train_loss: 2.3709, val_loss: 2.5853, lr: 0.010000, 228.97s\n",
      "2024-07-21 07:54:56,792 - INFO - Saved model at 6\n",
      "2024-07-21 07:54:56,793 - INFO - Val loss decrease from 2.6074 to 2.5853, saving to ./libcity/cache/89918/model_cache/HierAttnLstm_PEMS_BAY_epoch6.tar\n",
      "2024-07-21 07:58:35,938 - INFO - epoch complete!\n",
      "2024-07-21 07:58:35,939 - INFO - evaluating now!\n",
      "2024-07-21 07:58:45,007 - INFO - Epoch [7/100] train_loss: 2.3391, val_loss: 2.5108, lr: 0.010000, 228.21s\n",
      "2024-07-21 07:58:45,041 - INFO - Saved model at 7\n",
      "2024-07-21 07:58:45,042 - INFO - Val loss decrease from 2.5853 to 2.5108, saving to ./libcity/cache/89918/model_cache/HierAttnLstm_PEMS_BAY_epoch7.tar\n",
      "2024-07-21 08:02:25,370 - INFO - epoch complete!\n",
      "2024-07-21 08:02:25,371 - INFO - evaluating now!\n",
      "2024-07-21 08:02:34,468 - INFO - Epoch [8/100] train_loss: 2.3195, val_loss: 2.5501, lr: 0.010000, 229.43s\n",
      "2024-07-21 08:06:15,439 - INFO - epoch complete!\n",
      "2024-07-21 08:06:15,439 - INFO - evaluating now!\n",
      "2024-07-21 08:06:24,469 - INFO - Epoch [9/100] train_loss: 2.2891, val_loss: 2.5320, lr: 0.010000, 230.00s\n",
      "2024-07-21 08:10:07,550 - INFO - epoch complete!\n",
      "2024-07-21 08:10:07,550 - INFO - evaluating now!\n",
      "2024-07-21 08:10:16,718 - INFO - Epoch [10/100] train_loss: 2.2898, val_loss: 2.5006, lr: 0.010000, 232.25s\n",
      "2024-07-21 08:10:16,752 - INFO - Saved model at 10\n",
      "2024-07-21 08:10:16,753 - INFO - Val loss decrease from 2.5108 to 2.5006, saving to ./libcity/cache/89918/model_cache/HierAttnLstm_PEMS_BAY_epoch10.tar\n",
      "2024-07-21 08:13:59,089 - INFO - epoch complete!\n",
      "2024-07-21 08:13:59,090 - INFO - evaluating now!\n",
      "2024-07-21 08:14:08,280 - INFO - Epoch [11/100] train_loss: 2.3385, val_loss: 2.6888, lr: 0.010000, 231.53s\n",
      "2024-07-21 08:17:49,732 - INFO - epoch complete!\n",
      "2024-07-21 08:17:49,732 - INFO - evaluating now!\n",
      "2024-07-21 08:17:58,802 - INFO - Epoch [12/100] train_loss: 2.3027, val_loss: 2.5220, lr: 0.010000, 230.52s\n",
      "2024-07-21 08:21:40,280 - INFO - epoch complete!\n",
      "2024-07-21 08:21:40,280 - INFO - evaluating now!\n",
      "2024-07-21 08:21:49,424 - INFO - Epoch [13/100] train_loss: 2.2766, val_loss: 2.5297, lr: 0.010000, 230.62s\n",
      "2024-07-21 08:25:30,897 - INFO - epoch complete!\n",
      "2024-07-21 08:25:30,898 - INFO - evaluating now!\n",
      "2024-07-21 08:25:40,136 - INFO - Epoch [14/100] train_loss: 2.2609, val_loss: 2.5870, lr: 0.010000, 230.71s\n",
      "2024-07-21 08:29:22,975 - INFO - epoch complete!\n",
      "2024-07-21 08:29:22,975 - INFO - evaluating now!\n",
      "2024-07-21 08:29:32,103 - INFO - Epoch [15/100] train_loss: 2.2651, val_loss: 2.6277, lr: 0.010000, 231.97s\n",
      "2024-07-21 08:33:13,689 - INFO - epoch complete!\n",
      "2024-07-21 08:33:13,690 - INFO - evaluating now!\n",
      "2024-07-21 08:33:22,857 - INFO - Epoch [16/100] train_loss: 2.2532, val_loss: 2.5368, lr: 0.010000, 230.75s\n",
      "2024-07-21 08:37:04,105 - INFO - epoch complete!\n",
      "2024-07-21 08:37:04,105 - INFO - evaluating now!\n",
      "2024-07-21 08:37:13,250 - INFO - Epoch [17/100] train_loss: 2.2886, val_loss: 2.5764, lr: 0.010000, 230.39s\n",
      "2024-07-21 08:40:55,063 - INFO - epoch complete!\n",
      "2024-07-21 08:40:55,063 - INFO - evaluating now!\n",
      "2024-07-21 08:41:04,218 - INFO - Epoch [18/100] train_loss: 2.2610, val_loss: 2.5121, lr: 0.010000, 230.97s\n",
      "2024-07-21 08:44:45,364 - INFO - epoch complete!\n",
      "2024-07-21 08:44:45,364 - INFO - evaluating now!\n",
      "2024-07-21 08:44:54,473 - INFO - Epoch [19/100] train_loss: 2.2573, val_loss: 2.4929, lr: 0.010000, 230.25s\n",
      "2024-07-21 08:44:54,502 - INFO - Saved model at 19\n",
      "2024-07-21 08:44:54,502 - INFO - Val loss decrease from 2.5006 to 2.4929, saving to ./libcity/cache/89918/model_cache/HierAttnLstm_PEMS_BAY_epoch19.tar\n",
      "2024-07-21 08:48:37,474 - INFO - epoch complete!\n",
      "2024-07-21 08:48:37,475 - INFO - evaluating now!\n",
      "2024-07-21 08:48:46,688 - INFO - Epoch [20/100] train_loss: 2.2477, val_loss: 2.5343, lr: 0.010000, 232.19s\n",
      "2024-07-21 08:52:27,959 - INFO - epoch complete!\n",
      "2024-07-21 08:52:27,960 - INFO - evaluating now!\n",
      "2024-07-21 08:52:37,076 - INFO - Epoch [21/100] train_loss: 2.2441, val_loss: 2.4597, lr: 0.010000, 230.39s\n",
      "2024-07-21 08:52:37,105 - INFO - Saved model at 21\n",
      "2024-07-21 08:52:37,106 - INFO - Val loss decrease from 2.4929 to 2.4597, saving to ./libcity/cache/89918/model_cache/HierAttnLstm_PEMS_BAY_epoch21.tar\n",
      "2024-07-21 08:56:18,811 - INFO - epoch complete!\n",
      "2024-07-21 08:56:18,811 - INFO - evaluating now!\n",
      "2024-07-21 08:56:28,040 - INFO - Epoch [22/100] train_loss: 2.2479, val_loss: 2.6237, lr: 0.010000, 230.93s\n",
      "2024-07-21 09:00:09,747 - INFO - epoch complete!\n",
      "2024-07-21 09:00:09,748 - INFO - evaluating now!\n",
      "2024-07-21 09:00:18,927 - INFO - Epoch [23/100] train_loss: 2.2427, val_loss: 2.5083, lr: 0.010000, 230.89s\n",
      "2024-07-21 09:04:00,419 - INFO - epoch complete!\n",
      "2024-07-21 09:04:00,420 - INFO - evaluating now!\n",
      "2024-07-21 09:04:09,567 - INFO - Epoch [24/100] train_loss: 2.2451, val_loss: 2.4476, lr: 0.010000, 230.64s\n",
      "2024-07-21 09:04:09,598 - INFO - Saved model at 24\n",
      "2024-07-21 09:04:09,599 - INFO - Val loss decrease from 2.4597 to 2.4476, saving to ./libcity/cache/89918/model_cache/HierAttnLstm_PEMS_BAY_epoch24.tar\n",
      "2024-07-21 09:07:51,710 - INFO - epoch complete!\n",
      "2024-07-21 09:07:51,711 - INFO - evaluating now!\n",
      "2024-07-21 09:08:00,805 - INFO - Epoch [25/100] train_loss: 2.2289, val_loss: 2.4516, lr: 0.010000, 231.21s\n",
      "2024-07-21 09:11:42,804 - INFO - epoch complete!\n",
      "2024-07-21 09:11:42,805 - INFO - evaluating now!\n",
      "2024-07-21 09:11:51,985 - INFO - Epoch [26/100] train_loss: 2.2298, val_loss: 2.5176, lr: 0.010000, 231.18s\n",
      "2024-07-21 09:15:33,834 - INFO - epoch complete!\n",
      "2024-07-21 09:15:33,835 - INFO - evaluating now!\n",
      "2024-07-21 09:15:42,928 - INFO - Epoch [27/100] train_loss: 2.2319, val_loss: 2.5484, lr: 0.010000, 230.94s\n",
      "2024-07-21 09:19:24,451 - INFO - epoch complete!\n",
      "2024-07-21 09:19:24,451 - INFO - evaluating now!\n",
      "2024-07-21 09:19:33,590 - INFO - Epoch [28/100] train_loss: 2.2348, val_loss: 2.5092, lr: 0.010000, 230.66s\n",
      "2024-07-21 09:23:15,809 - INFO - epoch complete!\n",
      "2024-07-21 09:23:15,810 - INFO - evaluating now!\n",
      "2024-07-21 09:23:25,003 - INFO - Epoch [29/100] train_loss: 3.3311, val_loss: 5.1435, lr: 0.010000, 231.41s\n",
      "2024-07-21 09:27:06,158 - INFO - epoch complete!\n",
      "2024-07-21 09:27:06,158 - INFO - evaluating now!\n",
      "2024-07-21 09:27:15,320 - INFO - Epoch [30/100] train_loss: 4.4639, val_loss: 5.1504, lr: 0.010000, 230.32s\n",
      "2024-07-21 09:30:57,441 - INFO - epoch complete!\n",
      "2024-07-21 09:30:57,442 - INFO - evaluating now!\n",
      "2024-07-21 09:31:06,486 - INFO - Epoch [31/100] train_loss: 4.4635, val_loss: 5.1582, lr: 0.010000, 231.17s\n",
      "2024-07-21 09:34:48,280 - INFO - epoch complete!\n",
      "2024-07-21 09:34:48,280 - INFO - evaluating now!\n",
      "2024-07-21 09:34:57,391 - INFO - Epoch [32/100] train_loss: 4.4668, val_loss: 5.1505, lr: 0.010000, 230.90s\n",
      "2024-07-21 09:38:39,063 - INFO - epoch complete!\n",
      "2024-07-21 09:38:39,064 - INFO - evaluating now!\n",
      "2024-07-21 09:38:48,161 - INFO - Epoch [33/100] train_loss: 4.4667, val_loss: 5.1688, lr: 0.010000, 230.77s\n",
      "2024-07-21 09:42:30,301 - INFO - epoch complete!\n",
      "2024-07-21 09:42:30,301 - INFO - evaluating now!\n",
      "2024-07-21 09:42:39,439 - INFO - Epoch [34/100] train_loss: 4.4671, val_loss: 5.1592, lr: 0.010000, 231.28s\n",
      "2024-07-21 09:42:39,439 - WARNING - Early stopping at epoch: 34\n",
      "2024-07-21 09:42:39,439 - INFO - Trained totally 35 epochs, average train time is 221.377s, average eval time is 9.128s\n",
      "2024-07-21 09:42:39,459 - INFO - Loaded model at 24\n",
      "2024-07-21 09:42:39,460 - INFO - Saved model at ./libcity/cache/89918/model_cache/HierAttnLstm_PEMS_BAY.m\n",
      "2024-07-21 09:42:39,489 - INFO - Start evaluating ...\n",
      "2024-07-21 09:43:06,558 - INFO - Note that you select the single mode to evaluate!\n",
      "2024-07-21 09:43:06,566 - INFO - Evaluate result is saved at ./libcity/cache/89918/evaluate_cache/2024_07_21_09_43_06_HierAttnLstm_PEMS_BAY.csv\n",
      "2024-07-21 09:43:06,580 - INFO - \n",
      "        MAE  MAPE        MSE      RMSE  ...  masked_MSE  masked_RMSE        R2      EVAR\n",
      "1  2.456523   inf  25.510056  5.050748  ...   25.225519     5.022501  0.726507  0.731129\n",
      "2  2.456428   inf  25.508909  5.050634  ...   25.224375     5.022388  0.726515  0.731137\n",
      "3  2.472874   inf  25.983213  5.097373  ...   25.698616     5.069380  0.721427  0.726472\n",
      "4  2.481628   inf  26.219521  5.120500  ...   25.934942     5.092636  0.718892  0.724286\n",
      "5  2.502243   inf  26.761627  5.173164  ...   26.477070     5.145587  0.713077  0.719175\n",
      "6  2.519724   inf  27.152462  5.210803  ...   26.867926     5.183428  0.708883  0.715639\n",
      "\n",
      "[6 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "!python run_model.py --task traffic_state_pred --model HierAttnLstm --dataset PEMS_BAY --config_file HierAttnLstm_64_2_4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "ddlSvRR9FK1V"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-21 09:43:11,073 - INFO - Log directory: ./libcity/log\n",
      "2024-07-21 09:43:11,075 - INFO - Begin pipeline, task=traffic_state_pred, model_name=HierAttnLstm, dataset_name=PEMS_BAY, exp_id=9568\n",
      "2024-07-21 09:43:11,075 - INFO - {'task': 'traffic_state_pred', 'model': 'HierAttnLstm', 'dataset': 'PEMS_BAY', 'saved_model': True, 'train': True, 'seed': 0, 'input_window': 48, 'output_window': 6, 'device': device(type='cuda', index=0), 'hidden_size': 64, 'num_layers': 3, 'dropout': 0.1, 'natt_hops': 2, 'nfc': 512, 'max_up_len': 80, 'dataset_class': 'TrafficStatePointDataset', 'executor': 'TrafficStateExecutor', 'evaluator': 'TrafficStateEvaluator', 'batch_size': 32, 'cache_dataset': True, 'num_workers': 0, 'pad_with_last_sample': True, 'train_rate': 0.7, 'eval_rate': 0.1, 'scaler': 'minmax01', 'load_external': False, 'normal_external': False, 'ext_scaler': 'none', 'add_time_in_day': False, 'add_day_in_week': False, 'robustness_test': False, 'noise_type': 'gaussian', 'disturb_rate': 0.5, 'noise_mean': [5], 'noise_SD': [10], 'gpu': True, 'gpu_id': 0, 'max_epoch': 100, 'train_loss': 'none', 'epoch': 0, 'learner': 'adam', 'learning_rate': 0.01, 'weight_decay': 0, 'lr_epsilon': 1e-08, 'lr_beta1': 0.9, 'lr_beta2': 0.999, 'lr_alpha': 0.99, 'lr_momentum': 0, 'lr_decay': False, 'lr_scheduler': 'multisteplr', 'lr_decay_ratio': 0.1, 'steps': [5, 20, 40, 70], 'step_size': 10, 'lr_T_max': 30, 'lr_eta_min': 0, 'lr_patience': 10, 'lr_threshold': 0.0001, 'clip_grad_norm': False, 'max_grad_norm': 1.0, 'use_early_stop': True, 'patience': 10, 'log_level': 'INFO', 'log_every': 1, 'load_best_epoch': True, 'hyper_tune': False, 'metrics': ['MAE', 'MAPE', 'MSE', 'RMSE', 'masked_MAE', 'masked_MAPE', 'masked_MSE', 'masked_RMSE', 'R2', 'EVAR'], 'evaluator_mode': 'single', 'save_mode': ['csv'], 'geo': {'including_types': ['Point'], 'Point': {}}, 'rel': {'including_types': ['geo'], 'geo': {'cost': 'num'}}, 'dyna': {'including_types': ['state'], 'state': {'entity_id': 'geo_id', 'traffic_speed': 'num'}}, 'data_col': ['traffic_speed'], 'weight_col': 'cost', 'data_files': ['PEMS_BAY'], 'geo_file': 'PEMS_BAY', 'rel_file': 'PEMS_BAY', 'output_dim': 1, 'time_intervals': 300, 'init_weight_inf_or_zero': 'inf', 'set_weight_link_or_dist': 'dist', 'calculate_weight_adj': True, 'weight_adj_epsilon': 0.1, 'exp_id': 9568}\n",
      "self.scaler_type  minmax01\n",
      "2024-07-21 09:43:11,164 - INFO - Loaded file PEMS_BAY.geo, num_nodes=325\n",
      "2024-07-21 09:43:11,174 - INFO - set_weight_link_or_dist: dist\n",
      "2024-07-21 09:43:11,174 - INFO - init_weight_inf_or_zero: inf\n",
      "2024-07-21 09:43:11,188 - INFO - Loaded file PEMS_BAY.rel, shape=(325, 325)\n",
      "2024-07-21 09:43:11,189 - INFO - Start Calculate the weight by Gauss kernel!\n",
      "2024-07-21 09:43:11,192 - INFO - Loading ./libcity/cache/dataset_cache/point_based_PEMS_BAY_48_6_0.7_0.1_minmax01_32_False_False_False_True.npz\n",
      "2024-07-21 09:43:40,637 - INFO - train\tx: (36444, 48, 325, 1), y: (36444, 6, 325, 1)\n",
      "2024-07-21 09:43:40,637 - INFO - eval\tx: (5206, 48, 325, 1), y: (5206, 6, 325, 1)\n",
      "2024-07-21 09:43:40,638 - INFO - test\tx: (10413, 48, 325, 1), y: (10413, 6, 325, 1)\n",
      "2024-07-21 09:43:41,467 - INFO - MinMax01Scaler max: 85.1, min: 0.0\n",
      "2024-07-21 09:43:41,468 - INFO - NoneScaler\n",
      "2024-07-21 09:43:47.188767: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-07-21 09:43:47.239662: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-21 09:43:47.239717: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-21 09:43:47.241145: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-07-21 09:43:47.248824: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-21 09:43:48.467480: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-07-21 09:43:49,720 - INFO - HierAttnLstm(\n",
      "  (lstm_cells): ModuleList(\n",
      "    (0): LSTMCell(325, 64)\n",
      "    (1-2): 2 x LSTMCell(64, 64)\n",
      "  )\n",
      "  (hidden_state_pooling): ModuleList(\n",
      "    (0-1): 2 x SelfAttentionPooling(\n",
      "      (W): Linear(in_features=64, out_features=1, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (cell_state_pooling): ModuleList(\n",
      "    (0-1): 2 x SelfAttentionPooling(\n",
      "      (W): Linear(in_features=64, out_features=1, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (self_attention): SelfAttention(\n",
      "    (ut_dense): Sequential(\n",
      "      (0): Linear(in_features=64, out_features=64, bias=True)\n",
      "      (1): Tanh()\n",
      "    )\n",
      "    (et_dense): Linear(in_features=64, out_features=2, bias=True)\n",
      "    (softmax): Softmax(dim=-1)\n",
      "  )\n",
      "  (fc_layer): Sequential(\n",
      "    (0): Linear(in_features=128, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=325, bias=True)\n",
      "  )\n",
      ")\n",
      "2024-07-21 09:43:49,720 - INFO - lstm_cells.0.weight_ih\ttorch.Size([256, 325])\tcuda:0\tTrue\n",
      "2024-07-21 09:43:49,721 - INFO - lstm_cells.0.weight_hh\ttorch.Size([256, 64])\tcuda:0\tTrue\n",
      "2024-07-21 09:43:49,721 - INFO - lstm_cells.0.bias_ih\ttorch.Size([256])\tcuda:0\tTrue\n",
      "2024-07-21 09:43:49,721 - INFO - lstm_cells.0.bias_hh\ttorch.Size([256])\tcuda:0\tTrue\n",
      "2024-07-21 09:43:49,721 - INFO - lstm_cells.1.weight_ih\ttorch.Size([256, 64])\tcuda:0\tTrue\n",
      "2024-07-21 09:43:49,721 - INFO - lstm_cells.1.weight_hh\ttorch.Size([256, 64])\tcuda:0\tTrue\n",
      "2024-07-21 09:43:49,721 - INFO - lstm_cells.1.bias_ih\ttorch.Size([256])\tcuda:0\tTrue\n",
      "2024-07-21 09:43:49,721 - INFO - lstm_cells.1.bias_hh\ttorch.Size([256])\tcuda:0\tTrue\n",
      "2024-07-21 09:43:49,721 - INFO - lstm_cells.2.weight_ih\ttorch.Size([256, 64])\tcuda:0\tTrue\n",
      "2024-07-21 09:43:49,721 - INFO - lstm_cells.2.weight_hh\ttorch.Size([256, 64])\tcuda:0\tTrue\n",
      "2024-07-21 09:43:49,721 - INFO - lstm_cells.2.bias_ih\ttorch.Size([256])\tcuda:0\tTrue\n",
      "2024-07-21 09:43:49,721 - INFO - lstm_cells.2.bias_hh\ttorch.Size([256])\tcuda:0\tTrue\n",
      "2024-07-21 09:43:49,722 - INFO - hidden_state_pooling.0.W.weight\ttorch.Size([1, 64])\tcuda:0\tTrue\n",
      "2024-07-21 09:43:49,722 - INFO - hidden_state_pooling.0.W.bias\ttorch.Size([1])\tcuda:0\tTrue\n",
      "2024-07-21 09:43:49,722 - INFO - hidden_state_pooling.1.W.weight\ttorch.Size([1, 64])\tcuda:0\tTrue\n",
      "2024-07-21 09:43:49,722 - INFO - hidden_state_pooling.1.W.bias\ttorch.Size([1])\tcuda:0\tTrue\n",
      "2024-07-21 09:43:49,722 - INFO - cell_state_pooling.0.W.weight\ttorch.Size([1, 64])\tcuda:0\tTrue\n",
      "2024-07-21 09:43:49,722 - INFO - cell_state_pooling.0.W.bias\ttorch.Size([1])\tcuda:0\tTrue\n",
      "2024-07-21 09:43:49,722 - INFO - cell_state_pooling.1.W.weight\ttorch.Size([1, 64])\tcuda:0\tTrue\n",
      "2024-07-21 09:43:49,722 - INFO - cell_state_pooling.1.W.bias\ttorch.Size([1])\tcuda:0\tTrue\n",
      "2024-07-21 09:43:49,722 - INFO - self_attention.ut_dense.0.weight\ttorch.Size([64, 64])\tcuda:0\tTrue\n",
      "2024-07-21 09:43:49,722 - INFO - self_attention.ut_dense.0.bias\ttorch.Size([64])\tcuda:0\tTrue\n",
      "2024-07-21 09:43:49,723 - INFO - self_attention.et_dense.weight\ttorch.Size([2, 64])\tcuda:0\tTrue\n",
      "2024-07-21 09:43:49,723 - INFO - self_attention.et_dense.bias\ttorch.Size([2])\tcuda:0\tTrue\n",
      "2024-07-21 09:43:49,723 - INFO - fc_layer.0.weight\ttorch.Size([512, 128])\tcuda:0\tTrue\n",
      "2024-07-21 09:43:49,723 - INFO - fc_layer.0.bias\ttorch.Size([512])\tcuda:0\tTrue\n",
      "2024-07-21 09:43:49,723 - INFO - fc_layer.2.weight\ttorch.Size([325, 512])\tcuda:0\tTrue\n",
      "2024-07-21 09:43:49,723 - INFO - fc_layer.2.bias\ttorch.Size([325])\tcuda:0\tTrue\n",
      "2024-07-21 09:43:49,723 - INFO - Total parameter numbers: 403979\n",
      "2024-07-21 09:43:49,723 - INFO - You select `adam` optimizer.\n",
      "2024-07-21 09:43:49,724 - WARNING - Received none train loss func and will use the loss func defined in the model.\n",
      "2024-07-21 09:43:49,724 - INFO - Start training ...\n",
      "2024-07-21 09:43:49,724 - INFO - num_batches:1139\n",
      "2024-07-21 09:48:22,884 - INFO - epoch complete!\n",
      "2024-07-21 09:48:22,885 - INFO - evaluating now!\n",
      "2024-07-21 09:48:34,225 - INFO - Epoch [0/100] train_loss: 4.2571, val_loss: 3.0282, lr: 0.010000, 284.50s\n",
      "2024-07-21 09:48:34,256 - INFO - Saved model at 0\n",
      "2024-07-21 09:48:34,257 - INFO - Val loss decrease from inf to 3.0282, saving to ./libcity/cache/9568/model_cache/HierAttnLstm_PEMS_BAY_epoch0.tar\n",
      "2024-07-21 09:53:07,757 - INFO - epoch complete!\n",
      "2024-07-21 09:53:07,758 - INFO - evaluating now!\n",
      "2024-07-21 09:53:19,206 - INFO - Epoch [1/100] train_loss: 2.6045, val_loss: 2.6113, lr: 0.010000, 284.95s\n",
      "2024-07-21 09:53:19,237 - INFO - Saved model at 1\n",
      "2024-07-21 09:53:19,237 - INFO - Val loss decrease from 3.0282 to 2.6113, saving to ./libcity/cache/9568/model_cache/HierAttnLstm_PEMS_BAY_epoch1.tar\n",
      "2024-07-21 09:57:52,463 - INFO - epoch complete!\n",
      "2024-07-21 09:57:52,464 - INFO - evaluating now!\n",
      "2024-07-21 09:58:03,760 - INFO - Epoch [2/100] train_loss: 2.4574, val_loss: 2.6359, lr: 0.010000, 284.52s\n",
      "2024-07-21 10:02:37,392 - INFO - epoch complete!\n",
      "2024-07-21 10:02:37,392 - INFO - evaluating now!\n",
      "2024-07-21 10:02:48,800 - INFO - Epoch [3/100] train_loss: 2.3692, val_loss: 2.6351, lr: 0.010000, 285.04s\n",
      "2024-07-21 10:07:23,756 - INFO - epoch complete!\n",
      "2024-07-21 10:07:23,757 - INFO - evaluating now!\n",
      "2024-07-21 10:07:35,231 - INFO - Epoch [4/100] train_loss: 2.3245, val_loss: 2.4840, lr: 0.010000, 286.43s\n",
      "2024-07-21 10:07:35,262 - INFO - Saved model at 4\n",
      "2024-07-21 10:07:35,263 - INFO - Val loss decrease from 2.6113 to 2.4840, saving to ./libcity/cache/9568/model_cache/HierAttnLstm_PEMS_BAY_epoch4.tar\n",
      "2024-07-21 10:12:08,864 - INFO - epoch complete!\n",
      "2024-07-21 10:12:08,865 - INFO - evaluating now!\n",
      "2024-07-21 10:12:20,193 - INFO - Epoch [5/100] train_loss: 2.2832, val_loss: 2.4962, lr: 0.010000, 284.93s\n",
      "2024-07-21 10:16:52,218 - INFO - epoch complete!\n",
      "2024-07-21 10:16:52,219 - INFO - evaluating now!\n",
      "2024-07-21 10:17:03,485 - INFO - Epoch [6/100] train_loss: 2.2544, val_loss: 2.5338, lr: 0.010000, 283.29s\n",
      "2024-07-21 10:21:32,965 - INFO - epoch complete!\n",
      "2024-07-21 10:21:32,965 - INFO - evaluating now!\n",
      "2024-07-21 10:21:44,218 - INFO - Epoch [7/100] train_loss: 2.2395, val_loss: 2.4501, lr: 0.010000, 280.73s\n",
      "2024-07-21 10:21:44,264 - INFO - Saved model at 7\n",
      "2024-07-21 10:21:44,264 - INFO - Val loss decrease from 2.4840 to 2.4501, saving to ./libcity/cache/9568/model_cache/HierAttnLstm_PEMS_BAY_epoch7.tar\n",
      "2024-07-21 10:26:17,164 - INFO - epoch complete!\n",
      "2024-07-21 10:26:17,164 - INFO - evaluating now!\n",
      "2024-07-21 10:26:28,912 - INFO - Epoch [8/100] train_loss: 2.2079, val_loss: 2.4521, lr: 0.010000, 284.65s\n",
      "2024-07-21 10:31:09,653 - INFO - epoch complete!\n",
      "2024-07-21 10:31:09,654 - INFO - evaluating now!\n",
      "2024-07-21 10:31:21,433 - INFO - Epoch [9/100] train_loss: 2.3928, val_loss: 2.5320, lr: 0.010000, 292.52s\n",
      "2024-07-21 10:35:57,648 - INFO - epoch complete!\n",
      "2024-07-21 10:35:57,648 - INFO - evaluating now!\n",
      "2024-07-21 10:36:09,154 - INFO - Epoch [10/100] train_loss: 2.3205, val_loss: 2.4830, lr: 0.010000, 287.72s\n",
      "2024-07-21 10:40:50,451 - INFO - epoch complete!\n",
      "2024-07-21 10:40:50,451 - INFO - evaluating now!\n",
      "2024-07-21 10:41:02,046 - INFO - Epoch [11/100] train_loss: 2.2485, val_loss: 2.4173, lr: 0.010000, 292.89s\n",
      "2024-07-21 10:41:02,080 - INFO - Saved model at 11\n",
      "2024-07-21 10:41:02,080 - INFO - Val loss decrease from 2.4501 to 2.4173, saving to ./libcity/cache/9568/model_cache/HierAttnLstm_PEMS_BAY_epoch11.tar\n",
      "2024-07-21 10:45:43,240 - INFO - epoch complete!\n",
      "2024-07-21 10:45:43,241 - INFO - evaluating now!\n",
      "2024-07-21 10:45:54,898 - INFO - Epoch [12/100] train_loss: 2.2209, val_loss: 2.5936, lr: 0.010000, 292.82s\n",
      "2024-07-21 10:50:35,100 - INFO - epoch complete!\n",
      "2024-07-21 10:50:35,101 - INFO - evaluating now!\n",
      "2024-07-21 10:50:46,742 - INFO - Epoch [13/100] train_loss: 2.1965, val_loss: 2.4992, lr: 0.010000, 291.84s\n",
      "2024-07-21 10:55:26,593 - INFO - epoch complete!\n",
      "2024-07-21 10:55:26,594 - INFO - evaluating now!\n",
      "2024-07-21 10:55:38,241 - INFO - Epoch [14/100] train_loss: 2.1838, val_loss: 2.4937, lr: 0.010000, 291.50s\n",
      "2024-07-21 11:00:20,046 - INFO - epoch complete!\n",
      "2024-07-21 11:00:20,046 - INFO - evaluating now!\n",
      "2024-07-21 11:00:31,651 - INFO - Epoch [15/100] train_loss: 2.1819, val_loss: 2.4330, lr: 0.010000, 293.41s\n",
      "2024-07-21 11:05:10,011 - INFO - epoch complete!\n",
      "2024-07-21 11:05:10,012 - INFO - evaluating now!\n",
      "2024-07-21 11:05:21,686 - INFO - Epoch [16/100] train_loss: 2.1627, val_loss: 2.3963, lr: 0.010000, 290.03s\n",
      "2024-07-21 11:05:21,718 - INFO - Saved model at 16\n",
      "2024-07-21 11:05:21,718 - INFO - Val loss decrease from 2.4173 to 2.3963, saving to ./libcity/cache/9568/model_cache/HierAttnLstm_PEMS_BAY_epoch16.tar\n",
      "2024-07-21 11:09:59,551 - INFO - epoch complete!\n",
      "2024-07-21 11:09:59,552 - INFO - evaluating now!\n",
      "2024-07-21 11:10:11,169 - INFO - Epoch [17/100] train_loss: 2.1545, val_loss: 2.4082, lr: 0.010000, 289.45s\n",
      "2024-07-21 11:14:51,309 - INFO - epoch complete!\n",
      "2024-07-21 11:14:51,310 - INFO - evaluating now!\n",
      "2024-07-21 11:15:02,968 - INFO - Epoch [18/100] train_loss: 2.1516, val_loss: 2.4175, lr: 0.010000, 291.80s\n",
      "2024-07-21 11:19:43,615 - INFO - epoch complete!\n",
      "2024-07-21 11:19:43,616 - INFO - evaluating now!\n",
      "2024-07-21 11:19:55,167 - INFO - Epoch [19/100] train_loss: 2.1404, val_loss: 2.4427, lr: 0.010000, 292.20s\n",
      "2024-07-21 11:24:36,386 - INFO - epoch complete!\n",
      "2024-07-21 11:24:36,386 - INFO - evaluating now!\n",
      "2024-07-21 11:24:48,507 - INFO - Epoch [20/100] train_loss: 2.1401, val_loss: 2.4321, lr: 0.010000, 293.34s\n",
      "2024-07-21 11:29:36,872 - INFO - epoch complete!\n",
      "2024-07-21 11:29:36,873 - INFO - evaluating now!\n",
      "2024-07-21 11:29:48,942 - INFO - Epoch [21/100] train_loss: 2.1264, val_loss: 2.4401, lr: 0.010000, 300.43s\n",
      "2024-07-21 11:34:37,293 - INFO - epoch complete!\n",
      "2024-07-21 11:34:37,294 - INFO - evaluating now!\n",
      "2024-07-21 11:34:49,284 - INFO - Epoch [22/100] train_loss: 2.1330, val_loss: 2.4054, lr: 0.010000, 300.34s\n",
      "2024-07-21 11:39:37,049 - INFO - epoch complete!\n",
      "2024-07-21 11:39:37,050 - INFO - evaluating now!\n",
      "2024-07-21 11:39:49,098 - INFO - Epoch [23/100] train_loss: 2.1236, val_loss: 2.3967, lr: 0.010000, 299.81s\n",
      "2024-07-21 11:44:37,394 - INFO - epoch complete!\n",
      "2024-07-21 11:44:37,395 - INFO - evaluating now!\n",
      "2024-07-21 11:44:48,977 - INFO - Epoch [24/100] train_loss: 2.1244, val_loss: 2.4106, lr: 0.010000, 299.88s\n",
      "2024-07-21 11:49:32,599 - INFO - epoch complete!\n",
      "2024-07-21 11:49:32,600 - INFO - evaluating now!\n",
      "2024-07-21 11:49:44,507 - INFO - Epoch [25/100] train_loss: 2.1172, val_loss: 2.4632, lr: 0.010000, 295.53s\n",
      "2024-07-21 11:54:29,688 - INFO - epoch complete!\n",
      "2024-07-21 11:54:29,689 - INFO - evaluating now!\n",
      "2024-07-21 11:54:41,747 - INFO - Epoch [26/100] train_loss: 2.1153, val_loss: 2.4125, lr: 0.010000, 297.24s\n",
      "2024-07-21 11:54:41,747 - WARNING - Early stopping at epoch: 26\n",
      "2024-07-21 11:54:41,748 - INFO - Trained totally 27 epochs, average train time is 279.167s, average eval time is 11.639s\n",
      "2024-07-21 11:54:41,768 - INFO - Loaded model at 16\n",
      "2024-07-21 11:54:41,769 - INFO - Saved model at ./libcity/cache/9568/model_cache/HierAttnLstm_PEMS_BAY.m\n",
      "2024-07-21 11:54:41,800 - INFO - Start evaluating ...\n",
      "2024-07-21 11:55:11,187 - INFO - Note that you select the single mode to evaluate!\n",
      "2024-07-21 11:55:11,195 - INFO - Evaluate result is saved at ./libcity/cache/9568/evaluate_cache/2024_07_21_11_55_11_HierAttnLstm_PEMS_BAY.csv\n",
      "2024-07-21 11:55:11,210 - INFO - \n",
      "        MAE  MAPE        MSE      RMSE  ...  masked_MSE  masked_RMSE        R2      EVAR\n",
      "1  2.493146   inf  26.827444  5.179522  ...   26.544901     5.152174  0.712384  0.720931\n",
      "2  2.493035   inf  26.826138  5.179396  ...   26.543600     5.152048  0.712393  0.720940\n",
      "3  2.492949   inf  26.825104  5.179296  ...   26.542564     5.151947  0.712401  0.720948\n",
      "4  2.492883   inf  26.824251  5.179214  ...   26.541714     5.151865  0.712408  0.720956\n",
      "5  2.492817   inf  26.823252  5.179117  ...   26.540716     5.151768  0.712416  0.720965\n",
      "6  2.492741   inf  26.822214  5.179017  ...   26.539677     5.151668  0.712424  0.720975\n",
      "\n",
      "[6 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "!python run_model.py --task traffic_state_pred --model HierAttnLstm --dataset PEMS_BAY --config_file HierAttnLstm_64_3_2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "JRM5YVevFMOh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-21 11:55:16,234 - INFO - Log directory: ./libcity/log\n",
      "2024-07-21 11:55:16,236 - INFO - Begin pipeline, task=traffic_state_pred, model_name=HierAttnLstm, dataset_name=PEMS_BAY, exp_id=39082\n",
      "2024-07-21 11:55:16,264 - INFO - {'task': 'traffic_state_pred', 'model': 'HierAttnLstm', 'dataset': 'PEMS_BAY', 'saved_model': True, 'train': True, 'seed': 0, 'input_window': 48, 'output_window': 6, 'device': device(type='cuda', index=0), 'hidden_size': 64, 'num_layers': 3, 'dropout': 0.1, 'natt_hops': 3, 'nfc': 512, 'max_up_len': 80, 'dataset_class': 'TrafficStatePointDataset', 'executor': 'TrafficStateExecutor', 'evaluator': 'TrafficStateEvaluator', 'batch_size': 32, 'cache_dataset': True, 'num_workers': 0, 'pad_with_last_sample': True, 'train_rate': 0.7, 'eval_rate': 0.1, 'scaler': 'minmax01', 'load_external': False, 'normal_external': False, 'ext_scaler': 'none', 'add_time_in_day': False, 'add_day_in_week': False, 'robustness_test': False, 'noise_type': 'gaussian', 'disturb_rate': 0.5, 'noise_mean': [5], 'noise_SD': [10], 'gpu': True, 'gpu_id': 0, 'max_epoch': 100, 'train_loss': 'none', 'epoch': 0, 'learner': 'adam', 'learning_rate': 0.01, 'weight_decay': 0, 'lr_epsilon': 1e-08, 'lr_beta1': 0.9, 'lr_beta2': 0.999, 'lr_alpha': 0.99, 'lr_momentum': 0, 'lr_decay': False, 'lr_scheduler': 'multisteplr', 'lr_decay_ratio': 0.1, 'steps': [5, 20, 40, 70], 'step_size': 10, 'lr_T_max': 30, 'lr_eta_min': 0, 'lr_patience': 10, 'lr_threshold': 0.0001, 'clip_grad_norm': False, 'max_grad_norm': 1.0, 'use_early_stop': True, 'patience': 10, 'log_level': 'INFO', 'log_every': 1, 'load_best_epoch': True, 'hyper_tune': False, 'metrics': ['MAE', 'MAPE', 'MSE', 'RMSE', 'masked_MAE', 'masked_MAPE', 'masked_MSE', 'masked_RMSE', 'R2', 'EVAR'], 'evaluator_mode': 'single', 'save_mode': ['csv'], 'geo': {'including_types': ['Point'], 'Point': {}}, 'rel': {'including_types': ['geo'], 'geo': {'cost': 'num'}}, 'dyna': {'including_types': ['state'], 'state': {'entity_id': 'geo_id', 'traffic_speed': 'num'}}, 'data_col': ['traffic_speed'], 'weight_col': 'cost', 'data_files': ['PEMS_BAY'], 'geo_file': 'PEMS_BAY', 'rel_file': 'PEMS_BAY', 'output_dim': 1, 'time_intervals': 300, 'init_weight_inf_or_zero': 'inf', 'set_weight_link_or_dist': 'dist', 'calculate_weight_adj': True, 'weight_adj_epsilon': 0.1, 'exp_id': 39082}\n",
      "self.scaler_type  minmax01\n",
      "2024-07-21 11:55:16,303 - INFO - Loaded file PEMS_BAY.geo, num_nodes=325\n",
      "2024-07-21 11:55:16,313 - INFO - set_weight_link_or_dist: dist\n",
      "2024-07-21 11:55:16,314 - INFO - init_weight_inf_or_zero: inf\n",
      "2024-07-21 11:55:16,328 - INFO - Loaded file PEMS_BAY.rel, shape=(325, 325)\n",
      "2024-07-21 11:55:16,329 - INFO - Start Calculate the weight by Gauss kernel!\n",
      "2024-07-21 11:55:16,332 - INFO - Loading ./libcity/cache/dataset_cache/point_based_PEMS_BAY_48_6_0.7_0.1_minmax01_32_False_False_False_True.npz\n",
      "2024-07-21 11:55:46,652 - INFO - train\tx: (36444, 48, 325, 1), y: (36444, 6, 325, 1)\n",
      "2024-07-21 11:55:46,653 - INFO - eval\tx: (5206, 48, 325, 1), y: (5206, 6, 325, 1)\n",
      "2024-07-21 11:55:46,653 - INFO - test\tx: (10413, 48, 325, 1), y: (10413, 6, 325, 1)\n",
      "2024-07-21 11:55:47,536 - INFO - MinMax01Scaler max: 85.1, min: 0.0\n",
      "2024-07-21 11:55:47,537 - INFO - NoneScaler\n",
      "2024-07-21 11:55:53.521185: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-07-21 11:55:53.573380: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-21 11:55:53.573444: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-21 11:55:53.574867: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-07-21 11:55:53.582954: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-21 11:55:54.907425: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-07-21 11:55:56,259 - INFO - HierAttnLstm(\n",
      "  (lstm_cells): ModuleList(\n",
      "    (0): LSTMCell(325, 64)\n",
      "    (1-2): 2 x LSTMCell(64, 64)\n",
      "  )\n",
      "  (hidden_state_pooling): ModuleList(\n",
      "    (0-1): 2 x SelfAttentionPooling(\n",
      "      (W): Linear(in_features=64, out_features=1, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (cell_state_pooling): ModuleList(\n",
      "    (0-1): 2 x SelfAttentionPooling(\n",
      "      (W): Linear(in_features=64, out_features=1, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (self_attention): SelfAttention(\n",
      "    (ut_dense): Sequential(\n",
      "      (0): Linear(in_features=64, out_features=64, bias=True)\n",
      "      (1): Tanh()\n",
      "    )\n",
      "    (et_dense): Linear(in_features=64, out_features=3, bias=True)\n",
      "    (softmax): Softmax(dim=-1)\n",
      "  )\n",
      "  (fc_layer): Sequential(\n",
      "    (0): Linear(in_features=192, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=325, bias=True)\n",
      "  )\n",
      ")\n",
      "2024-07-21 11:55:56,260 - INFO - lstm_cells.0.weight_ih\ttorch.Size([256, 325])\tcuda:0\tTrue\n",
      "2024-07-21 11:55:56,260 - INFO - lstm_cells.0.weight_hh\ttorch.Size([256, 64])\tcuda:0\tTrue\n",
      "2024-07-21 11:55:56,261 - INFO - lstm_cells.0.bias_ih\ttorch.Size([256])\tcuda:0\tTrue\n",
      "2024-07-21 11:55:56,261 - INFO - lstm_cells.0.bias_hh\ttorch.Size([256])\tcuda:0\tTrue\n",
      "2024-07-21 11:55:56,261 - INFO - lstm_cells.1.weight_ih\ttorch.Size([256, 64])\tcuda:0\tTrue\n",
      "2024-07-21 11:55:56,261 - INFO - lstm_cells.1.weight_hh\ttorch.Size([256, 64])\tcuda:0\tTrue\n",
      "2024-07-21 11:55:56,261 - INFO - lstm_cells.1.bias_ih\ttorch.Size([256])\tcuda:0\tTrue\n",
      "2024-07-21 11:55:56,261 - INFO - lstm_cells.1.bias_hh\ttorch.Size([256])\tcuda:0\tTrue\n",
      "2024-07-21 11:55:56,261 - INFO - lstm_cells.2.weight_ih\ttorch.Size([256, 64])\tcuda:0\tTrue\n",
      "2024-07-21 11:55:56,261 - INFO - lstm_cells.2.weight_hh\ttorch.Size([256, 64])\tcuda:0\tTrue\n",
      "2024-07-21 11:55:56,261 - INFO - lstm_cells.2.bias_ih\ttorch.Size([256])\tcuda:0\tTrue\n",
      "2024-07-21 11:55:56,262 - INFO - lstm_cells.2.bias_hh\ttorch.Size([256])\tcuda:0\tTrue\n",
      "2024-07-21 11:55:56,262 - INFO - hidden_state_pooling.0.W.weight\ttorch.Size([1, 64])\tcuda:0\tTrue\n",
      "2024-07-21 11:55:56,262 - INFO - hidden_state_pooling.0.W.bias\ttorch.Size([1])\tcuda:0\tTrue\n",
      "2024-07-21 11:55:56,262 - INFO - hidden_state_pooling.1.W.weight\ttorch.Size([1, 64])\tcuda:0\tTrue\n",
      "2024-07-21 11:55:56,262 - INFO - hidden_state_pooling.1.W.bias\ttorch.Size([1])\tcuda:0\tTrue\n",
      "2024-07-21 11:55:56,262 - INFO - cell_state_pooling.0.W.weight\ttorch.Size([1, 64])\tcuda:0\tTrue\n",
      "2024-07-21 11:55:56,262 - INFO - cell_state_pooling.0.W.bias\ttorch.Size([1])\tcuda:0\tTrue\n",
      "2024-07-21 11:55:56,262 - INFO - cell_state_pooling.1.W.weight\ttorch.Size([1, 64])\tcuda:0\tTrue\n",
      "2024-07-21 11:55:56,262 - INFO - cell_state_pooling.1.W.bias\ttorch.Size([1])\tcuda:0\tTrue\n",
      "2024-07-21 11:55:56,262 - INFO - self_attention.ut_dense.0.weight\ttorch.Size([64, 64])\tcuda:0\tTrue\n",
      "2024-07-21 11:55:56,263 - INFO - self_attention.ut_dense.0.bias\ttorch.Size([64])\tcuda:0\tTrue\n",
      "2024-07-21 11:55:56,263 - INFO - self_attention.et_dense.weight\ttorch.Size([3, 64])\tcuda:0\tTrue\n",
      "2024-07-21 11:55:56,263 - INFO - self_attention.et_dense.bias\ttorch.Size([3])\tcuda:0\tTrue\n",
      "2024-07-21 11:55:56,263 - INFO - fc_layer.0.weight\ttorch.Size([512, 192])\tcuda:0\tTrue\n",
      "2024-07-21 11:55:56,263 - INFO - fc_layer.0.bias\ttorch.Size([512])\tcuda:0\tTrue\n",
      "2024-07-21 11:55:56,263 - INFO - fc_layer.2.weight\ttorch.Size([325, 512])\tcuda:0\tTrue\n",
      "2024-07-21 11:55:56,263 - INFO - fc_layer.2.bias\ttorch.Size([325])\tcuda:0\tTrue\n",
      "2024-07-21 11:55:56,263 - INFO - Total parameter numbers: 436812\n",
      "2024-07-21 11:55:56,263 - INFO - You select `adam` optimizer.\n",
      "2024-07-21 11:55:56,264 - WARNING - Received none train loss func and will use the loss func defined in the model.\n",
      "2024-07-21 11:55:56,264 - INFO - Start training ...\n",
      "2024-07-21 11:55:56,264 - INFO - num_batches:1139\n",
      "2024-07-21 12:00:41,351 - INFO - epoch complete!\n",
      "2024-07-21 12:00:41,351 - INFO - evaluating now!\n",
      "2024-07-21 12:00:53,220 - INFO - Epoch [0/100] train_loss: 4.5696, val_loss: 3.7822, lr: 0.010000, 296.96s\n",
      "2024-07-21 12:00:53,256 - INFO - Saved model at 0\n",
      "2024-07-21 12:00:53,257 - INFO - Val loss decrease from inf to 3.7822, saving to ./libcity/cache/39082/model_cache/HierAttnLstm_PEMS_BAY_epoch0.tar\n",
      "2024-07-21 12:05:37,581 - INFO - epoch complete!\n",
      "2024-07-21 12:05:37,582 - INFO - evaluating now!\n",
      "2024-07-21 12:05:49,539 - INFO - Epoch [1/100] train_loss: 2.8263, val_loss: 3.0449, lr: 0.010000, 296.28s\n",
      "2024-07-21 12:05:49,573 - INFO - Saved model at 1\n",
      "2024-07-21 12:05:49,573 - INFO - Val loss decrease from 3.7822 to 3.0449, saving to ./libcity/cache/39082/model_cache/HierAttnLstm_PEMS_BAY_epoch1.tar\n",
      "2024-07-21 12:10:33,872 - INFO - epoch complete!\n",
      "2024-07-21 12:10:33,873 - INFO - evaluating now!\n",
      "2024-07-21 12:10:45,865 - INFO - Epoch [2/100] train_loss: 2.5774, val_loss: 2.6628, lr: 0.010000, 296.29s\n",
      "2024-07-21 12:10:45,900 - INFO - Saved model at 2\n",
      "2024-07-21 12:10:45,900 - INFO - Val loss decrease from 3.0449 to 2.6628, saving to ./libcity/cache/39082/model_cache/HierAttnLstm_PEMS_BAY_epoch2.tar\n",
      "2024-07-21 12:15:29,805 - INFO - epoch complete!\n",
      "2024-07-21 12:15:29,806 - INFO - evaluating now!\n",
      "2024-07-21 12:15:41,808 - INFO - Epoch [3/100] train_loss: 2.5041, val_loss: 2.6936, lr: 0.010000, 295.91s\n",
      "2024-07-21 12:20:26,223 - INFO - epoch complete!\n",
      "2024-07-21 12:20:26,224 - INFO - evaluating now!\n",
      "2024-07-21 12:20:38,130 - INFO - Epoch [4/100] train_loss: 2.4122, val_loss: 2.5977, lr: 0.010000, 296.32s\n",
      "2024-07-21 12:20:38,163 - INFO - Saved model at 4\n",
      "2024-07-21 12:20:38,163 - INFO - Val loss decrease from 2.6628 to 2.5977, saving to ./libcity/cache/39082/model_cache/HierAttnLstm_PEMS_BAY_epoch4.tar\n",
      "2024-07-21 12:25:22,801 - INFO - epoch complete!\n",
      "2024-07-21 12:25:22,802 - INFO - evaluating now!\n",
      "2024-07-21 12:25:34,796 - INFO - Epoch [5/100] train_loss: 2.3795, val_loss: 2.5839, lr: 0.010000, 296.63s\n",
      "2024-07-21 12:25:34,829 - INFO - Saved model at 5\n",
      "2024-07-21 12:25:34,830 - INFO - Val loss decrease from 2.5977 to 2.5839, saving to ./libcity/cache/39082/model_cache/HierAttnLstm_PEMS_BAY_epoch5.tar\n",
      "2024-07-21 12:30:19,202 - INFO - epoch complete!\n",
      "2024-07-21 12:30:19,202 - INFO - evaluating now!\n",
      "2024-07-21 12:30:31,327 - INFO - Epoch [6/100] train_loss: 2.3523, val_loss: 2.6104, lr: 0.010000, 296.50s\n",
      "2024-07-21 12:35:15,544 - INFO - epoch complete!\n",
      "2024-07-21 12:35:15,544 - INFO - evaluating now!\n",
      "2024-07-21 12:35:27,468 - INFO - Epoch [7/100] train_loss: 2.3219, val_loss: 2.5891, lr: 0.010000, 296.14s\n",
      "2024-07-21 12:40:11,460 - INFO - epoch complete!\n",
      "2024-07-21 12:40:11,461 - INFO - evaluating now!\n",
      "2024-07-21 12:40:23,627 - INFO - Epoch [8/100] train_loss: 2.3073, val_loss: 2.5486, lr: 0.010000, 296.16s\n",
      "2024-07-21 12:40:23,662 - INFO - Saved model at 8\n",
      "2024-07-21 12:40:23,663 - INFO - Val loss decrease from 2.5839 to 2.5486, saving to ./libcity/cache/39082/model_cache/HierAttnLstm_PEMS_BAY_epoch8.tar\n",
      "2024-07-21 12:45:08,120 - INFO - epoch complete!\n",
      "2024-07-21 12:45:08,121 - INFO - evaluating now!\n",
      "2024-07-21 12:45:20,282 - INFO - Epoch [9/100] train_loss: 3.2444, val_loss: 3.0399, lr: 0.010000, 296.62s\n",
      "2024-07-21 12:50:05,376 - INFO - epoch complete!\n",
      "2024-07-21 12:50:05,377 - INFO - evaluating now!\n",
      "2024-07-21 12:50:17,440 - INFO - Epoch [10/100] train_loss: 2.7902, val_loss: 2.9090, lr: 0.010000, 297.16s\n",
      "2024-07-21 12:55:02,531 - INFO - epoch complete!\n",
      "2024-07-21 12:55:02,532 - INFO - evaluating now!\n",
      "2024-07-21 12:55:14,655 - INFO - Epoch [11/100] train_loss: 2.7513, val_loss: 2.9001, lr: 0.010000, 297.22s\n",
      "2024-07-21 12:59:58,978 - INFO - epoch complete!\n",
      "2024-07-21 12:59:58,979 - INFO - evaluating now!\n",
      "2024-07-21 13:00:11,155 - INFO - Epoch [12/100] train_loss: 2.7250, val_loss: 2.8588, lr: 0.010000, 296.50s\n",
      "2024-07-21 13:04:55,563 - INFO - epoch complete!\n",
      "2024-07-21 13:04:55,563 - INFO - evaluating now!\n",
      "2024-07-21 13:05:07,771 - INFO - Epoch [13/100] train_loss: 2.6928, val_loss: 2.8498, lr: 0.010000, 296.62s\n",
      "2024-07-21 13:09:51,909 - INFO - epoch complete!\n",
      "2024-07-21 13:09:51,910 - INFO - evaluating now!\n",
      "2024-07-21 13:10:03,885 - INFO - Epoch [14/100] train_loss: 2.6769, val_loss: 2.9131, lr: 0.010000, 296.11s\n",
      "2024-07-21 13:14:47,453 - INFO - epoch complete!\n",
      "2024-07-21 13:14:47,454 - INFO - evaluating now!\n",
      "2024-07-21 13:14:59,487 - INFO - Epoch [15/100] train_loss: 2.6687, val_loss: 2.8077, lr: 0.010000, 295.60s\n",
      "2024-07-21 13:19:42,990 - INFO - epoch complete!\n",
      "2024-07-21 13:19:42,990 - INFO - evaluating now!\n",
      "2024-07-21 13:19:55,011 - INFO - Epoch [16/100] train_loss: 2.6459, val_loss: 2.8568, lr: 0.010000, 295.52s\n",
      "2024-07-21 13:24:38,733 - INFO - epoch complete!\n",
      "2024-07-21 13:24:38,734 - INFO - evaluating now!\n",
      "2024-07-21 13:24:50,888 - INFO - Epoch [17/100] train_loss: 2.6271, val_loss: 2.8300, lr: 0.010000, 295.88s\n",
      "2024-07-21 13:29:31,366 - INFO - epoch complete!\n",
      "2024-07-21 13:29:31,367 - INFO - evaluating now!\n",
      "2024-07-21 13:29:43,110 - INFO - Epoch [18/100] train_loss: 2.6261, val_loss: 2.8224, lr: 0.010000, 292.22s\n",
      "2024-07-21 13:29:43,111 - WARNING - Early stopping at epoch: 18\n",
      "2024-07-21 13:29:43,111 - INFO - Trained totally 19 epochs, average train time is 284.106s, average eval time is 12.031s\n",
      "2024-07-21 13:29:43,129 - INFO - Loaded model at 8\n",
      "2024-07-21 13:29:43,130 - INFO - Saved model at ./libcity/cache/39082/model_cache/HierAttnLstm_PEMS_BAY.m\n",
      "2024-07-21 13:29:43,160 - INFO - Start evaluating ...\n",
      "2024-07-21 13:30:11,033 - INFO - Note that you select the single mode to evaluate!\n",
      "2024-07-21 13:30:11,043 - INFO - Evaluate result is saved at ./libcity/cache/39082/evaluate_cache/2024_07_21_13_30_11_HierAttnLstm_PEMS_BAY.csv\n",
      "2024-07-21 13:30:11,057 - INFO - \n",
      "        MAE  MAPE        MSE      RMSE  ...  masked_MSE  masked_RMSE        R2      EVAR\n",
      "1  2.587577   inf  28.241108  5.314236  ...   27.955952     5.287339  0.697228  0.708636\n",
      "2  2.587437   inf  28.239407  5.314076  ...   27.954252     5.287178  0.697241  0.708648\n",
      "3  2.587327   inf  28.238079  5.313951  ...   27.952925     5.287053  0.697252  0.708658\n",
      "4  2.587256   inf  28.237049  5.313854  ...   27.951895     5.286955  0.697261  0.708666\n",
      "5  2.587197   inf  28.235674  5.313725  ...   27.950516     5.286825  0.697273  0.708677\n",
      "6  2.587135   inf  28.234207  5.313587  ...   27.949055     5.286686  0.697285  0.708689\n",
      "\n",
      "[6 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "!python run_model.py --task traffic_state_pred --model HierAttnLstm --dataset PEMS_BAY --config_file HierAttnLstm_64_3_3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "T4cQwCFrFNlh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-21 13:30:15,877 - INFO - Log directory: ./libcity/log\n",
      "2024-07-21 13:30:15,878 - INFO - Begin pipeline, task=traffic_state_pred, model_name=HierAttnLstm, dataset_name=PEMS_BAY, exp_id=55796\n",
      "2024-07-21 13:30:15,879 - INFO - {'task': 'traffic_state_pred', 'model': 'HierAttnLstm', 'dataset': 'PEMS_BAY', 'saved_model': True, 'train': True, 'seed': 0, 'input_window': 48, 'output_window': 6, 'device': device(type='cuda', index=0), 'hidden_size': 64, 'num_layers': 3, 'dropout': 0.1, 'natt_hops': 4, 'nfc': 512, 'max_up_len': 80, 'dataset_class': 'TrafficStatePointDataset', 'executor': 'TrafficStateExecutor', 'evaluator': 'TrafficStateEvaluator', 'batch_size': 32, 'cache_dataset': True, 'num_workers': 0, 'pad_with_last_sample': True, 'train_rate': 0.7, 'eval_rate': 0.1, 'scaler': 'minmax01', 'load_external': False, 'normal_external': False, 'ext_scaler': 'none', 'add_time_in_day': False, 'add_day_in_week': False, 'robustness_test': False, 'noise_type': 'gaussian', 'disturb_rate': 0.5, 'noise_mean': [5], 'noise_SD': [10], 'gpu': True, 'gpu_id': 0, 'max_epoch': 100, 'train_loss': 'none', 'epoch': 0, 'learner': 'adam', 'learning_rate': 0.01, 'weight_decay': 0, 'lr_epsilon': 1e-08, 'lr_beta1': 0.9, 'lr_beta2': 0.999, 'lr_alpha': 0.99, 'lr_momentum': 0, 'lr_decay': False, 'lr_scheduler': 'multisteplr', 'lr_decay_ratio': 0.1, 'steps': [5, 20, 40, 70], 'step_size': 10, 'lr_T_max': 30, 'lr_eta_min': 0, 'lr_patience': 10, 'lr_threshold': 0.0001, 'clip_grad_norm': False, 'max_grad_norm': 1.0, 'use_early_stop': True, 'patience': 10, 'log_level': 'INFO', 'log_every': 1, 'load_best_epoch': True, 'hyper_tune': False, 'metrics': ['MAE', 'MAPE', 'MSE', 'RMSE', 'masked_MAE', 'masked_MAPE', 'masked_MSE', 'masked_RMSE', 'R2', 'EVAR'], 'evaluator_mode': 'single', 'save_mode': ['csv'], 'geo': {'including_types': ['Point'], 'Point': {}}, 'rel': {'including_types': ['geo'], 'geo': {'cost': 'num'}}, 'dyna': {'including_types': ['state'], 'state': {'entity_id': 'geo_id', 'traffic_speed': 'num'}}, 'data_col': ['traffic_speed'], 'weight_col': 'cost', 'data_files': ['PEMS_BAY'], 'geo_file': 'PEMS_BAY', 'rel_file': 'PEMS_BAY', 'output_dim': 1, 'time_intervals': 300, 'init_weight_inf_or_zero': 'inf', 'set_weight_link_or_dist': 'dist', 'calculate_weight_adj': True, 'weight_adj_epsilon': 0.1, 'exp_id': 55796}\n",
      "self.scaler_type  minmax01\n",
      "2024-07-21 13:30:15,911 - INFO - Loaded file PEMS_BAY.geo, num_nodes=325\n",
      "2024-07-21 13:30:15,921 - INFO - set_weight_link_or_dist: dist\n",
      "2024-07-21 13:30:15,921 - INFO - init_weight_inf_or_zero: inf\n",
      "2024-07-21 13:30:15,936 - INFO - Loaded file PEMS_BAY.rel, shape=(325, 325)\n",
      "2024-07-21 13:30:15,936 - INFO - Start Calculate the weight by Gauss kernel!\n",
      "2024-07-21 13:30:15,939 - INFO - Loading ./libcity/cache/dataset_cache/point_based_PEMS_BAY_48_6_0.7_0.1_minmax01_32_False_False_False_True.npz\n",
      "2024-07-21 13:30:45,903 - INFO - train\tx: (36444, 48, 325, 1), y: (36444, 6, 325, 1)\n",
      "2024-07-21 13:30:45,904 - INFO - eval\tx: (5206, 48, 325, 1), y: (5206, 6, 325, 1)\n",
      "2024-07-21 13:30:45,904 - INFO - test\tx: (10413, 48, 325, 1), y: (10413, 6, 325, 1)\n",
      "2024-07-21 13:30:46,743 - INFO - MinMax01Scaler max: 85.1, min: 0.0\n",
      "2024-07-21 13:30:46,744 - INFO - NoneScaler\n",
      "2024-07-21 13:30:52.596665: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-07-21 13:30:52.649036: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-21 13:30:52.649098: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-21 13:30:52.650643: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-07-21 13:30:52.658709: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-21 13:30:53.934552: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-07-21 13:30:55,216 - INFO - HierAttnLstm(\n",
      "  (lstm_cells): ModuleList(\n",
      "    (0): LSTMCell(325, 64)\n",
      "    (1-2): 2 x LSTMCell(64, 64)\n",
      "  )\n",
      "  (hidden_state_pooling): ModuleList(\n",
      "    (0-1): 2 x SelfAttentionPooling(\n",
      "      (W): Linear(in_features=64, out_features=1, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (cell_state_pooling): ModuleList(\n",
      "    (0-1): 2 x SelfAttentionPooling(\n",
      "      (W): Linear(in_features=64, out_features=1, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (self_attention): SelfAttention(\n",
      "    (ut_dense): Sequential(\n",
      "      (0): Linear(in_features=64, out_features=64, bias=True)\n",
      "      (1): Tanh()\n",
      "    )\n",
      "    (et_dense): Linear(in_features=64, out_features=4, bias=True)\n",
      "    (softmax): Softmax(dim=-1)\n",
      "  )\n",
      "  (fc_layer): Sequential(\n",
      "    (0): Linear(in_features=256, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=325, bias=True)\n",
      "  )\n",
      ")\n",
      "2024-07-21 13:30:55,217 - INFO - lstm_cells.0.weight_ih\ttorch.Size([256, 325])\tcuda:0\tTrue\n",
      "2024-07-21 13:30:55,217 - INFO - lstm_cells.0.weight_hh\ttorch.Size([256, 64])\tcuda:0\tTrue\n",
      "2024-07-21 13:30:55,217 - INFO - lstm_cells.0.bias_ih\ttorch.Size([256])\tcuda:0\tTrue\n",
      "2024-07-21 13:30:55,217 - INFO - lstm_cells.0.bias_hh\ttorch.Size([256])\tcuda:0\tTrue\n",
      "2024-07-21 13:30:55,217 - INFO - lstm_cells.1.weight_ih\ttorch.Size([256, 64])\tcuda:0\tTrue\n",
      "2024-07-21 13:30:55,217 - INFO - lstm_cells.1.weight_hh\ttorch.Size([256, 64])\tcuda:0\tTrue\n",
      "2024-07-21 13:30:55,218 - INFO - lstm_cells.1.bias_ih\ttorch.Size([256])\tcuda:0\tTrue\n",
      "2024-07-21 13:30:55,218 - INFO - lstm_cells.1.bias_hh\ttorch.Size([256])\tcuda:0\tTrue\n",
      "2024-07-21 13:30:55,218 - INFO - lstm_cells.2.weight_ih\ttorch.Size([256, 64])\tcuda:0\tTrue\n",
      "2024-07-21 13:30:55,218 - INFO - lstm_cells.2.weight_hh\ttorch.Size([256, 64])\tcuda:0\tTrue\n",
      "2024-07-21 13:30:55,218 - INFO - lstm_cells.2.bias_ih\ttorch.Size([256])\tcuda:0\tTrue\n",
      "2024-07-21 13:30:55,218 - INFO - lstm_cells.2.bias_hh\ttorch.Size([256])\tcuda:0\tTrue\n",
      "2024-07-21 13:30:55,218 - INFO - hidden_state_pooling.0.W.weight\ttorch.Size([1, 64])\tcuda:0\tTrue\n",
      "2024-07-21 13:30:55,218 - INFO - hidden_state_pooling.0.W.bias\ttorch.Size([1])\tcuda:0\tTrue\n",
      "2024-07-21 13:30:55,218 - INFO - hidden_state_pooling.1.W.weight\ttorch.Size([1, 64])\tcuda:0\tTrue\n",
      "2024-07-21 13:30:55,218 - INFO - hidden_state_pooling.1.W.bias\ttorch.Size([1])\tcuda:0\tTrue\n",
      "2024-07-21 13:30:55,218 - INFO - cell_state_pooling.0.W.weight\ttorch.Size([1, 64])\tcuda:0\tTrue\n",
      "2024-07-21 13:30:55,219 - INFO - cell_state_pooling.0.W.bias\ttorch.Size([1])\tcuda:0\tTrue\n",
      "2024-07-21 13:30:55,219 - INFO - cell_state_pooling.1.W.weight\ttorch.Size([1, 64])\tcuda:0\tTrue\n",
      "2024-07-21 13:30:55,219 - INFO - cell_state_pooling.1.W.bias\ttorch.Size([1])\tcuda:0\tTrue\n",
      "2024-07-21 13:30:55,219 - INFO - self_attention.ut_dense.0.weight\ttorch.Size([64, 64])\tcuda:0\tTrue\n",
      "2024-07-21 13:30:55,219 - INFO - self_attention.ut_dense.0.bias\ttorch.Size([64])\tcuda:0\tTrue\n",
      "2024-07-21 13:30:55,219 - INFO - self_attention.et_dense.weight\ttorch.Size([4, 64])\tcuda:0\tTrue\n",
      "2024-07-21 13:30:55,219 - INFO - self_attention.et_dense.bias\ttorch.Size([4])\tcuda:0\tTrue\n",
      "2024-07-21 13:30:55,219 - INFO - fc_layer.0.weight\ttorch.Size([512, 256])\tcuda:0\tTrue\n",
      "2024-07-21 13:30:55,219 - INFO - fc_layer.0.bias\ttorch.Size([512])\tcuda:0\tTrue\n",
      "2024-07-21 13:30:55,219 - INFO - fc_layer.2.weight\ttorch.Size([325, 512])\tcuda:0\tTrue\n",
      "2024-07-21 13:30:55,220 - INFO - fc_layer.2.bias\ttorch.Size([325])\tcuda:0\tTrue\n",
      "2024-07-21 13:30:55,220 - INFO - Total parameter numbers: 469645\n",
      "2024-07-21 13:30:55,220 - INFO - You select `adam` optimizer.\n",
      "2024-07-21 13:30:55,221 - WARNING - Received none train loss func and will use the loss func defined in the model.\n",
      "2024-07-21 13:30:55,221 - INFO - Start training ...\n",
      "2024-07-21 13:30:55,221 - INFO - num_batches:1139\n",
      "2024-07-21 13:35:35,662 - INFO - epoch complete!\n",
      "2024-07-21 13:35:35,662 - INFO - evaluating now!\n",
      "2024-07-21 13:35:47,245 - INFO - Epoch [0/100] train_loss: 4.9902, val_loss: 4.3381, lr: 0.010000, 292.02s\n",
      "2024-07-21 13:35:47,295 - INFO - Saved model at 0\n",
      "2024-07-21 13:35:47,295 - INFO - Val loss decrease from inf to 4.3381, saving to ./libcity/cache/55796/model_cache/HierAttnLstm_PEMS_BAY_epoch0.tar\n",
      "2024-07-21 13:40:27,673 - INFO - epoch complete!\n",
      "2024-07-21 13:40:27,674 - INFO - evaluating now!\n",
      "2024-07-21 13:40:39,349 - INFO - Epoch [1/100] train_loss: 3.4318, val_loss: 3.2712, lr: 0.010000, 292.05s\n",
      "2024-07-21 13:40:39,384 - INFO - Saved model at 1\n",
      "2024-07-21 13:40:39,384 - INFO - Val loss decrease from 4.3381 to 3.2712, saving to ./libcity/cache/55796/model_cache/HierAttnLstm_PEMS_BAY_epoch1.tar\n",
      "2024-07-21 13:45:18,854 - INFO - epoch complete!\n",
      "2024-07-21 13:45:18,855 - INFO - evaluating now!\n",
      "2024-07-21 13:45:30,504 - INFO - Epoch [2/100] train_loss: 2.8378, val_loss: 2.7085, lr: 0.010000, 291.12s\n",
      "2024-07-21 13:45:30,538 - INFO - Saved model at 2\n",
      "2024-07-21 13:45:30,538 - INFO - Val loss decrease from 3.2712 to 2.7085, saving to ./libcity/cache/55796/model_cache/HierAttnLstm_PEMS_BAY_epoch2.tar\n",
      "2024-07-21 13:50:11,261 - INFO - epoch complete!\n",
      "2024-07-21 13:50:11,261 - INFO - evaluating now!\n",
      "2024-07-21 13:50:22,825 - INFO - Epoch [3/100] train_loss: 2.6276, val_loss: 2.6887, lr: 0.010000, 292.29s\n",
      "2024-07-21 13:50:22,857 - INFO - Saved model at 3\n",
      "2024-07-21 13:50:22,857 - INFO - Val loss decrease from 2.7085 to 2.6887, saving to ./libcity/cache/55796/model_cache/HierAttnLstm_PEMS_BAY_epoch3.tar\n",
      "2024-07-21 13:55:01,864 - INFO - epoch complete!\n",
      "2024-07-21 13:55:01,864 - INFO - evaluating now!\n",
      "2024-07-21 13:55:13,269 - INFO - Epoch [4/100] train_loss: 2.5235, val_loss: 2.6631, lr: 0.010000, 290.41s\n",
      "2024-07-21 13:55:13,302 - INFO - Saved model at 4\n",
      "2024-07-21 13:55:13,303 - INFO - Val loss decrease from 2.6887 to 2.6631, saving to ./libcity/cache/55796/model_cache/HierAttnLstm_PEMS_BAY_epoch4.tar\n",
      "2024-07-21 13:59:44,473 - INFO - epoch complete!\n",
      "2024-07-21 13:59:44,473 - INFO - evaluating now!\n",
      "2024-07-21 13:59:55,827 - INFO - Epoch [5/100] train_loss: 2.4728, val_loss: 2.6018, lr: 0.010000, 282.52s\n",
      "2024-07-21 13:59:55,859 - INFO - Saved model at 5\n",
      "2024-07-21 13:59:55,859 - INFO - Val loss decrease from 2.6631 to 2.6018, saving to ./libcity/cache/55796/model_cache/HierAttnLstm_PEMS_BAY_epoch5.tar\n",
      "2024-07-21 14:04:27,757 - INFO - epoch complete!\n",
      "2024-07-21 14:04:27,758 - INFO - evaluating now!\n",
      "2024-07-21 14:04:39,153 - INFO - Epoch [6/100] train_loss: 2.4802, val_loss: 2.7607, lr: 0.010000, 283.29s\n",
      "2024-07-21 14:09:11,748 - INFO - epoch complete!\n",
      "2024-07-21 14:09:11,748 - INFO - evaluating now!\n",
      "2024-07-21 14:09:23,203 - INFO - Epoch [7/100] train_loss: 2.4415, val_loss: 2.6681, lr: 0.010000, 284.05s\n",
      "2024-07-21 14:13:57,073 - INFO - epoch complete!\n",
      "2024-07-21 14:13:57,073 - INFO - evaluating now!\n",
      "2024-07-21 14:14:08,667 - INFO - Epoch [8/100] train_loss: 2.4190, val_loss: 2.5893, lr: 0.010000, 285.46s\n",
      "2024-07-21 14:14:08,701 - INFO - Saved model at 8\n",
      "2024-07-21 14:14:08,702 - INFO - Val loss decrease from 2.6018 to 2.5893, saving to ./libcity/cache/55796/model_cache/HierAttnLstm_PEMS_BAY_epoch8.tar\n",
      "2024-07-21 14:18:41,863 - INFO - epoch complete!\n",
      "2024-07-21 14:18:41,864 - INFO - evaluating now!\n",
      "2024-07-21 14:18:53,327 - INFO - Epoch [9/100] train_loss: 2.4126, val_loss: 2.5670, lr: 0.010000, 284.62s\n",
      "2024-07-21 14:18:53,374 - INFO - Saved model at 9\n",
      "2024-07-21 14:18:53,374 - INFO - Val loss decrease from 2.5893 to 2.5670, saving to ./libcity/cache/55796/model_cache/HierAttnLstm_PEMS_BAY_epoch9.tar\n",
      "2024-07-21 14:23:26,461 - INFO - epoch complete!\n",
      "2024-07-21 14:23:26,462 - INFO - evaluating now!\n",
      "2024-07-21 14:23:37,875 - INFO - Epoch [10/100] train_loss: 2.3879, val_loss: 4.4965, lr: 0.010000, 284.50s\n",
      "2024-07-21 14:28:10,977 - INFO - epoch complete!\n",
      "2024-07-21 14:28:10,977 - INFO - evaluating now!\n",
      "2024-07-21 14:28:22,434 - INFO - Epoch [11/100] train_loss: 2.4424, val_loss: 2.5775, lr: 0.010000, 284.56s\n",
      "2024-07-21 14:32:54,917 - INFO - epoch complete!\n",
      "2024-07-21 14:32:54,918 - INFO - evaluating now!\n",
      "2024-07-21 14:33:06,427 - INFO - Epoch [12/100] train_loss: 2.3763, val_loss: 2.5911, lr: 0.010000, 283.99s\n",
      "2024-07-21 14:37:39,819 - INFO - epoch complete!\n",
      "2024-07-21 14:37:39,820 - INFO - evaluating now!\n",
      "2024-07-21 14:37:51,197 - INFO - Epoch [13/100] train_loss: 2.4285, val_loss: 2.7281, lr: 0.010000, 284.77s\n",
      "2024-07-21 14:42:24,695 - INFO - epoch complete!\n",
      "2024-07-21 14:42:24,696 - INFO - evaluating now!\n",
      "2024-07-21 14:42:36,292 - INFO - Epoch [14/100] train_loss: 2.4380, val_loss: 2.5705, lr: 0.010000, 285.09s\n",
      "2024-07-21 14:47:11,725 - INFO - epoch complete!\n",
      "2024-07-21 14:47:11,726 - INFO - evaluating now!\n",
      "2024-07-21 14:47:23,156 - INFO - Epoch [15/100] train_loss: 2.4267, val_loss: 2.6063, lr: 0.010000, 286.86s\n",
      "2024-07-21 14:52:01,112 - INFO - epoch complete!\n",
      "2024-07-21 14:52:01,112 - INFO - evaluating now!\n",
      "2024-07-21 14:52:12,775 - INFO - Epoch [16/100] train_loss: 2.4448, val_loss: 2.6062, lr: 0.010000, 289.62s\n",
      "2024-07-21 14:56:50,572 - INFO - epoch complete!\n",
      "2024-07-21 14:56:50,573 - INFO - evaluating now!\n",
      "2024-07-21 14:57:02,169 - INFO - Epoch [17/100] train_loss: 2.3825, val_loss: 2.6615, lr: 0.010000, 289.39s\n",
      "2024-07-21 15:01:38,442 - INFO - epoch complete!\n",
      "2024-07-21 15:01:38,443 - INFO - evaluating now!\n",
      "2024-07-21 15:01:50,026 - INFO - Epoch [18/100] train_loss: 2.3862, val_loss: 2.6532, lr: 0.010000, 287.86s\n",
      "2024-07-21 15:06:27,069 - INFO - epoch complete!\n",
      "2024-07-21 15:06:27,070 - INFO - evaluating now!\n",
      "2024-07-21 15:06:38,627 - INFO - Epoch [19/100] train_loss: 2.4404, val_loss: 2.6038, lr: 0.010000, 288.60s\n",
      "2024-07-21 15:06:38,628 - WARNING - Early stopping at epoch: 19\n",
      "2024-07-21 15:06:38,628 - INFO - Trained totally 20 epochs, average train time is 275.638s, average eval time is 11.516s\n",
      "2024-07-21 15:06:38,650 - INFO - Loaded model at 9\n",
      "2024-07-21 15:06:38,651 - INFO - Saved model at ./libcity/cache/55796/model_cache/HierAttnLstm_PEMS_BAY.m\n",
      "2024-07-21 15:06:38,686 - INFO - Start evaluating ...\n",
      "2024-07-21 15:07:07,019 - INFO - Note that you select the single mode to evaluate!\n",
      "2024-07-21 15:07:07,026 - INFO - Evaluate result is saved at ./libcity/cache/55796/evaluate_cache/2024_07_21_15_07_07_HierAttnLstm_PEMS_BAY.csv\n",
      "2024-07-21 15:07:07,040 - INFO - \n",
      "        MAE  MAPE        MSE      RMSE  ...  masked_MSE  masked_RMSE        R2      EVAR\n",
      "1  2.602143   inf  28.719612  5.359068  ...   28.436010     5.332542  0.692098  0.696334\n",
      "2  2.602022   inf  28.718040  5.358922  ...   28.434441     5.332396  0.692109  0.696346\n",
      "3  2.601925   inf  28.716768  5.358803  ...   28.433168     5.332276  0.692120  0.696357\n",
      "4  2.601845   inf  28.715660  5.358699  ...   28.432062     5.332172  0.692130  0.696367\n",
      "5  2.601763   inf  28.714214  5.358564  ...   28.430616     5.332037  0.692142  0.696380\n",
      "6  2.601667   inf  28.712683  5.358422  ...   28.429079     5.331892  0.692155  0.696394\n",
      "\n",
      "[6 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "!python run_model.py --task traffic_state_pred --model HierAttnLstm --dataset PEMS_BAY --config_file HierAttnLstm_64_3_4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qtkcIXLPFOtZ"
   },
   "outputs": [],
   "source": [
    "!python run_model.py --task traffic_state_pred --model HierAttnLstm --dataset PEMS_BAY --config_file HierAttnLstm_64_4_2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ikb8tqh1FQDV"
   },
   "outputs": [],
   "source": [
    "!python run_model.py --task traffic_state_pred --model HierAttnLstm --dataset PEMS_BAY --config_file HierAttnLstm_64_4_3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A7GctZ8SFRa4"
   },
   "outputs": [],
   "source": [
    "!python run_model.py --task traffic_state_pred --model HierAttnLstm --dataset PEMS_BAY --config_file HierAttnLstm_64_4_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running: python run_model.py --task traffic_state_pred --model HierAttnLstm --dataset PEMS_BAY --config_file HierAttnLstm_64_2_2.json\n",
      "Output saved to output_HierAttnLstm_64_2_2.txt\n",
      "Running: python run_model.py --task traffic_state_pred --model HierAttnLstm --dataset PEMS_BAY --config_file HierAttnLstm_64_2_3.json\n",
      "Output saved to output_HierAttnLstm_64_2_3.txt\n",
      "Running: python run_model.py --task traffic_state_pred --model HierAttnLstm --dataset PEMS_BAY --config_file HierAttnLstm_64_3_2.json\n",
      "Output saved to output_HierAttnLstm_64_3_2.txt\n",
      "Running: python run_model.py --task traffic_state_pred --model HierAttnLstm --dataset PEMS_BAY --config_file HierAttnLstm_64_3_3.json\n",
      "Output saved to output_HierAttnLstm_64_3_3.txt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 35\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOutput saved to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_filename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m# Pause before running the next command (optional)\u001b[39;00m\n\u001b[1;32m---> 35\u001b[0m \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import subprocess\n",
    "\n",
    "hidden_sizes = [64, 128] #, 256]  # Reduced for demonstration\n",
    "num_layers = [2, 3] #, 4]\n",
    "natt_hops = [2, 3] #, 4]\n",
    "\n",
    "for hs in hidden_sizes:\n",
    "    for nl in num_layers:\n",
    "        for nh in natt_hops:\n",
    "            # Command to run\n",
    "            cmd = f\"python run_model.py --task traffic_state_pred --model HierAttnLstm --dataset PEMS_BAY --config_file HierAttnLstm_{hs}_{nl}_{nh}.json\"\n",
    "\n",
    "            # Print the command for clarity\n",
    "            print(f\"Running: {cmd}\")\n",
    "\n",
    "            # Execute the command and capture the output\n",
    "            result = subprocess.run(cmd, shell=True, capture_output=True, text=True)\n",
    "\n",
    "            # Create filename for output\n",
    "            output_filename = f\"output_HierAttnLstm_{hs}_{nl}_{nh}.txt\"\n",
    "\n",
    "            # Save the output (stdout and stderr) to the file\n",
    "            with open(output_filename, \"w\") as outfile:\n",
    "                outfile.write(f\"Command:\\n{cmd}\\n\\n\")\n",
    "                outfile.write(\"Standard Output:\\n\")\n",
    "                outfile.write(result.stdout)\n",
    "                outfile.write(\"\\nStandard Error:\\n\")\n",
    "                outfile.write(result.stderr)\n",
    "\n",
    "            print(f\"Output saved to {output_filename}\")\n",
    "\n",
    "            # Pause before running the next command (optional)\n",
    "            time.sleep(5)  # Adjust the sleep time as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPSbGirZmcusfUdZcE7sG2W",
   "gpuType": "A100",
   "machine_shape": "hm",
   "mount_file_id": "1g1lZfDtZzxU9Mfi4YujQlN21BuHxZHfw",
   "name": "",
   "version": ""
  },
  "kernelspec": {
   "display_name": "python3.10",
   "language": "python",
   "name": "python3.10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
