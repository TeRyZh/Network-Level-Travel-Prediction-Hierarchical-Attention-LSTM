Command:
python run_model.py --task traffic_state_pred --model HierAttnLstm --dataset PEMSD8 --config_file HierAttnLstm_OW_9 --exp_id 00010

Standard Output:
2024-07-25 09:54:22,014 - INFO - Log directory: ./libcity/log
2024-07-25 09:54:22,014 - INFO - Begin pipeline, task=traffic_state_pred, model_name=HierAttnLstm, dataset_name=PEMSD8, exp_id=00010
2024-07-25 09:54:22,015 - INFO - {'task': 'traffic_state_pred', 'model': 'HierAttnLstm', 'dataset': 'PEMSD8', 'saved_model': True, 'train': True, 'exp_id': '00010', 'seed': 0, 'input_window': 48, 'output_window': 9, 'device': device(type='cuda', index=0), 'hidden_size': 128, 'num_layers': 3, 'dropout': 0.1, 'natt_hops': 3, 'nfc': 512, 'max_up_len': 96, 'dataset_class': 'TrafficStatePointDataset', 'executor': 'TrafficStateExecutor', 'evaluator': 'TrafficStateEvaluator', 'batch_size': 32, 'cache_dataset': True, 'num_workers': 0, 'pad_with_last_sample': True, 'train_rate': 0.7, 'eval_rate': 0.1, 'scaler': 'minmax01', 'load_external': False, 'normal_external': False, 'ext_scaler': 'none', 'add_time_in_day': False, 'add_day_in_week': False, 'robustness_test': False, 'noise_type': 'gaussian', 'disturb_rate': 0.5, 'noise_mean': [5], 'noise_SD': [10], 'gpu': True, 'gpu_id': 0, 'max_epoch': 100, 'train_loss': 'none', 'epoch': 0, 'learner': 'adam', 'learning_rate': 0.01, 'weight_decay': 0, 'lr_epsilon': 1e-08, 'lr_beta1': 0.9, 'lr_beta2': 0.999, 'lr_alpha': 0.99, 'lr_momentum': 0, 'lr_decay': False, 'lr_scheduler': 'multisteplr', 'lr_decay_ratio': 0.1, 'steps': [5, 20, 40, 70], 'step_size': 10, 'lr_T_max': 30, 'lr_eta_min': 0, 'lr_patience': 10, 'lr_threshold': 0.0001, 'clip_grad_norm': False, 'max_grad_norm': 1.0, 'use_early_stop': True, 'patience': 5, 'log_level': 'INFO', 'log_every': 1, 'load_best_epoch': True, 'hyper_tune': False, 'metrics': ['MAE', 'MAPE', 'MSE', 'RMSE', 'masked_MAE', 'masked_MAPE', 'masked_MSE', 'masked_RMSE', 'R2', 'EVAR'], 'evaluator_mode': 'single', 'save_mode': ['csv'], 'geo': {'including_types': ['Point'], 'Point': {}}, 'rel': {'including_types': ['geo'], 'geo': {'cost': 'num'}}, 'dyna': {'including_types': ['state'], 'state': {'entity_id': 'geo_id', 'traffic_flow': 'num', 'traffic_occupancy': 'num', 'traffic_speed': 'num'}}, 'data_col': ['traffic_flow', 'traffic_occupancy', 'traffic_speed'], 'weight_col': 'cost', 'data_files': ['PEMSD8'], 'geo_file': 'PEMSD8', 'rel_file': 'PEMSD8', 'output_dim': 3, 'time_intervals': 300, 'init_weight_inf_or_zero': 'zero', 'set_weight_link_or_dist': 'link', 'calculate_weight_adj': False, 'weight_adj_epsilon': 0.1}
self.scaler_type  minmax01
2024-07-25 09:54:22,024 - INFO - Loaded file PEMSD8.geo, num_nodes=170
2024-07-25 09:54:22,041 - INFO - set_weight_link_or_dist: link
2024-07-25 09:54:22,041 - INFO - init_weight_inf_or_zero: zero
2024-07-25 09:54:22,043 - INFO - Loaded file PEMSD8.rel, shape=(170, 170)
2024-07-25 09:54:22,043 - INFO - Loading file PEMSD8.dyna
2024-07-25 09:54:23,630 - INFO - Loaded file PEMSD8.dyna, shape=(17856, 170, 3)
2024-07-25 09:54:42,824 - INFO - Dataset created
2024-07-25 09:54:42,824 - INFO - x shape: (17800, 48, 170, 3), y shape: (17800, 9, 170, 3)
2024-07-25 09:54:42,946 - INFO - train	x: (12460, 48, 170, 3), y: (12460, 9, 170, 3)
2024-07-25 09:54:42,947 - INFO - eval	x: (1780, 48, 170, 3), y: (1780, 9, 170, 3)
2024-07-25 09:54:42,947 - INFO - test	x: (3560, 48, 170, 3), y: (3560, 9, 170, 3)
2024-07-25 09:56:47,726 - INFO - Saved at ./libcity/cache/dataset_cache/point_based_PEMSD8_48_9_0.7_0.1_minmax01_32_False_False_False_True.npz
2024-07-25 09:56:48,144 - INFO - MinMax01Scaler max: 1147.0, min: 0.0
2024-07-25 09:56:48,144 - INFO - NoneScaler
2024-07-25 09:56:51,805 - INFO - HierAttnLstm(
  (lstm_cells): ModuleList(
    (0): LSTMCell(510, 128)
    (1-2): 2 x LSTMCell(128, 128)
  )
  (hidden_state_pooling): ModuleList(
    (0-1): 2 x SelfAttentionPooling(
      (W): Linear(in_features=128, out_features=1, bias=True)
    )
  )
  (cell_state_pooling): ModuleList(
    (0-1): 2 x SelfAttentionPooling(
      (W): Linear(in_features=128, out_features=1, bias=True)
    )
  )
  (self_attention): SelfAttention(
    (ut_dense): Sequential(
      (0): Linear(in_features=128, out_features=128, bias=True)
      (1): Tanh()
    )
    (et_dense): Linear(in_features=128, out_features=3, bias=True)
    (softmax): Softmax(dim=-1)
  )
  (fc_layer): Sequential(
    (0): Linear(in_features=384, out_features=512, bias=True)
    (1): ReLU()
    (2): Linear(in_features=512, out_features=510, bias=True)
  )
)
2024-07-25 09:56:51,805 - INFO - lstm_cells.0.weight_ih	torch.Size([512, 510])	cuda:0	True
2024-07-25 09:56:51,805 - INFO - lstm_cells.0.weight_hh	torch.Size([512, 128])	cuda:0	True
2024-07-25 09:56:51,805 - INFO - lstm_cells.0.bias_ih	torch.Size([512])	cuda:0	True
2024-07-25 09:56:51,805 - INFO - lstm_cells.0.bias_hh	torch.Size([512])	cuda:0	True
2024-07-25 09:56:51,805 - INFO - lstm_cells.1.weight_ih	torch.Size([512, 128])	cuda:0	True
2024-07-25 09:56:51,805 - INFO - lstm_cells.1.weight_hh	torch.Size([512, 128])	cuda:0	True
2024-07-25 09:56:51,805 - INFO - lstm_cells.1.bias_ih	torch.Size([512])	cuda:0	True
2024-07-25 09:56:51,805 - INFO - lstm_cells.1.bias_hh	torch.Size([512])	cuda:0	True
2024-07-25 09:56:51,806 - INFO - lstm_cells.2.weight_ih	torch.Size([512, 128])	cuda:0	True
2024-07-25 09:56:51,806 - INFO - lstm_cells.2.weight_hh	torch.Size([512, 128])	cuda:0	True
2024-07-25 09:56:51,806 - INFO - lstm_cells.2.bias_ih	torch.Size([512])	cuda:0	True
2024-07-25 09:56:51,806 - INFO - lstm_cells.2.bias_hh	torch.Size([512])	cuda:0	True
2024-07-25 09:56:51,806 - INFO - hidden_state_pooling.0.W.weight	torch.Size([1, 128])	cuda:0	True
2024-07-25 09:56:51,806 - INFO - hidden_state_pooling.0.W.bias	torch.Size([1])	cuda:0	True
2024-07-25 09:56:51,806 - INFO - hidden_state_pooling.1.W.weight	torch.Size([1, 128])	cuda:0	True
2024-07-25 09:56:51,806 - INFO - hidden_state_pooling.1.W.bias	torch.Size([1])	cuda:0	True
2024-07-25 09:56:51,806 - INFO - cell_state_pooling.0.W.weight	torch.Size([1, 128])	cuda:0	True
2024-07-25 09:56:51,806 - INFO - cell_state_pooling.0.W.bias	torch.Size([1])	cuda:0	True
2024-07-25 09:56:51,806 - INFO - cell_state_pooling.1.W.weight	torch.Size([1, 128])	cuda:0	True
2024-07-25 09:56:51,806 - INFO - cell_state_pooling.1.W.bias	torch.Size([1])	cuda:0	True
2024-07-25 09:56:51,806 - INFO - self_attention.ut_dense.0.weight	torch.Size([128, 128])	cuda:0	True
2024-07-25 09:56:51,806 - INFO - self_attention.ut_dense.0.bias	torch.Size([128])	cuda:0	True
2024-07-25 09:56:51,807 - INFO - self_attention.et_dense.weight	torch.Size([3, 128])	cuda:0	True
2024-07-25 09:56:51,807 - INFO - self_attention.et_dense.bias	torch.Size([3])	cuda:0	True
2024-07-25 09:56:51,807 - INFO - fc_layer.0.weight	torch.Size([512, 384])	cuda:0	True
2024-07-25 09:56:51,807 - INFO - fc_layer.0.bias	torch.Size([512])	cuda:0	True
2024-07-25 09:56:51,807 - INFO - fc_layer.2.weight	torch.Size([510, 512])	cuda:0	True
2024-07-25 09:56:51,807 - INFO - fc_layer.2.bias	torch.Size([510])	cuda:0	True
2024-07-25 09:56:51,807 - INFO - Total parameter numbers: 1068037
2024-07-25 09:56:51,807 - INFO - You select `adam` optimizer.
2024-07-25 09:56:51,808 - WARNING - Received none train loss func and will use the loss func defined in the model.
2024-07-25 09:56:51,808 - INFO - Start training ...
2024-07-25 09:56:51,808 - INFO - num_batches:390
2024-07-25 09:59:35,286 - INFO - epoch complete!
2024-07-25 09:59:35,286 - INFO - evaluating now!
2024-07-25 09:59:42,602 - INFO - Epoch [0/100] train_loss: 20.9579, val_loss: 12.4667, lr: 0.010000, 170.79s
2024-07-25 09:59:42,626 - INFO - Saved model at 0
2024-07-25 09:59:42,626 - INFO - Val loss decrease from inf to 12.4667, saving to ./libcity/cache/00010/model_cache/HierAttnLstm_PEMSD8_epoch0.tar
2024-07-25 10:02:24,033 - INFO - epoch complete!
2024-07-25 10:02:24,034 - INFO - evaluating now!
2024-07-25 10:02:31,130 - INFO - Epoch [1/100] train_loss: 10.5322, val_loss: 11.5698, lr: 0.010000, 168.50s
2024-07-25 10:02:31,152 - INFO - Saved model at 1
2024-07-25 10:02:31,152 - INFO - Val loss decrease from 12.4667 to 11.5698, saving to ./libcity/cache/00010/model_cache/HierAttnLstm_PEMSD8_epoch1.tar
2024-07-25 10:05:13,670 - INFO - epoch complete!
2024-07-25 10:05:13,671 - INFO - evaluating now!
2024-07-25 10:05:21,064 - INFO - Epoch [2/100] train_loss: 9.8984, val_loss: 11.6197, lr: 0.010000, 169.91s
2024-07-25 10:08:01,125 - INFO - epoch complete!
2024-07-25 10:08:01,125 - INFO - evaluating now!
2024-07-25 10:08:08,176 - INFO - Epoch [3/100] train_loss: 9.5567, val_loss: 10.9694, lr: 0.010000, 167.11s
2024-07-25 10:08:08,200 - INFO - Saved model at 3
2024-07-25 10:08:08,200 - INFO - Val loss decrease from 11.5698 to 10.9694, saving to ./libcity/cache/00010/model_cache/HierAttnLstm_PEMSD8_epoch3.tar
2024-07-25 10:10:47,681 - INFO - epoch complete!
2024-07-25 10:10:47,682 - INFO - evaluating now!
2024-07-25 10:10:54,541 - INFO - Epoch [4/100] train_loss: 9.3499, val_loss: 11.2837, lr: 0.010000, 166.34s
2024-07-25 10:13:38,726 - INFO - epoch complete!
2024-07-25 10:13:38,726 - INFO - evaluating now!
2024-07-25 10:13:45,868 - INFO - Epoch [5/100] train_loss: 9.2556, val_loss: 11.6443, lr: 0.010000, 171.33s
2024-07-25 10:16:29,489 - INFO - epoch complete!
2024-07-25 10:16:29,489 - INFO - evaluating now!
2024-07-25 10:16:36,552 - INFO - Epoch [6/100] train_loss: 9.2139, val_loss: 10.8726, lr: 0.010000, 170.68s
2024-07-25 10:16:36,607 - INFO - Saved model at 6
2024-07-25 10:16:36,607 - INFO - Val loss decrease from 10.9694 to 10.8726, saving to ./libcity/cache/00010/model_cache/HierAttnLstm_PEMSD8_epoch6.tar
2024-07-25 10:19:18,518 - INFO - epoch complete!
2024-07-25 10:19:18,518 - INFO - evaluating now!
2024-07-25 10:19:25,612 - INFO - Epoch [7/100] train_loss: 9.2472, val_loss: 10.9636, lr: 0.010000, 169.00s
2024-07-25 10:22:12,506 - INFO - epoch complete!
2024-07-25 10:22:12,506 - INFO - evaluating now!
2024-07-25 10:22:19,540 - INFO - Epoch [8/100] train_loss: 9.1141, val_loss: 10.8512, lr: 0.010000, 173.93s
2024-07-25 10:22:19,564 - INFO - Saved model at 8
2024-07-25 10:22:19,564 - INFO - Val loss decrease from 10.8726 to 10.8512, saving to ./libcity/cache/00010/model_cache/HierAttnLstm_PEMSD8_epoch8.tar
2024-07-25 10:24:59,831 - INFO - epoch complete!
2024-07-25 10:24:59,831 - INFO - evaluating now!
2024-07-25 10:25:06,920 - INFO - Epoch [9/100] train_loss: 9.0389, val_loss: 10.7055, lr: 0.010000, 167.36s
2024-07-25 10:25:06,989 - INFO - Saved model at 9
2024-07-25 10:25:06,989 - INFO - Val loss decrease from 10.8512 to 10.7055, saving to ./libcity/cache/00010/model_cache/HierAttnLstm_PEMSD8_epoch9.tar
2024-07-25 10:27:49,372 - INFO - epoch complete!
2024-07-25 10:27:49,372 - INFO - evaluating now!
2024-07-25 10:27:56,255 - INFO - Epoch [10/100] train_loss: 9.0928, val_loss: 10.7749, lr: 0.010000, 169.27s
2024-07-25 10:30:39,498 - INFO - epoch complete!
2024-07-25 10:30:39,499 - INFO - evaluating now!
2024-07-25 10:30:46,383 - INFO - Epoch [11/100] train_loss: 9.0147, val_loss: 10.5708, lr: 0.010000, 170.13s
2024-07-25 10:30:46,406 - INFO - Saved model at 11
2024-07-25 10:30:46,406 - INFO - Val loss decrease from 10.7055 to 10.5708, saving to ./libcity/cache/00010/model_cache/HierAttnLstm_PEMSD8_epoch11.tar
2024-07-25 10:33:27,593 - INFO - epoch complete!
2024-07-25 10:33:27,593 - INFO - evaluating now!
2024-07-25 10:33:34,612 - INFO - Epoch [12/100] train_loss: 8.9829, val_loss: 10.6123, lr: 0.010000, 168.20s
2024-07-25 10:36:15,809 - INFO - epoch complete!
2024-07-25 10:36:15,810 - INFO - evaluating now!
2024-07-25 10:36:22,732 - INFO - Epoch [13/100] train_loss: 8.9512, val_loss: 10.5111, lr: 0.010000, 168.12s
2024-07-25 10:36:22,766 - INFO - Saved model at 13
2024-07-25 10:36:22,766 - INFO - Val loss decrease from 10.5708 to 10.5111, saving to ./libcity/cache/00010/model_cache/HierAttnLstm_PEMSD8_epoch13.tar
2024-07-25 10:39:02,945 - INFO - epoch complete!
2024-07-25 10:39:02,946 - INFO - evaluating now!
2024-07-25 10:39:09,945 - INFO - Epoch [14/100] train_loss: 8.9825, val_loss: 10.4355, lr: 0.010000, 167.18s
2024-07-25 10:39:09,969 - INFO - Saved model at 14
2024-07-25 10:39:09,969 - INFO - Val loss decrease from 10.5111 to 10.4355, saving to ./libcity/cache/00010/model_cache/HierAttnLstm_PEMSD8_epoch14.tar
2024-07-25 10:41:50,309 - INFO - epoch complete!
2024-07-25 10:41:50,310 - INFO - evaluating now!
2024-07-25 10:41:57,325 - INFO - Epoch [15/100] train_loss: 8.9425, val_loss: 10.6257, lr: 0.010000, 167.36s
2024-07-25 10:44:36,823 - INFO - epoch complete!
2024-07-25 10:44:36,824 - INFO - evaluating now!
2024-07-25 10:44:43,744 - INFO - Epoch [16/100] train_loss: 8.9263, val_loss: 10.6308, lr: 0.010000, 166.42s
2024-07-25 10:47:24,325 - INFO - epoch complete!
2024-07-25 10:47:24,325 - INFO - evaluating now!
2024-07-25 10:47:31,318 - INFO - Epoch [17/100] train_loss: 8.9781, val_loss: 10.5910, lr: 0.010000, 167.57s
2024-07-25 10:50:11,404 - INFO - epoch complete!
2024-07-25 10:50:11,404 - INFO - evaluating now!
2024-07-25 10:50:18,323 - INFO - Epoch [18/100] train_loss: 8.8928, val_loss: 10.5723, lr: 0.010000, 167.00s
2024-07-25 10:52:58,429 - INFO - epoch complete!
2024-07-25 10:52:58,429 - INFO - evaluating now!
2024-07-25 10:53:05,522 - INFO - Epoch [19/100] train_loss: 8.9072, val_loss: 10.4849, lr: 0.010000, 167.20s
2024-07-25 10:53:05,522 - WARNING - Early stopping at epoch: 19
2024-07-25 10:53:05,522 - INFO - Trained totally 20 epochs, average train time is 161.631s, average eval time is 7.039s
2024-07-25 10:53:05,541 - INFO - Loaded model at 14
2024-07-25 10:53:05,541 - INFO - Saved model at ./libcity/cache/00010/model_cache/HierAttnLstm_PEMSD8.m
2024-07-25 10:53:05,565 - INFO - Start evaluating ...
2024-07-25 10:53:21,802 - INFO - Note that you select the single mode to evaluate!
2024-07-25 10:53:21,805 - INFO - Evaluate result is saved at ./libcity/cache/00010/evaluate_cache\2024_07_25_10_53_21_HierAttnLstm_PEMSD8.csv
2024-07-25 10:53:21,816 - INFO - 
        MAE         MAPE         MSE  ...  masked_RMSE        R2      EVAR
1  9.444011  1410186.750  518.019104  ...    22.735191  0.968924  0.968929
2  9.441726  1410651.375  517.756165  ...    22.729408  0.968926  0.968930
3  9.439483  1411139.500  517.467407  ...    22.723051  0.968929  0.968933
4  9.437078  1411449.625  517.177856  ...    22.716665  0.968932  0.968936
5  9.434747  1411498.625  516.892334  ...    22.710365  0.968936  0.968940
6  9.432317  1412133.125  516.601135  ...    22.703953  0.968940  0.968944
7  9.430240  1412816.500  516.327209  ...    22.697929  0.968942  0.968947
8  9.427944  1412976.375  516.064880  ...    22.692139  0.968945  0.968949
9  9.451294  1413649.625  519.390381  ...    22.765577  0.968731  0.968739

[9 rows x 10 columns]

Standard Error:
