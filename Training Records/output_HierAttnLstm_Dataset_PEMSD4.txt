Command:
python run_model.py --task traffic_state_pred --model HierAttnLstm --dataset PEMSD4

Standard Output:
2024-07-23 05:03:54,207 - INFO - Log directory: ./libcity/log
2024-07-23 05:03:54,208 - INFO - Begin pipeline, task=traffic_state_pred, model_name=HierAttnLstm, dataset_name=PEMSD4, exp_id=50492
2024-07-23 05:03:54,208 - INFO - {'task': 'traffic_state_pred', 'model': 'HierAttnLstm', 'dataset': 'PEMSD4', 'saved_model': True, 'train': True, 'seed': 0, 'dataset_class': 'TrafficStatePointDataset', 'executor': 'TrafficStateExecutor', 'evaluator': 'TrafficStateEvaluator', 'input_window': 48, 'output_window': 6, 'device': device(type='cuda', index=0), 'hidden_size': 128, 'num_layers': 3, 'dropout': 0.1, 'natt_hops': 3, 'nfc': 512, 'max_up_len': 96, 'batch_size': 32, 'cache_dataset': True, 'num_workers': 0, 'pad_with_last_sample': True, 'train_rate': 0.7, 'eval_rate': 0.1, 'scaler': 'minmax01', 'load_external': False, 'normal_external': False, 'ext_scaler': 'none', 'add_time_in_day': False, 'add_day_in_week': False, 'robustness_test': False, 'noise_type': 'gaussian', 'disturb_rate': 0.5, 'noise_mean': [5], 'noise_SD': [10], 'gpu': True, 'gpu_id': 0, 'max_epoch': 100, 'train_loss': 'none', 'epoch': 0, 'learner': 'adam', 'learning_rate': 0.01, 'weight_decay': 0, 'lr_epsilon': 1e-08, 'lr_beta1': 0.9, 'lr_beta2': 0.999, 'lr_alpha': 0.99, 'lr_momentum': 0, 'lr_decay': False, 'lr_scheduler': 'multisteplr', 'lr_decay_ratio': 0.1, 'steps': [5, 20, 40, 70], 'step_size': 10, 'lr_T_max': 30, 'lr_eta_min': 0, 'lr_patience': 10, 'lr_threshold': 0.0001, 'clip_grad_norm': False, 'max_grad_norm': 1.0, 'use_early_stop': True, 'patience': 10, 'log_level': 'INFO', 'log_every': 1, 'load_best_epoch': True, 'hyper_tune': False, 'metrics': ['MAE', 'MAPE', 'MSE', 'RMSE', 'masked_MAE', 'masked_MAPE', 'masked_MSE', 'masked_RMSE', 'R2', 'EVAR'], 'evaluator_mode': 'single', 'save_mode': ['csv'], 'geo': {'including_types': ['Point'], 'Point': {}}, 'rel': {'including_types': ['geo'], 'geo': {'cost': 'num'}}, 'dyna': {'including_types': ['state'], 'state': {'entity_id': 'geo_id', 'traffic_flow': 'num', 'traffic_occupancy': 'num', 'traffic_speed': 'num'}}, 'data_col': ['traffic_flow', 'traffic_occupancy', 'traffic_speed'], 'weight_col': 'cost', 'data_files': ['PEMSD4'], 'geo_file': 'PEMSD4', 'rel_file': 'PEMSD4', 'output_dim': 3, 'time_intervals': 300, 'init_weight_inf_or_zero': 'zero', 'set_weight_link_or_dist': 'link', 'calculate_weight_adj': False, 'weight_adj_epsilon': 0.1, 'exp_id': 50492}
self.scaler_type  minmax01
2024-07-23 05:03:54,227 - INFO - Loaded file PEMSD4.geo, num_nodes=307
2024-07-23 05:03:54,253 - INFO - set_weight_link_or_dist: link
2024-07-23 05:03:54,253 - INFO - init_weight_inf_or_zero: zero
2024-07-23 05:03:54,256 - INFO - Loaded file PEMSD4.rel, shape=(307, 307)
2024-07-23 05:03:54,256 - INFO - Loading file PEMSD4.dyna
2024-07-23 05:03:56,681 - INFO - Loaded file PEMSD4.dyna, shape=(16992, 307, 3)
2024-07-23 05:04:03,388 - INFO - Dataset created
2024-07-23 05:04:03,388 - INFO - x shape: (16939, 48, 307, 3), y shape: (16939, 6, 307, 3)
2024-07-23 05:04:03,618 - INFO - train	x: (11857, 48, 307, 3), y: (11857, 6, 307, 3)
2024-07-23 05:04:03,619 - INFO - eval	x: (1694, 48, 307, 3), y: (1694, 6, 307, 3)
2024-07-23 05:04:03,619 - INFO - test	x: (3388, 48, 307, 3), y: (3388, 6, 307, 3)
2024-07-23 05:07:34,744 - INFO - Saved at ./libcity/cache/dataset_cache/point_based_PEMSD4_48_6_0.7_0.1_minmax01_32_False_False_False_True.npz
2024-07-23 05:07:35,219 - INFO - MinMax01Scaler max: 919.0, min: 0.0
2024-07-23 05:07:35,220 - INFO - NoneScaler
2024-07-23 05:07:39,905 - INFO - HierAttnLstm(
  (lstm_cells): ModuleList(
    (0): LSTMCell(921, 128)
    (1-2): 2 x LSTMCell(128, 128)
  )
  (hidden_state_pooling): ModuleList(
    (0-1): 2 x SelfAttentionPooling(
      (W): Linear(in_features=128, out_features=1, bias=True)
    )
  )
  (cell_state_pooling): ModuleList(
    (0-1): 2 x SelfAttentionPooling(
      (W): Linear(in_features=128, out_features=1, bias=True)
    )
  )
  (self_attention): SelfAttention(
    (ut_dense): Sequential(
      (0): Linear(in_features=128, out_features=128, bias=True)
      (1): Tanh()
    )
    (et_dense): Linear(in_features=128, out_features=3, bias=True)
    (softmax): Softmax(dim=-1)
  )
  (fc_layer): Sequential(
    (0): Linear(in_features=384, out_features=512, bias=True)
    (1): ReLU()
    (2): Linear(in_features=512, out_features=921, bias=True)
  )
)
2024-07-23 05:07:39,905 - INFO - lstm_cells.0.weight_ih	torch.Size([512, 921])	cuda:0	True
2024-07-23 05:07:39,905 - INFO - lstm_cells.0.weight_hh	torch.Size([512, 128])	cuda:0	True
2024-07-23 05:07:39,906 - INFO - lstm_cells.0.bias_ih	torch.Size([512])	cuda:0	True
2024-07-23 05:07:39,906 - INFO - lstm_cells.0.bias_hh	torch.Size([512])	cuda:0	True
2024-07-23 05:07:39,906 - INFO - lstm_cells.1.weight_ih	torch.Size([512, 128])	cuda:0	True
2024-07-23 05:07:39,906 - INFO - lstm_cells.1.weight_hh	torch.Size([512, 128])	cuda:0	True
2024-07-23 05:07:39,906 - INFO - lstm_cells.1.bias_ih	torch.Size([512])	cuda:0	True
2024-07-23 05:07:39,906 - INFO - lstm_cells.1.bias_hh	torch.Size([512])	cuda:0	True
2024-07-23 05:07:39,906 - INFO - lstm_cells.2.weight_ih	torch.Size([512, 128])	cuda:0	True
2024-07-23 05:07:39,906 - INFO - lstm_cells.2.weight_hh	torch.Size([512, 128])	cuda:0	True
2024-07-23 05:07:39,906 - INFO - lstm_cells.2.bias_ih	torch.Size([512])	cuda:0	True
2024-07-23 05:07:39,906 - INFO - lstm_cells.2.bias_hh	torch.Size([512])	cuda:0	True
2024-07-23 05:07:39,906 - INFO - hidden_state_pooling.0.W.weight	torch.Size([1, 128])	cuda:0	True
2024-07-23 05:07:39,906 - INFO - hidden_state_pooling.0.W.bias	torch.Size([1])	cuda:0	True
2024-07-23 05:07:39,906 - INFO - hidden_state_pooling.1.W.weight	torch.Size([1, 128])	cuda:0	True
2024-07-23 05:07:39,906 - INFO - hidden_state_pooling.1.W.bias	torch.Size([1])	cuda:0	True
2024-07-23 05:07:39,906 - INFO - cell_state_pooling.0.W.weight	torch.Size([1, 128])	cuda:0	True
2024-07-23 05:07:39,906 - INFO - cell_state_pooling.0.W.bias	torch.Size([1])	cuda:0	True
2024-07-23 05:07:39,906 - INFO - cell_state_pooling.1.W.weight	torch.Size([1, 128])	cuda:0	True
2024-07-23 05:07:39,907 - INFO - cell_state_pooling.1.W.bias	torch.Size([1])	cuda:0	True
2024-07-23 05:07:39,907 - INFO - self_attention.ut_dense.0.weight	torch.Size([128, 128])	cuda:0	True
2024-07-23 05:07:39,907 - INFO - self_attention.ut_dense.0.bias	torch.Size([128])	cuda:0	True
2024-07-23 05:07:39,907 - INFO - self_attention.et_dense.weight	torch.Size([3, 128])	cuda:0	True
2024-07-23 05:07:39,907 - INFO - self_attention.et_dense.bias	torch.Size([3])	cuda:0	True
2024-07-23 05:07:39,907 - INFO - fc_layer.0.weight	torch.Size([512, 384])	cuda:0	True
2024-07-23 05:07:39,907 - INFO - fc_layer.0.bias	torch.Size([512])	cuda:0	True
2024-07-23 05:07:39,907 - INFO - fc_layer.2.weight	torch.Size([921, 512])	cuda:0	True
2024-07-23 05:07:39,907 - INFO - fc_layer.2.bias	torch.Size([921])	cuda:0	True
2024-07-23 05:07:39,907 - INFO - Total parameter numbers: 1489312
2024-07-23 05:07:39,907 - INFO - You select `adam` optimizer.
2024-07-23 05:07:39,908 - WARNING - Received none train loss func and will use the loss func defined in the model.
2024-07-23 05:07:39,908 - INFO - Start training ...
2024-07-23 05:07:39,908 - INFO - num_batches:371
2024-07-23 05:09:24,129 - INFO - epoch complete!
2024-07-23 05:09:24,129 - INFO - evaluating now!
2024-07-23 05:09:28,701 - INFO - Epoch [0/100] train_loss: 19.9824, val_loss: 11.0875, lr: 0.010000, 108.79s
2024-07-23 05:09:28,726 - INFO - Saved model at 0
2024-07-23 05:09:28,726 - INFO - Val loss decrease from inf to 11.0875, saving to ./libcity/cache/50492/model_cache/HierAttnLstm_PEMSD4_epoch0.tar
2024-07-23 05:11:13,113 - INFO - epoch complete!
2024-07-23 05:11:13,113 - INFO - evaluating now!
2024-07-23 05:11:17,590 - INFO - Epoch [1/100] train_loss: 10.1872, val_loss: 9.6716, lr: 0.010000, 108.86s
2024-07-23 05:11:17,610 - INFO - Saved model at 1
2024-07-23 05:11:17,611 - INFO - Val loss decrease from 11.0875 to 9.6716, saving to ./libcity/cache/50492/model_cache/HierAttnLstm_PEMSD4_epoch1.tar
2024-07-23 05:13:02,596 - INFO - epoch complete!
2024-07-23 05:13:02,597 - INFO - evaluating now!
2024-07-23 05:13:07,211 - INFO - Epoch [2/100] train_loss: 9.4110, val_loss: 9.3443, lr: 0.010000, 109.60s
2024-07-23 05:13:07,232 - INFO - Saved model at 2
2024-07-23 05:13:07,232 - INFO - Val loss decrease from 9.6716 to 9.3443, saving to ./libcity/cache/50492/model_cache/HierAttnLstm_PEMSD4_epoch2.tar
2024-07-23 05:14:52,292 - INFO - epoch complete!
2024-07-23 05:14:52,292 - INFO - evaluating now!
2024-07-23 05:14:56,731 - INFO - Epoch [3/100] train_loss: 9.2142, val_loss: 9.2496, lr: 0.010000, 109.50s
2024-07-23 05:14:56,751 - INFO - Saved model at 3
2024-07-23 05:14:56,751 - INFO - Val loss decrease from 9.3443 to 9.2496, saving to ./libcity/cache/50492/model_cache/HierAttnLstm_PEMSD4_epoch3.tar
2024-07-23 05:16:41,700 - INFO - epoch complete!
2024-07-23 05:16:41,700 - INFO - evaluating now!
2024-07-23 05:16:46,241 - INFO - Epoch [4/100] train_loss: 8.9578, val_loss: 8.9734, lr: 0.010000, 109.49s
2024-07-23 05:16:46,264 - INFO - Saved model at 4
2024-07-23 05:16:46,264 - INFO - Val loss decrease from 9.2496 to 8.9734, saving to ./libcity/cache/50492/model_cache/HierAttnLstm_PEMSD4_epoch4.tar
2024-07-23 05:18:31,236 - INFO - epoch complete!
2024-07-23 05:18:31,236 - INFO - evaluating now!
2024-07-23 05:18:35,847 - INFO - Epoch [5/100] train_loss: 8.8511, val_loss: 8.9762, lr: 0.010000, 109.58s
2024-07-23 05:20:20,429 - INFO - epoch complete!
2024-07-23 05:20:20,429 - INFO - evaluating now!
2024-07-23 05:20:25,028 - INFO - Epoch [6/100] train_loss: 8.7264, val_loss: 9.0387, lr: 0.010000, 109.18s
2024-07-23 05:22:09,670 - INFO - epoch complete!
2024-07-23 05:22:09,671 - INFO - evaluating now!
2024-07-23 05:22:14,143 - INFO - Epoch [7/100] train_loss: 8.6340, val_loss: 8.8982, lr: 0.010000, 109.11s
2024-07-23 05:22:14,165 - INFO - Saved model at 7
2024-07-23 05:22:14,165 - INFO - Val loss decrease from 8.9734 to 8.8982, saving to ./libcity/cache/50492/model_cache/HierAttnLstm_PEMSD4_epoch7.tar
2024-07-23 05:23:58,459 - INFO - epoch complete!
2024-07-23 05:23:58,459 - INFO - evaluating now!
2024-07-23 05:24:03,061 - INFO - Epoch [8/100] train_loss: 8.6494, val_loss: 8.9364, lr: 0.010000, 108.90s
2024-07-23 05:25:47,140 - INFO - epoch complete!
2024-07-23 05:25:47,140 - INFO - evaluating now!
2024-07-23 05:25:51,617 - INFO - Epoch [9/100] train_loss: 8.4646, val_loss: 8.6028, lr: 0.010000, 108.56s
2024-07-23 05:25:51,639 - INFO - Saved model at 9
2024-07-23 05:25:51,639 - INFO - Val loss decrease from 8.8982 to 8.6028, saving to ./libcity/cache/50492/model_cache/HierAttnLstm_PEMSD4_epoch9.tar
2024-07-23 05:27:36,232 - INFO - epoch complete!
2024-07-23 05:27:36,232 - INFO - evaluating now!
2024-07-23 05:27:40,876 - INFO - Epoch [10/100] train_loss: 8.4817, val_loss: 8.9561, lr: 0.010000, 109.24s
2024-07-23 05:29:25,930 - INFO - epoch complete!
2024-07-23 05:29:25,930 - INFO - evaluating now!
2024-07-23 05:29:30,542 - INFO - Epoch [11/100] train_loss: 8.3087, val_loss: 8.7555, lr: 0.010000, 109.66s
2024-07-23 05:31:16,037 - INFO - epoch complete!
2024-07-23 05:31:16,037 - INFO - evaluating now!
2024-07-23 05:31:20,617 - INFO - Epoch [12/100] train_loss: 8.2903, val_loss: 8.4908, lr: 0.010000, 110.08s
2024-07-23 05:31:20,645 - INFO - Saved model at 12
2024-07-23 05:31:20,645 - INFO - Val loss decrease from 8.6028 to 8.4908, saving to ./libcity/cache/50492/model_cache/HierAttnLstm_PEMSD4_epoch12.tar
2024-07-23 05:33:06,166 - INFO - epoch complete!
2024-07-23 05:33:06,166 - INFO - evaluating now!
2024-07-23 05:33:10,780 - INFO - Epoch [13/100] train_loss: 8.2383, val_loss: 8.6984, lr: 0.010000, 110.13s
2024-07-23 05:34:56,077 - INFO - epoch complete!
2024-07-23 05:34:56,077 - INFO - evaluating now!
2024-07-23 05:35:00,712 - INFO - Epoch [14/100] train_loss: 8.1975, val_loss: 8.4122, lr: 0.010000, 109.93s
2024-07-23 05:35:00,733 - INFO - Saved model at 14
2024-07-23 05:35:00,733 - INFO - Val loss decrease from 8.4908 to 8.4122, saving to ./libcity/cache/50492/model_cache/HierAttnLstm_PEMSD4_epoch14.tar
2024-07-23 05:36:44,933 - INFO - epoch complete!
2024-07-23 05:36:44,933 - INFO - evaluating now!
2024-07-23 05:36:49,582 - INFO - Epoch [15/100] train_loss: 8.1656, val_loss: 8.5772, lr: 0.010000, 108.85s
2024-07-23 05:38:34,486 - INFO - epoch complete!
2024-07-23 05:38:34,486 - INFO - evaluating now!
2024-07-23 05:38:39,010 - INFO - Epoch [16/100] train_loss: 8.1004, val_loss: 8.5203, lr: 0.010000, 109.43s
2024-07-23 05:40:23,107 - INFO - epoch complete!
2024-07-23 05:40:23,108 - INFO - evaluating now!
2024-07-23 05:40:27,802 - INFO - Epoch [17/100] train_loss: 8.1342, val_loss: 8.5383, lr: 0.010000, 108.79s
2024-07-23 05:42:11,947 - INFO - epoch complete!
2024-07-23 05:42:11,947 - INFO - evaluating now!
2024-07-23 05:42:16,659 - INFO - Epoch [18/100] train_loss: 7.9955, val_loss: 8.4000, lr: 0.010000, 108.86s
2024-07-23 05:42:16,683 - INFO - Saved model at 18
2024-07-23 05:42:16,683 - INFO - Val loss decrease from 8.4122 to 8.4000, saving to ./libcity/cache/50492/model_cache/HierAttnLstm_PEMSD4_epoch18.tar
2024-07-23 05:44:01,196 - INFO - epoch complete!
2024-07-23 05:44:01,196 - INFO - evaluating now!
2024-07-23 05:44:05,873 - INFO - Epoch [19/100] train_loss: 7.9949, val_loss: 8.4733, lr: 0.010000, 109.19s
2024-07-23 05:45:50,118 - INFO - epoch complete!
2024-07-23 05:45:50,118 - INFO - evaluating now!
2024-07-23 05:45:54,681 - INFO - Epoch [20/100] train_loss: 8.0331, val_loss: 8.3415, lr: 0.010000, 108.81s
2024-07-23 05:45:54,702 - INFO - Saved model at 20
2024-07-23 05:45:54,702 - INFO - Val loss decrease from 8.4000 to 8.3415, saving to ./libcity/cache/50492/model_cache/HierAttnLstm_PEMSD4_epoch20.tar
2024-07-23 05:47:38,889 - INFO - epoch complete!
2024-07-23 05:47:38,890 - INFO - evaluating now!
2024-07-23 05:47:43,440 - INFO - Epoch [21/100] train_loss: 8.0125, val_loss: 8.3639, lr: 0.010000, 108.74s
2024-07-23 05:49:27,019 - INFO - epoch complete!
2024-07-23 05:49:27,019 - INFO - evaluating now!
2024-07-23 05:49:31,577 - INFO - Epoch [22/100] train_loss: 7.9296, val_loss: 8.6421, lr: 0.010000, 108.14s
2024-07-23 05:51:16,128 - INFO - epoch complete!
2024-07-23 05:51:16,128 - INFO - evaluating now!
2024-07-23 05:51:20,759 - INFO - Epoch [23/100] train_loss: 7.9187, val_loss: 8.5869, lr: 0.010000, 109.18s
2024-07-23 05:53:06,282 - INFO - epoch complete!
2024-07-23 05:53:06,282 - INFO - evaluating now!
2024-07-23 05:53:10,852 - INFO - Epoch [24/100] train_loss: 7.9054, val_loss: 8.4381, lr: 0.010000, 110.09s
2024-07-23 05:54:55,524 - INFO - epoch complete!
2024-07-23 05:54:55,524 - INFO - evaluating now!
2024-07-23 05:55:00,028 - INFO - Epoch [25/100] train_loss: 7.8646, val_loss: 8.4190, lr: 0.010000, 109.18s
2024-07-23 05:56:44,564 - INFO - epoch complete!
2024-07-23 05:56:44,564 - INFO - evaluating now!
2024-07-23 05:56:49,036 - INFO - Epoch [26/100] train_loss: 7.8168, val_loss: 8.3907, lr: 0.010000, 109.01s
2024-07-23 05:58:33,291 - INFO - epoch complete!
2024-07-23 05:58:33,291 - INFO - evaluating now!
2024-07-23 05:58:37,971 - INFO - Epoch [27/100] train_loss: 7.8413, val_loss: 8.4378, lr: 0.010000, 108.93s
2024-07-23 06:00:22,959 - INFO - epoch complete!
2024-07-23 06:00:22,959 - INFO - evaluating now!
2024-07-23 06:00:27,546 - INFO - Epoch [28/100] train_loss: 7.8038, val_loss: 8.2855, lr: 0.010000, 109.58s
2024-07-23 06:00:27,567 - INFO - Saved model at 28
2024-07-23 06:00:27,567 - INFO - Val loss decrease from 8.3415 to 8.2855, saving to ./libcity/cache/50492/model_cache/HierAttnLstm_PEMSD4_epoch28.tar
2024-07-23 06:02:12,161 - INFO - epoch complete!
2024-07-23 06:02:12,162 - INFO - evaluating now!
2024-07-23 06:02:16,707 - INFO - Epoch [29/100] train_loss: 7.8006, val_loss: 8.3128, lr: 0.010000, 109.14s
2024-07-23 06:04:01,387 - INFO - epoch complete!
2024-07-23 06:04:01,388 - INFO - evaluating now!
2024-07-23 06:04:05,919 - INFO - Epoch [30/100] train_loss: 7.7812, val_loss: 8.3560, lr: 0.010000, 109.21s
2024-07-23 06:05:49,897 - INFO - epoch complete!
2024-07-23 06:05:49,897 - INFO - evaluating now!
2024-07-23 06:05:54,646 - INFO - Epoch [31/100] train_loss: 7.7874, val_loss: 8.2138, lr: 0.010000, 108.73s
2024-07-23 06:05:54,668 - INFO - Saved model at 31
2024-07-23 06:05:54,668 - INFO - Val loss decrease from 8.2855 to 8.2138, saving to ./libcity/cache/50492/model_cache/HierAttnLstm_PEMSD4_epoch31.tar
2024-07-23 06:07:39,091 - INFO - epoch complete!
2024-07-23 06:07:39,091 - INFO - evaluating now!
2024-07-23 06:07:43,719 - INFO - Epoch [32/100] train_loss: 7.7390, val_loss: 8.3397, lr: 0.010000, 109.05s
2024-07-23 06:09:27,355 - INFO - epoch complete!
2024-07-23 06:09:27,355 - INFO - evaluating now!
2024-07-23 06:09:31,955 - INFO - Epoch [33/100] train_loss: 7.7116, val_loss: 8.3930, lr: 0.010000, 108.24s
2024-07-23 06:11:14,757 - INFO - epoch complete!
2024-07-23 06:11:14,757 - INFO - evaluating now!
2024-07-23 06:11:19,288 - INFO - Epoch [34/100] train_loss: 7.7153, val_loss: 8.3200, lr: 0.010000, 107.33s
2024-07-23 06:13:03,132 - INFO - epoch complete!
2024-07-23 06:13:03,133 - INFO - evaluating now!
2024-07-23 06:13:07,703 - INFO - Epoch [35/100] train_loss: 7.7593, val_loss: 8.4501, lr: 0.010000, 108.42s
2024-07-23 06:14:51,177 - INFO - epoch complete!
2024-07-23 06:14:51,177 - INFO - evaluating now!
2024-07-23 06:14:55,725 - INFO - Epoch [36/100] train_loss: 7.6974, val_loss: 8.4009, lr: 0.010000, 108.02s
2024-07-23 06:16:39,235 - INFO - epoch complete!
2024-07-23 06:16:39,235 - INFO - evaluating now!
2024-07-23 06:16:43,768 - INFO - Epoch [37/100] train_loss: 7.6803, val_loss: 8.3794, lr: 0.010000, 108.04s
2024-07-23 06:18:27,299 - INFO - epoch complete!
2024-07-23 06:18:27,299 - INFO - evaluating now!
2024-07-23 06:18:31,806 - INFO - Epoch [38/100] train_loss: 7.7142, val_loss: 8.3165, lr: 0.010000, 108.04s
2024-07-23 06:20:15,285 - INFO - epoch complete!
2024-07-23 06:20:15,285 - INFO - evaluating now!
2024-07-23 06:20:19,765 - INFO - Epoch [39/100] train_loss: 7.7172, val_loss: 8.3149, lr: 0.010000, 107.96s
2024-07-23 06:22:03,238 - INFO - epoch complete!
2024-07-23 06:22:03,239 - INFO - evaluating now!
2024-07-23 06:22:07,877 - INFO - Epoch [40/100] train_loss: 7.6465, val_loss: 8.3747, lr: 0.010000, 108.11s
2024-07-23 06:23:51,759 - INFO - epoch complete!
2024-07-23 06:23:51,760 - INFO - evaluating now!
2024-07-23 06:23:56,438 - INFO - Epoch [41/100] train_loss: 7.6512, val_loss: 8.1533, lr: 0.010000, 108.56s
2024-07-23 06:23:56,569 - INFO - Saved model at 41
2024-07-23 06:23:56,569 - INFO - Val loss decrease from 8.2138 to 8.1533, saving to ./libcity/cache/50492/model_cache/HierAttnLstm_PEMSD4_epoch41.tar
2024-07-23 06:25:40,124 - INFO - epoch complete!
2024-07-23 06:25:40,125 - INFO - evaluating now!
2024-07-23 06:25:44,688 - INFO - Epoch [42/100] train_loss: 7.6086, val_loss: 8.2813, lr: 0.010000, 108.12s
2024-07-23 06:27:28,242 - INFO - epoch complete!
2024-07-23 06:27:28,243 - INFO - evaluating now!
2024-07-23 06:27:32,912 - INFO - Epoch [43/100] train_loss: 7.6676, val_loss: 8.4530, lr: 0.010000, 108.22s
2024-07-23 06:29:15,691 - INFO - epoch complete!
2024-07-23 06:29:15,691 - INFO - evaluating now!
2024-07-23 06:29:20,256 - INFO - Epoch [44/100] train_loss: 7.6769, val_loss: 8.2254, lr: 0.010000, 107.34s
2024-07-23 06:31:04,004 - INFO - epoch complete!
2024-07-23 06:31:04,004 - INFO - evaluating now!
2024-07-23 06:31:08,586 - INFO - Epoch [45/100] train_loss: 7.6017, val_loss: 8.3316, lr: 0.010000, 108.33s
2024-07-23 06:32:52,066 - INFO - epoch complete!
2024-07-23 06:32:52,066 - INFO - evaluating now!
2024-07-23 06:32:56,558 - INFO - Epoch [46/100] train_loss: 7.6057, val_loss: 8.1888, lr: 0.010000, 107.97s
2024-07-23 06:34:40,264 - INFO - epoch complete!
2024-07-23 06:34:40,264 - INFO - evaluating now!
2024-07-23 06:34:44,813 - INFO - Epoch [47/100] train_loss: 7.6947, val_loss: 8.2038, lr: 0.010000, 108.25s
2024-07-23 06:36:27,548 - INFO - epoch complete!
2024-07-23 06:36:27,548 - INFO - evaluating now!
2024-07-23 06:36:32,035 - INFO - Epoch [48/100] train_loss: 7.5728, val_loss: 8.3268, lr: 0.010000, 107.22s
2024-07-23 06:38:15,938 - INFO - epoch complete!
2024-07-23 06:38:15,938 - INFO - evaluating now!
2024-07-23 06:38:20,408 - INFO - Epoch [49/100] train_loss: 7.5783, val_loss: 8.3623, lr: 0.010000, 108.37s
2024-07-23 06:40:03,578 - INFO - epoch complete!
2024-07-23 06:40:03,578 - INFO - evaluating now!
2024-07-23 06:40:08,078 - INFO - Epoch [50/100] train_loss: 7.5564, val_loss: 8.2039, lr: 0.010000, 107.67s
2024-07-23 06:41:50,801 - INFO - epoch complete!
2024-07-23 06:41:50,802 - INFO - evaluating now!
2024-07-23 06:41:55,407 - INFO - Epoch [51/100] train_loss: 7.7960, val_loss: 8.2814, lr: 0.010000, 107.33s
2024-07-23 06:41:55,407 - WARNING - Early stopping at epoch: 51
2024-07-23 06:41:55,407 - INFO - Trained totally 52 epochs, average train time is 104.176s, average eval time is 4.574s
2024-07-23 06:41:55,424 - INFO - Loaded model at 41
2024-07-23 06:41:55,424 - INFO - Saved model at ./libcity/cache/50492/model_cache/HierAttnLstm_PEMSD4.m
2024-07-23 06:41:55,446 - INFO - Start evaluating ...
2024-07-23 06:42:07,035 - INFO - Note that you select the single mode to evaluate!
2024-07-23 06:42:07,040 - INFO - Evaluate result is saved at ./libcity/cache/50492/evaluate_cache\2024_07_23_06_42_07_HierAttnLstm_PEMSD4.csv
2024-07-23 06:42:07,051 - INFO - 
        MAE        MAPE         MSE  ...  masked_RMSE        R2      EVAR
1  8.730986  20590570.0  500.655579  ...    21.195576  0.969979  0.969980
2  8.731169  20588184.0  500.665497  ...    21.195822  0.969979  0.969979
3  8.731342  20589128.0  500.678680  ...    21.196123  0.969978  0.969979
4  8.731450  20587558.0  500.683228  ...    21.196234  0.969978  0.969979
5  8.731449  20581736.0  500.679657  ...    21.196194  0.969979  0.969979
6  8.731515  20580312.0  500.675598  ...    21.196117  0.969979  0.969979

[6 rows x 10 columns]

Standard Error:
