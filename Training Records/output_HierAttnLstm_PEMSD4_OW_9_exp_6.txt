Command:
python run_model.py --task traffic_state_pred --model HierAttnLstm --dataset PEMSD4 --config_file HierAttnLstm_OW_9 --exp_id 00006

Standard Output:
2024-07-25 07:04:46,267 - INFO - Log directory: ./libcity/log
2024-07-25 07:04:46,267 - INFO - Begin pipeline, task=traffic_state_pred, model_name=HierAttnLstm, dataset_name=PEMSD4, exp_id=00006
2024-07-25 07:04:46,267 - INFO - {'task': 'traffic_state_pred', 'model': 'HierAttnLstm', 'dataset': 'PEMSD4', 'saved_model': True, 'train': True, 'exp_id': '00006', 'seed': 0, 'input_window': 48, 'output_window': 9, 'device': device(type='cuda', index=0), 'hidden_size': 128, 'num_layers': 3, 'dropout': 0.1, 'natt_hops': 3, 'nfc': 512, 'max_up_len': 96, 'dataset_class': 'TrafficStatePointDataset', 'executor': 'TrafficStateExecutor', 'evaluator': 'TrafficStateEvaluator', 'batch_size': 32, 'cache_dataset': True, 'num_workers': 0, 'pad_with_last_sample': True, 'train_rate': 0.7, 'eval_rate': 0.1, 'scaler': 'minmax01', 'load_external': False, 'normal_external': False, 'ext_scaler': 'none', 'add_time_in_day': False, 'add_day_in_week': False, 'robustness_test': False, 'noise_type': 'gaussian', 'disturb_rate': 0.5, 'noise_mean': [5], 'noise_SD': [10], 'gpu': True, 'gpu_id': 0, 'max_epoch': 100, 'train_loss': 'none', 'epoch': 0, 'learner': 'adam', 'learning_rate': 0.01, 'weight_decay': 0, 'lr_epsilon': 1e-08, 'lr_beta1': 0.9, 'lr_beta2': 0.999, 'lr_alpha': 0.99, 'lr_momentum': 0, 'lr_decay': False, 'lr_scheduler': 'multisteplr', 'lr_decay_ratio': 0.1, 'steps': [5, 20, 40, 70], 'step_size': 10, 'lr_T_max': 30, 'lr_eta_min': 0, 'lr_patience': 10, 'lr_threshold': 0.0001, 'clip_grad_norm': False, 'max_grad_norm': 1.0, 'use_early_stop': True, 'patience': 5, 'log_level': 'INFO', 'log_every': 1, 'load_best_epoch': True, 'hyper_tune': False, 'metrics': ['MAE', 'MAPE', 'MSE', 'RMSE', 'masked_MAE', 'masked_MAPE', 'masked_MSE', 'masked_RMSE', 'R2', 'EVAR'], 'evaluator_mode': 'single', 'save_mode': ['csv'], 'geo': {'including_types': ['Point'], 'Point': {}}, 'rel': {'including_types': ['geo'], 'geo': {'cost': 'num'}}, 'dyna': {'including_types': ['state'], 'state': {'entity_id': 'geo_id', 'traffic_flow': 'num', 'traffic_occupancy': 'num', 'traffic_speed': 'num'}}, 'data_col': ['traffic_flow', 'traffic_occupancy', 'traffic_speed'], 'weight_col': 'cost', 'data_files': ['PEMSD4'], 'geo_file': 'PEMSD4', 'rel_file': 'PEMSD4', 'output_dim': 3, 'time_intervals': 300, 'init_weight_inf_or_zero': 'zero', 'set_weight_link_or_dist': 'link', 'calculate_weight_adj': False, 'weight_adj_epsilon': 0.1}
self.scaler_type  minmax01
2024-07-25 07:04:46,276 - INFO - Loaded file PEMSD4.geo, num_nodes=307
2024-07-25 07:04:46,277 - INFO - set_weight_link_or_dist: link
2024-07-25 07:04:46,277 - INFO - init_weight_inf_or_zero: zero
2024-07-25 07:04:46,279 - INFO - Loaded file PEMSD4.rel, shape=(307, 307)
2024-07-25 07:04:46,279 - INFO - Loading file PEMSD4.dyna
2024-07-25 07:04:48,826 - INFO - Loaded file PEMSD4.dyna, shape=(16992, 307, 3)
2024-07-25 07:05:36,716 - INFO - Dataset created
2024-07-25 07:05:36,716 - INFO - x shape: (16936, 48, 307, 3), y shape: (16936, 9, 307, 3)
2024-07-25 07:05:36,883 - INFO - train	x: (11855, 48, 307, 3), y: (11855, 9, 307, 3)
2024-07-25 07:05:36,883 - INFO - eval	x: (1694, 48, 307, 3), y: (1694, 9, 307, 3)
2024-07-25 07:05:36,883 - INFO - test	x: (3387, 48, 307, 3), y: (3387, 9, 307, 3)
2024-07-25 07:09:28,577 - INFO - Saved at ./libcity/cache/dataset_cache/point_based_PEMSD4_48_9_0.7_0.1_minmax01_32_False_False_False_True.npz
2024-07-25 07:09:29,103 - INFO - MinMax01Scaler max: 919.0, min: 0.0
2024-07-25 07:09:29,103 - INFO - NoneScaler
2024-07-25 07:09:37,206 - INFO - HierAttnLstm(
  (lstm_cells): ModuleList(
    (0): LSTMCell(921, 128)
    (1-2): 2 x LSTMCell(128, 128)
  )
  (hidden_state_pooling): ModuleList(
    (0-1): 2 x SelfAttentionPooling(
      (W): Linear(in_features=128, out_features=1, bias=True)
    )
  )
  (cell_state_pooling): ModuleList(
    (0-1): 2 x SelfAttentionPooling(
      (W): Linear(in_features=128, out_features=1, bias=True)
    )
  )
  (self_attention): SelfAttention(
    (ut_dense): Sequential(
      (0): Linear(in_features=128, out_features=128, bias=True)
      (1): Tanh()
    )
    (et_dense): Linear(in_features=128, out_features=3, bias=True)
    (softmax): Softmax(dim=-1)
  )
  (fc_layer): Sequential(
    (0): Linear(in_features=384, out_features=512, bias=True)
    (1): ReLU()
    (2): Linear(in_features=512, out_features=921, bias=True)
  )
)
2024-07-25 07:09:37,206 - INFO - lstm_cells.0.weight_ih	torch.Size([512, 921])	cuda:0	True
2024-07-25 07:09:37,206 - INFO - lstm_cells.0.weight_hh	torch.Size([512, 128])	cuda:0	True
2024-07-25 07:09:37,206 - INFO - lstm_cells.0.bias_ih	torch.Size([512])	cuda:0	True
2024-07-25 07:09:37,206 - INFO - lstm_cells.0.bias_hh	torch.Size([512])	cuda:0	True
2024-07-25 07:09:37,207 - INFO - lstm_cells.1.weight_ih	torch.Size([512, 128])	cuda:0	True
2024-07-25 07:09:37,207 - INFO - lstm_cells.1.weight_hh	torch.Size([512, 128])	cuda:0	True
2024-07-25 07:09:37,207 - INFO - lstm_cells.1.bias_ih	torch.Size([512])	cuda:0	True
2024-07-25 07:09:37,207 - INFO - lstm_cells.1.bias_hh	torch.Size([512])	cuda:0	True
2024-07-25 07:09:37,207 - INFO - lstm_cells.2.weight_ih	torch.Size([512, 128])	cuda:0	True
2024-07-25 07:09:37,207 - INFO - lstm_cells.2.weight_hh	torch.Size([512, 128])	cuda:0	True
2024-07-25 07:09:37,207 - INFO - lstm_cells.2.bias_ih	torch.Size([512])	cuda:0	True
2024-07-25 07:09:37,207 - INFO - lstm_cells.2.bias_hh	torch.Size([512])	cuda:0	True
2024-07-25 07:09:37,207 - INFO - hidden_state_pooling.0.W.weight	torch.Size([1, 128])	cuda:0	True
2024-07-25 07:09:37,207 - INFO - hidden_state_pooling.0.W.bias	torch.Size([1])	cuda:0	True
2024-07-25 07:09:37,207 - INFO - hidden_state_pooling.1.W.weight	torch.Size([1, 128])	cuda:0	True
2024-07-25 07:09:37,207 - INFO - hidden_state_pooling.1.W.bias	torch.Size([1])	cuda:0	True
2024-07-25 07:09:37,207 - INFO - cell_state_pooling.0.W.weight	torch.Size([1, 128])	cuda:0	True
2024-07-25 07:09:37,207 - INFO - cell_state_pooling.0.W.bias	torch.Size([1])	cuda:0	True
2024-07-25 07:09:37,207 - INFO - cell_state_pooling.1.W.weight	torch.Size([1, 128])	cuda:0	True
2024-07-25 07:09:37,207 - INFO - cell_state_pooling.1.W.bias	torch.Size([1])	cuda:0	True
2024-07-25 07:09:37,208 - INFO - self_attention.ut_dense.0.weight	torch.Size([128, 128])	cuda:0	True
2024-07-25 07:09:37,208 - INFO - self_attention.ut_dense.0.bias	torch.Size([128])	cuda:0	True
2024-07-25 07:09:37,208 - INFO - self_attention.et_dense.weight	torch.Size([3, 128])	cuda:0	True
2024-07-25 07:09:37,208 - INFO - self_attention.et_dense.bias	torch.Size([3])	cuda:0	True
2024-07-25 07:09:37,208 - INFO - fc_layer.0.weight	torch.Size([512, 384])	cuda:0	True
2024-07-25 07:09:37,208 - INFO - fc_layer.0.bias	torch.Size([512])	cuda:0	True
2024-07-25 07:09:37,208 - INFO - fc_layer.2.weight	torch.Size([921, 512])	cuda:0	True
2024-07-25 07:09:37,208 - INFO - fc_layer.2.bias	torch.Size([921])	cuda:0	True
2024-07-25 07:09:37,208 - INFO - Total parameter numbers: 1489312
2024-07-25 07:09:37,208 - INFO - You select `adam` optimizer.
2024-07-25 07:09:37,209 - WARNING - Received none train loss func and will use the loss func defined in the model.
2024-07-25 07:09:37,209 - INFO - Start training ...
2024-07-25 07:09:37,209 - INFO - num_batches:371
2024-07-25 07:12:12,227 - INFO - epoch complete!
2024-07-25 07:12:12,227 - INFO - evaluating now!
2024-07-25 07:12:18,910 - INFO - Epoch [0/100] train_loss: 20.8513, val_loss: 11.4365, lr: 0.010000, 161.70s
2024-07-25 07:12:18,934 - INFO - Saved model at 0
2024-07-25 07:12:18,934 - INFO - Val loss decrease from inf to 11.4365, saving to ./libcity/cache/00006/model_cache/HierAttnLstm_PEMSD4_epoch0.tar
2024-07-25 07:14:49,394 - INFO - epoch complete!
2024-07-25 07:14:49,395 - INFO - evaluating now!
2024-07-25 07:14:56,155 - INFO - Epoch [1/100] train_loss: 10.6412, val_loss: 10.8143, lr: 0.010000, 157.22s
2024-07-25 07:14:56,175 - INFO - Saved model at 1
2024-07-25 07:14:56,175 - INFO - Val loss decrease from 11.4365 to 10.8143, saving to ./libcity/cache/00006/model_cache/HierAttnLstm_PEMSD4_epoch1.tar
2024-07-25 07:17:26,890 - INFO - epoch complete!
2024-07-25 07:17:26,890 - INFO - evaluating now!
2024-07-25 07:17:33,544 - INFO - Epoch [2/100] train_loss: 9.9060, val_loss: 9.7108, lr: 0.010000, 157.37s
2024-07-25 07:17:33,567 - INFO - Saved model at 2
2024-07-25 07:17:33,567 - INFO - Val loss decrease from 10.8143 to 9.7108, saving to ./libcity/cache/00006/model_cache/HierAttnLstm_PEMSD4_epoch2.tar
2024-07-25 07:20:03,511 - INFO - epoch complete!
2024-07-25 07:20:03,511 - INFO - evaluating now!
2024-07-25 07:20:10,288 - INFO - Epoch [3/100] train_loss: 9.5194, val_loss: 9.3768, lr: 0.010000, 156.72s
2024-07-25 07:20:10,309 - INFO - Saved model at 3
2024-07-25 07:20:10,309 - INFO - Val loss decrease from 9.7108 to 9.3768, saving to ./libcity/cache/00006/model_cache/HierAttnLstm_PEMSD4_epoch3.tar
2024-07-25 07:22:40,753 - INFO - epoch complete!
2024-07-25 07:22:40,753 - INFO - evaluating now!
2024-07-25 07:22:47,264 - INFO - Epoch [4/100] train_loss: 9.2505, val_loss: 9.5049, lr: 0.010000, 156.95s
2024-07-25 07:25:17,798 - INFO - epoch complete!
2024-07-25 07:25:17,798 - INFO - evaluating now!
2024-07-25 07:25:24,412 - INFO - Epoch [5/100] train_loss: 9.1993, val_loss: 9.0395, lr: 0.010000, 157.15s
2024-07-25 07:25:24,433 - INFO - Saved model at 5
2024-07-25 07:25:24,433 - INFO - Val loss decrease from 9.3768 to 9.0395, saving to ./libcity/cache/00006/model_cache/HierAttnLstm_PEMSD4_epoch5.tar
2024-07-25 07:27:55,043 - INFO - epoch complete!
2024-07-25 07:27:55,043 - INFO - evaluating now!
2024-07-25 07:28:01,770 - INFO - Epoch [6/100] train_loss: 9.0363, val_loss: 9.0744, lr: 0.010000, 157.34s
2024-07-25 07:30:32,512 - INFO - epoch complete!
2024-07-25 07:30:32,512 - INFO - evaluating now!
2024-07-25 07:30:39,218 - INFO - Epoch [7/100] train_loss: 8.9821, val_loss: 8.9943, lr: 0.010000, 157.45s
2024-07-25 07:30:39,239 - INFO - Saved model at 7
2024-07-25 07:30:39,239 - INFO - Val loss decrease from 9.0395 to 8.9943, saving to ./libcity/cache/00006/model_cache/HierAttnLstm_PEMSD4_epoch7.tar
2024-07-25 07:33:10,817 - INFO - epoch complete!
2024-07-25 07:33:10,817 - INFO - evaluating now!
2024-07-25 07:33:17,412 - INFO - Epoch [8/100] train_loss: 8.9112, val_loss: 9.3793, lr: 0.010000, 158.17s
2024-07-25 07:35:47,576 - INFO - epoch complete!
2024-07-25 07:35:47,576 - INFO - evaluating now!
2024-07-25 07:35:54,329 - INFO - Epoch [9/100] train_loss: 8.8417, val_loss: 9.4970, lr: 0.010000, 156.92s
2024-07-25 07:38:25,039 - INFO - epoch complete!
2024-07-25 07:38:25,039 - INFO - evaluating now!
2024-07-25 07:38:31,747 - INFO - Epoch [10/100] train_loss: 8.8653, val_loss: 8.9489, lr: 0.010000, 157.42s
2024-07-25 07:38:31,774 - INFO - Saved model at 10
2024-07-25 07:38:31,774 - INFO - Val loss decrease from 8.9943 to 8.9489, saving to ./libcity/cache/00006/model_cache/HierAttnLstm_PEMSD4_epoch10.tar
2024-07-25 07:41:02,117 - INFO - epoch complete!
2024-07-25 07:41:02,118 - INFO - evaluating now!
2024-07-25 07:41:08,679 - INFO - Epoch [11/100] train_loss: 8.7928, val_loss: 8.9529, lr: 0.010000, 156.91s
2024-07-25 07:43:39,313 - INFO - epoch complete!
2024-07-25 07:43:39,313 - INFO - evaluating now!
2024-07-25 07:43:46,146 - INFO - Epoch [12/100] train_loss: 8.7073, val_loss: 8.9988, lr: 0.010000, 157.47s
2024-07-25 07:46:16,675 - INFO - epoch complete!
2024-07-25 07:46:16,675 - INFO - evaluating now!
2024-07-25 07:46:23,471 - INFO - Epoch [13/100] train_loss: 8.7199, val_loss: 9.3750, lr: 0.010000, 157.32s
2024-07-25 07:48:53,867 - INFO - epoch complete!
2024-07-25 07:48:53,867 - INFO - evaluating now!
2024-07-25 07:49:00,619 - INFO - Epoch [14/100] train_loss: 8.7180, val_loss: 9.4015, lr: 0.010000, 157.15s
2024-07-25 07:51:31,207 - INFO - epoch complete!
2024-07-25 07:51:31,207 - INFO - evaluating now!
2024-07-25 07:51:38,195 - INFO - Epoch [15/100] train_loss: 8.6674, val_loss: 8.6823, lr: 0.010000, 157.58s
2024-07-25 07:51:38,218 - INFO - Saved model at 15
2024-07-25 07:51:38,218 - INFO - Val loss decrease from 8.9489 to 8.6823, saving to ./libcity/cache/00006/model_cache/HierAttnLstm_PEMSD4_epoch15.tar
2024-07-25 07:54:09,624 - INFO - epoch complete!
2024-07-25 07:54:09,624 - INFO - evaluating now!
2024-07-25 07:54:16,292 - INFO - Epoch [16/100] train_loss: 8.6000, val_loss: 8.7497, lr: 0.010000, 158.07s
2024-07-25 07:56:47,781 - INFO - epoch complete!
2024-07-25 07:56:47,782 - INFO - evaluating now!
2024-07-25 07:56:54,709 - INFO - Epoch [17/100] train_loss: 8.5704, val_loss: 8.7899, lr: 0.010000, 158.42s
2024-07-25 07:59:25,077 - INFO - epoch complete!
2024-07-25 07:59:25,077 - INFO - evaluating now!
2024-07-25 07:59:31,815 - INFO - Epoch [18/100] train_loss: 8.6267, val_loss: 9.1056, lr: 0.010000, 157.11s
2024-07-25 08:02:03,109 - INFO - epoch complete!
2024-07-25 08:02:03,109 - INFO - evaluating now!
2024-07-25 08:02:10,025 - INFO - Epoch [19/100] train_loss: 8.5510, val_loss: 8.8921, lr: 0.010000, 158.21s
2024-07-25 08:04:40,428 - INFO - epoch complete!
2024-07-25 08:04:40,428 - INFO - evaluating now!
2024-07-25 08:04:47,131 - INFO - Epoch [20/100] train_loss: 8.5604, val_loss: 8.7254, lr: 0.010000, 157.11s
2024-07-25 08:04:47,132 - WARNING - Early stopping at epoch: 20
2024-07-25 08:04:47,132 - INFO - Trained totally 21 epochs, average train time is 150.875s, average eval time is 6.732s
2024-07-25 08:04:47,151 - INFO - Loaded model at 15
2024-07-25 08:04:47,151 - INFO - Saved model at ./libcity/cache/00006/model_cache/HierAttnLstm_PEMSD4.m
2024-07-25 08:04:47,174 - INFO - Start evaluating ...
2024-07-25 08:05:04,744 - INFO - Note that you select the single mode to evaluate!
2024-07-25 08:05:04,747 - INFO - Evaluate result is saved at ./libcity/cache/00006/evaluate_cache\2024_07_25_08_05_04_HierAttnLstm_PEMSD4.csv
2024-07-25 08:05:04,756 - INFO - 
        MAE        MAPE         MSE  ...  masked_RMSE        R2      EVAR
1  9.075498  21050220.0  523.624512  ...    21.743410  0.968608  0.968627
2  9.076323  21050150.0  523.696350  ...    21.745041  0.968604  0.968623
3  9.076727  21047290.0  523.728455  ...    21.745743  0.968603  0.968621
4  9.077043  21047418.0  523.752625  ...    21.746283  0.968601  0.968620
5  9.077224  21048304.0  523.768921  ...    21.746653  0.968601  0.968619
6  9.077489  21048480.0  523.792419  ...    21.747196  0.968599  0.968618
7  9.077410  21042638.0  523.785950  ...    21.747059  0.968600  0.968618
8  9.077257  21038934.0  523.777649  ...    21.746893  0.968600  0.968619
9  9.122851  20937300.0  527.585693  ...    21.838671  0.968372  0.968401

[9 rows x 10 columns]

Standard Error:
