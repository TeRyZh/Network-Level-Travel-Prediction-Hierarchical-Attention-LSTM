Command:
python run_model.py --task traffic_state_pred --model HierAttnLstm --dataset PEMSD8

Standard Output:
2024-07-23 06:42:24,908 - INFO - Log directory: ./libcity/log
2024-07-23 06:42:24,909 - INFO - Begin pipeline, task=traffic_state_pred, model_name=HierAttnLstm, dataset_name=PEMSD8, exp_id=12262
2024-07-23 06:42:24,909 - INFO - {'task': 'traffic_state_pred', 'model': 'HierAttnLstm', 'dataset': 'PEMSD8', 'saved_model': True, 'train': True, 'seed': 0, 'dataset_class': 'TrafficStatePointDataset', 'executor': 'TrafficStateExecutor', 'evaluator': 'TrafficStateEvaluator', 'input_window': 48, 'output_window': 6, 'device': device(type='cuda', index=0), 'hidden_size': 128, 'num_layers': 3, 'dropout': 0.1, 'natt_hops': 3, 'nfc': 512, 'max_up_len': 96, 'batch_size': 32, 'cache_dataset': True, 'num_workers': 0, 'pad_with_last_sample': True, 'train_rate': 0.7, 'eval_rate': 0.1, 'scaler': 'minmax01', 'load_external': False, 'normal_external': False, 'ext_scaler': 'none', 'add_time_in_day': False, 'add_day_in_week': False, 'robustness_test': False, 'noise_type': 'gaussian', 'disturb_rate': 0.5, 'noise_mean': [5], 'noise_SD': [10], 'gpu': True, 'gpu_id': 0, 'max_epoch': 100, 'train_loss': 'none', 'epoch': 0, 'learner': 'adam', 'learning_rate': 0.01, 'weight_decay': 0, 'lr_epsilon': 1e-08, 'lr_beta1': 0.9, 'lr_beta2': 0.999, 'lr_alpha': 0.99, 'lr_momentum': 0, 'lr_decay': False, 'lr_scheduler': 'multisteplr', 'lr_decay_ratio': 0.1, 'steps': [5, 20, 40, 70], 'step_size': 10, 'lr_T_max': 30, 'lr_eta_min': 0, 'lr_patience': 10, 'lr_threshold': 0.0001, 'clip_grad_norm': False, 'max_grad_norm': 1.0, 'use_early_stop': True, 'patience': 10, 'log_level': 'INFO', 'log_every': 1, 'load_best_epoch': True, 'hyper_tune': False, 'metrics': ['MAE', 'MAPE', 'MSE', 'RMSE', 'masked_MAE', 'masked_MAPE', 'masked_MSE', 'masked_RMSE', 'R2', 'EVAR'], 'evaluator_mode': 'single', 'save_mode': ['csv'], 'geo': {'including_types': ['Point'], 'Point': {}}, 'rel': {'including_types': ['geo'], 'geo': {'cost': 'num'}}, 'dyna': {'including_types': ['state'], 'state': {'entity_id': 'geo_id', 'traffic_flow': 'num', 'traffic_occupancy': 'num', 'traffic_speed': 'num'}}, 'data_col': ['traffic_flow', 'traffic_occupancy', 'traffic_speed'], 'weight_col': 'cost', 'data_files': ['PEMSD8'], 'geo_file': 'PEMSD8', 'rel_file': 'PEMSD8', 'output_dim': 3, 'time_intervals': 300, 'init_weight_inf_or_zero': 'zero', 'set_weight_link_or_dist': 'link', 'calculate_weight_adj': False, 'weight_adj_epsilon': 0.1, 'exp_id': 12262}
self.scaler_type  minmax01
2024-07-23 06:42:24,958 - INFO - Loaded file PEMSD8.geo, num_nodes=170
2024-07-23 06:42:24,987 - INFO - set_weight_link_or_dist: link
2024-07-23 06:42:24,987 - INFO - init_weight_inf_or_zero: zero
2024-07-23 06:42:24,988 - INFO - Loaded file PEMSD8.rel, shape=(170, 170)
2024-07-23 06:42:24,988 - INFO - Loading file PEMSD8.dyna
2024-07-23 06:42:26,397 - INFO - Loaded file PEMSD8.dyna, shape=(17856, 170, 3)
2024-07-23 06:42:30,691 - INFO - Dataset created
2024-07-23 06:42:30,691 - INFO - x shape: (17803, 48, 170, 3), y shape: (17803, 6, 170, 3)
2024-07-23 06:42:30,807 - INFO - train	x: (12462, 48, 170, 3), y: (12462, 6, 170, 3)
2024-07-23 06:42:30,807 - INFO - eval	x: (1780, 48, 170, 3), y: (1780, 6, 170, 3)
2024-07-23 06:42:30,807 - INFO - test	x: (3561, 48, 170, 3), y: (3561, 6, 170, 3)
2024-07-23 06:44:16,389 - INFO - Saved at ./libcity/cache/dataset_cache/point_based_PEMSD8_48_6_0.7_0.1_minmax01_32_False_False_False_True.npz
2024-07-23 06:44:16,674 - INFO - MinMax01Scaler max: 1147.0, min: 0.0
2024-07-23 06:44:16,675 - INFO - NoneScaler
2024-07-23 06:44:20,406 - INFO - HierAttnLstm(
  (lstm_cells): ModuleList(
    (0): LSTMCell(510, 128)
    (1-2): 2 x LSTMCell(128, 128)
  )
  (hidden_state_pooling): ModuleList(
    (0-1): 2 x SelfAttentionPooling(
      (W): Linear(in_features=128, out_features=1, bias=True)
    )
  )
  (cell_state_pooling): ModuleList(
    (0-1): 2 x SelfAttentionPooling(
      (W): Linear(in_features=128, out_features=1, bias=True)
    )
  )
  (self_attention): SelfAttention(
    (ut_dense): Sequential(
      (0): Linear(in_features=128, out_features=128, bias=True)
      (1): Tanh()
    )
    (et_dense): Linear(in_features=128, out_features=3, bias=True)
    (softmax): Softmax(dim=-1)
  )
  (fc_layer): Sequential(
    (0): Linear(in_features=384, out_features=512, bias=True)
    (1): ReLU()
    (2): Linear(in_features=512, out_features=510, bias=True)
  )
)
2024-07-23 06:44:20,406 - INFO - lstm_cells.0.weight_ih	torch.Size([512, 510])	cuda:0	True
2024-07-23 06:44:20,406 - INFO - lstm_cells.0.weight_hh	torch.Size([512, 128])	cuda:0	True
2024-07-23 06:44:20,406 - INFO - lstm_cells.0.bias_ih	torch.Size([512])	cuda:0	True
2024-07-23 06:44:20,407 - INFO - lstm_cells.0.bias_hh	torch.Size([512])	cuda:0	True
2024-07-23 06:44:20,407 - INFO - lstm_cells.1.weight_ih	torch.Size([512, 128])	cuda:0	True
2024-07-23 06:44:20,407 - INFO - lstm_cells.1.weight_hh	torch.Size([512, 128])	cuda:0	True
2024-07-23 06:44:20,407 - INFO - lstm_cells.1.bias_ih	torch.Size([512])	cuda:0	True
2024-07-23 06:44:20,407 - INFO - lstm_cells.1.bias_hh	torch.Size([512])	cuda:0	True
2024-07-23 06:44:20,407 - INFO - lstm_cells.2.weight_ih	torch.Size([512, 128])	cuda:0	True
2024-07-23 06:44:20,407 - INFO - lstm_cells.2.weight_hh	torch.Size([512, 128])	cuda:0	True
2024-07-23 06:44:20,407 - INFO - lstm_cells.2.bias_ih	torch.Size([512])	cuda:0	True
2024-07-23 06:44:20,407 - INFO - lstm_cells.2.bias_hh	torch.Size([512])	cuda:0	True
2024-07-23 06:44:20,407 - INFO - hidden_state_pooling.0.W.weight	torch.Size([1, 128])	cuda:0	True
2024-07-23 06:44:20,407 - INFO - hidden_state_pooling.0.W.bias	torch.Size([1])	cuda:0	True
2024-07-23 06:44:20,407 - INFO - hidden_state_pooling.1.W.weight	torch.Size([1, 128])	cuda:0	True
2024-07-23 06:44:20,407 - INFO - hidden_state_pooling.1.W.bias	torch.Size([1])	cuda:0	True
2024-07-23 06:44:20,407 - INFO - cell_state_pooling.0.W.weight	torch.Size([1, 128])	cuda:0	True
2024-07-23 06:44:20,407 - INFO - cell_state_pooling.0.W.bias	torch.Size([1])	cuda:0	True
2024-07-23 06:44:20,407 - INFO - cell_state_pooling.1.W.weight	torch.Size([1, 128])	cuda:0	True
2024-07-23 06:44:20,407 - INFO - cell_state_pooling.1.W.bias	torch.Size([1])	cuda:0	True
2024-07-23 06:44:20,408 - INFO - self_attention.ut_dense.0.weight	torch.Size([128, 128])	cuda:0	True
2024-07-23 06:44:20,408 - INFO - self_attention.ut_dense.0.bias	torch.Size([128])	cuda:0	True
2024-07-23 06:44:20,408 - INFO - self_attention.et_dense.weight	torch.Size([3, 128])	cuda:0	True
2024-07-23 06:44:20,408 - INFO - self_attention.et_dense.bias	torch.Size([3])	cuda:0	True
2024-07-23 06:44:20,408 - INFO - fc_layer.0.weight	torch.Size([512, 384])	cuda:0	True
2024-07-23 06:44:20,408 - INFO - fc_layer.0.bias	torch.Size([512])	cuda:0	True
2024-07-23 06:44:20,408 - INFO - fc_layer.2.weight	torch.Size([510, 512])	cuda:0	True
2024-07-23 06:44:20,408 - INFO - fc_layer.2.bias	torch.Size([510])	cuda:0	True
2024-07-23 06:44:20,408 - INFO - Total parameter numbers: 1068037
2024-07-23 06:44:20,408 - INFO - You select `adam` optimizer.
2024-07-23 06:44:20,408 - WARNING - Received none train loss func and will use the loss func defined in the model.
2024-07-23 06:44:20,409 - INFO - Start training ...
2024-07-23 06:44:20,409 - INFO - num_batches:390
2024-07-23 06:46:12,352 - INFO - epoch complete!
2024-07-23 06:46:12,352 - INFO - evaluating now!
2024-07-23 06:46:17,043 - INFO - Epoch [0/100] train_loss: 19.8564, val_loss: 12.1140, lr: 0.010000, 116.63s
2024-07-23 06:46:17,068 - INFO - Saved model at 0
2024-07-23 06:46:17,068 - INFO - Val loss decrease from inf to 12.1140, saving to ./libcity/cache/12262/model_cache/HierAttnLstm_PEMSD8_epoch0.tar
2024-07-23 06:48:08,949 - INFO - epoch complete!
2024-07-23 06:48:08,949 - INFO - evaluating now!
2024-07-23 06:48:13,734 - INFO - Epoch [1/100] train_loss: 10.3322, val_loss: 11.6897, lr: 0.010000, 116.67s
2024-07-23 06:48:13,759 - INFO - Saved model at 1
2024-07-23 06:48:13,759 - INFO - Val loss decrease from 12.1140 to 11.6897, saving to ./libcity/cache/12262/model_cache/HierAttnLstm_PEMSD8_epoch1.tar
2024-07-23 06:50:05,729 - INFO - epoch complete!
2024-07-23 06:50:05,729 - INFO - evaluating now!
2024-07-23 06:50:10,385 - INFO - Epoch [2/100] train_loss: 9.8111, val_loss: 11.3853, lr: 0.010000, 116.63s
2024-07-23 06:50:10,408 - INFO - Saved model at 2
2024-07-23 06:50:10,408 - INFO - Val loss decrease from 11.6897 to 11.3853, saving to ./libcity/cache/12262/model_cache/HierAttnLstm_PEMSD8_epoch2.tar
2024-07-23 06:52:02,616 - INFO - epoch complete!
2024-07-23 06:52:02,616 - INFO - evaluating now!
2024-07-23 06:52:07,288 - INFO - Epoch [3/100] train_loss: 9.3449, val_loss: 10.8179, lr: 0.010000, 116.88s
2024-07-23 06:52:07,312 - INFO - Saved model at 3
2024-07-23 06:52:07,312 - INFO - Val loss decrease from 11.3853 to 10.8179, saving to ./libcity/cache/12262/model_cache/HierAttnLstm_PEMSD8_epoch3.tar
2024-07-23 06:53:59,658 - INFO - epoch complete!
2024-07-23 06:53:59,658 - INFO - evaluating now!
2024-07-23 06:54:04,535 - INFO - Epoch [4/100] train_loss: 9.1086, val_loss: 10.6516, lr: 0.010000, 117.22s
2024-07-23 06:54:04,560 - INFO - Saved model at 4
2024-07-23 06:54:04,560 - INFO - Val loss decrease from 10.8179 to 10.6516, saving to ./libcity/cache/12262/model_cache/HierAttnLstm_PEMSD8_epoch4.tar
2024-07-23 06:55:56,036 - INFO - epoch complete!
2024-07-23 06:55:56,036 - INFO - evaluating now!
2024-07-23 06:56:00,734 - INFO - Epoch [5/100] train_loss: 9.0479, val_loss: 11.1356, lr: 0.010000, 116.17s
2024-07-23 06:57:53,151 - INFO - epoch complete!
2024-07-23 06:57:53,151 - INFO - evaluating now!
2024-07-23 06:57:57,875 - INFO - Epoch [6/100] train_loss: 9.0138, val_loss: 10.6083, lr: 0.010000, 117.14s
2024-07-23 06:57:57,909 - INFO - Saved model at 6
2024-07-23 06:57:57,909 - INFO - Val loss decrease from 10.6516 to 10.6083, saving to ./libcity/cache/12262/model_cache/HierAttnLstm_PEMSD8_epoch6.tar
2024-07-23 06:59:50,034 - INFO - epoch complete!
2024-07-23 06:59:50,034 - INFO - evaluating now!
2024-07-23 06:59:54,857 - INFO - Epoch [7/100] train_loss: 8.9242, val_loss: 10.7785, lr: 0.010000, 116.95s
2024-07-23 07:01:46,742 - INFO - epoch complete!
2024-07-23 07:01:46,743 - INFO - evaluating now!
2024-07-23 07:01:51,571 - INFO - Epoch [8/100] train_loss: 8.8237, val_loss: 10.6283, lr: 0.010000, 116.71s
2024-07-23 07:03:42,705 - INFO - epoch complete!
2024-07-23 07:03:42,705 - INFO - evaluating now!
2024-07-23 07:03:47,405 - INFO - Epoch [9/100] train_loss: 8.8228, val_loss: 10.4571, lr: 0.010000, 115.83s
2024-07-23 07:03:47,429 - INFO - Saved model at 9
2024-07-23 07:03:47,429 - INFO - Val loss decrease from 10.6083 to 10.4571, saving to ./libcity/cache/12262/model_cache/HierAttnLstm_PEMSD8_epoch9.tar
2024-07-23 07:05:38,801 - INFO - epoch complete!
2024-07-23 07:05:38,801 - INFO - evaluating now!
2024-07-23 07:05:43,517 - INFO - Epoch [10/100] train_loss: 8.8257, val_loss: 10.3240, lr: 0.010000, 116.09s
2024-07-23 07:05:43,542 - INFO - Saved model at 10
2024-07-23 07:05:43,542 - INFO - Val loss decrease from 10.4571 to 10.3240, saving to ./libcity/cache/12262/model_cache/HierAttnLstm_PEMSD8_epoch10.tar
2024-07-23 07:07:34,471 - INFO - epoch complete!
2024-07-23 07:07:34,471 - INFO - evaluating now!
2024-07-23 07:07:39,172 - INFO - Epoch [11/100] train_loss: 8.7616, val_loss: 10.4198, lr: 0.010000, 115.63s
2024-07-23 07:09:30,426 - INFO - epoch complete!
2024-07-23 07:09:30,426 - INFO - evaluating now!
2024-07-23 07:09:35,130 - INFO - Epoch [12/100] train_loss: 8.7052, val_loss: 10.2703, lr: 0.010000, 115.96s
2024-07-23 07:09:35,153 - INFO - Saved model at 12
2024-07-23 07:09:35,153 - INFO - Val loss decrease from 10.3240 to 10.2703, saving to ./libcity/cache/12262/model_cache/HierAttnLstm_PEMSD8_epoch12.tar
2024-07-23 07:11:26,343 - INFO - epoch complete!
2024-07-23 07:11:26,343 - INFO - evaluating now!
2024-07-23 07:11:30,999 - INFO - Epoch [13/100] train_loss: 8.7769, val_loss: 10.5553, lr: 0.010000, 115.85s
2024-07-23 07:13:22,511 - INFO - epoch complete!
2024-07-23 07:13:22,511 - INFO - evaluating now!
2024-07-23 07:13:27,278 - INFO - Epoch [14/100] train_loss: 8.7280, val_loss: 10.4958, lr: 0.010000, 116.28s
2024-07-23 07:15:18,756 - INFO - epoch complete!
2024-07-23 07:15:18,756 - INFO - evaluating now!
2024-07-23 07:15:23,479 - INFO - Epoch [15/100] train_loss: 8.6062, val_loss: 10.3339, lr: 0.010000, 116.20s
2024-07-23 07:17:14,492 - INFO - epoch complete!
2024-07-23 07:17:14,492 - INFO - evaluating now!
2024-07-23 07:17:19,109 - INFO - Epoch [16/100] train_loss: 8.7228, val_loss: 10.5245, lr: 0.010000, 115.63s
2024-07-23 07:19:09,919 - INFO - epoch complete!
2024-07-23 07:19:09,919 - INFO - evaluating now!
2024-07-23 07:19:14,603 - INFO - Epoch [17/100] train_loss: 8.6839, val_loss: 10.4995, lr: 0.010000, 115.49s
2024-07-23 07:21:05,147 - INFO - epoch complete!
2024-07-23 07:21:05,148 - INFO - evaluating now!
2024-07-23 07:21:09,836 - INFO - Epoch [18/100] train_loss: 8.6718, val_loss: 10.3436, lr: 0.010000, 115.23s
2024-07-23 07:23:01,097 - INFO - epoch complete!
2024-07-23 07:23:01,097 - INFO - evaluating now!
2024-07-23 07:23:05,754 - INFO - Epoch [19/100] train_loss: 8.5815, val_loss: 10.2162, lr: 0.010000, 115.92s
2024-07-23 07:23:05,779 - INFO - Saved model at 19
2024-07-23 07:23:05,779 - INFO - Val loss decrease from 10.2703 to 10.2162, saving to ./libcity/cache/12262/model_cache/HierAttnLstm_PEMSD8_epoch19.tar
2024-07-23 07:24:57,452 - INFO - epoch complete!
2024-07-23 07:24:57,452 - INFO - evaluating now!
2024-07-23 07:25:02,205 - INFO - Epoch [20/100] train_loss: 8.6254, val_loss: 10.5712, lr: 0.010000, 116.43s
2024-07-23 07:26:53,671 - INFO - epoch complete!
2024-07-23 07:26:53,671 - INFO - evaluating now!
2024-07-23 07:26:58,295 - INFO - Epoch [21/100] train_loss: 8.6051, val_loss: 10.3993, lr: 0.010000, 116.09s
2024-07-23 07:28:49,426 - INFO - epoch complete!
2024-07-23 07:28:49,426 - INFO - evaluating now!
2024-07-23 07:28:54,098 - INFO - Epoch [22/100] train_loss: 8.6188, val_loss: 10.4668, lr: 0.010000, 115.80s
2024-07-23 07:30:44,895 - INFO - epoch complete!
2024-07-23 07:30:44,895 - INFO - evaluating now!
2024-07-23 07:30:49,633 - INFO - Epoch [23/100] train_loss: 8.5523, val_loss: 10.3632, lr: 0.010000, 115.53s
2024-07-23 07:32:40,498 - INFO - epoch complete!
2024-07-23 07:32:40,499 - INFO - evaluating now!
2024-07-23 07:32:45,274 - INFO - Epoch [24/100] train_loss: 8.5600, val_loss: 10.5016, lr: 0.010000, 115.64s
2024-07-23 07:34:36,341 - INFO - epoch complete!
2024-07-23 07:34:36,341 - INFO - evaluating now!
2024-07-23 07:34:41,045 - INFO - Epoch [25/100] train_loss: 8.5881, val_loss: 10.3420, lr: 0.010000, 115.77s
2024-07-23 07:36:32,869 - INFO - epoch complete!
2024-07-23 07:36:32,869 - INFO - evaluating now!
2024-07-23 07:36:37,524 - INFO - Epoch [26/100] train_loss: 8.5641, val_loss: 10.4437, lr: 0.010000, 116.48s
2024-07-23 07:38:28,113 - INFO - epoch complete!
2024-07-23 07:38:28,114 - INFO - evaluating now!
2024-07-23 07:38:32,785 - INFO - Epoch [27/100] train_loss: 8.5726, val_loss: 10.3283, lr: 0.010000, 115.26s
2024-07-23 07:40:23,616 - INFO - epoch complete!
2024-07-23 07:40:23,616 - INFO - evaluating now!
2024-07-23 07:40:28,425 - INFO - Epoch [28/100] train_loss: 8.5281, val_loss: 10.2287, lr: 0.010000, 115.64s
2024-07-23 07:42:19,668 - INFO - epoch complete!
2024-07-23 07:42:19,668 - INFO - evaluating now!
2024-07-23 07:42:24,294 - INFO - Epoch [29/100] train_loss: 8.4947, val_loss: 10.6337, lr: 0.010000, 115.87s
2024-07-23 07:42:24,295 - WARNING - Early stopping at epoch: 29
2024-07-23 07:42:24,295 - INFO - Trained totally 30 epochs, average train time is 111.407s, average eval time is 4.713s
2024-07-23 07:42:24,311 - INFO - Loaded model at 19
2024-07-23 07:42:24,311 - INFO - Saved model at ./libcity/cache/12262/model_cache/HierAttnLstm_PEMSD8.m
2024-07-23 07:42:24,335 - INFO - Start evaluating ...
2024-07-23 07:42:35,082 - INFO - Note that you select the single mode to evaluate!
2024-07-23 07:42:35,085 - INFO - Evaluate result is saved at ./libcity/cache/12262/evaluate_cache\2024_07_23_07_42_35_HierAttnLstm_PEMSD8.csv
2024-07-23 07:42:35,094 - INFO - 
        MAE         MAPE         MSE  ...  masked_RMSE        R2      EVAR
1  9.163513  1139903.875  511.529602  ...    22.591078  0.969279  0.969315
2  9.160967  1139903.875  511.214905  ...    22.584095  0.969284  0.969320
3  9.158655  1140037.125  510.904053  ...    22.577208  0.969289  0.969325
4  9.156294  1140322.500  510.599243  ...    22.570467  0.969294  0.969330
5  9.153967  1140322.375  510.295074  ...    22.563713  0.969299  0.969335
6  9.151646  1140784.000  510.004089  ...    22.557274  0.969303  0.969339

[6 rows x 10 columns]

Standard Error:
