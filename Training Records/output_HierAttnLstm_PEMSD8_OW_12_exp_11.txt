Command:
python run_model.py --task traffic_state_pred --model HierAttnLstm --dataset PEMSD8 --config_file HierAttnLstm_OW_12 --exp_id 00011

Standard Output:
2024-07-25 10:53:32,778 - INFO - Log directory: ./libcity/log
2024-07-25 10:53:32,778 - INFO - Begin pipeline, task=traffic_state_pred, model_name=HierAttnLstm, dataset_name=PEMSD8, exp_id=00011
2024-07-25 10:53:32,778 - INFO - {'task': 'traffic_state_pred', 'model': 'HierAttnLstm', 'dataset': 'PEMSD8', 'saved_model': True, 'train': True, 'exp_id': '00011', 'seed': 0, 'input_window': 48, 'output_window': 12, 'device': device(type='cuda', index=0), 'hidden_size': 128, 'num_layers': 3, 'dropout': 0.1, 'natt_hops': 3, 'nfc': 512, 'max_up_len': 96, 'dataset_class': 'TrafficStatePointDataset', 'executor': 'TrafficStateExecutor', 'evaluator': 'TrafficStateEvaluator', 'batch_size': 32, 'cache_dataset': True, 'num_workers': 0, 'pad_with_last_sample': True, 'train_rate': 0.7, 'eval_rate': 0.1, 'scaler': 'minmax01', 'load_external': False, 'normal_external': False, 'ext_scaler': 'none', 'add_time_in_day': False, 'add_day_in_week': False, 'robustness_test': False, 'noise_type': 'gaussian', 'disturb_rate': 0.5, 'noise_mean': [5], 'noise_SD': [10], 'gpu': True, 'gpu_id': 0, 'max_epoch': 100, 'train_loss': 'none', 'epoch': 0, 'learner': 'adam', 'learning_rate': 0.01, 'weight_decay': 0, 'lr_epsilon': 1e-08, 'lr_beta1': 0.9, 'lr_beta2': 0.999, 'lr_alpha': 0.99, 'lr_momentum': 0, 'lr_decay': False, 'lr_scheduler': 'multisteplr', 'lr_decay_ratio': 0.1, 'steps': [5, 20, 40, 70], 'step_size': 10, 'lr_T_max': 30, 'lr_eta_min': 0, 'lr_patience': 10, 'lr_threshold': 0.0001, 'clip_grad_norm': False, 'max_grad_norm': 1.0, 'use_early_stop': True, 'patience': 5, 'log_level': 'INFO', 'log_every': 1, 'load_best_epoch': True, 'hyper_tune': False, 'metrics': ['MAE', 'MAPE', 'MSE', 'RMSE', 'masked_MAE', 'masked_MAPE', 'masked_MSE', 'masked_RMSE', 'R2', 'EVAR'], 'evaluator_mode': 'single', 'save_mode': ['csv'], 'geo': {'including_types': ['Point'], 'Point': {}}, 'rel': {'including_types': ['geo'], 'geo': {'cost': 'num'}}, 'dyna': {'including_types': ['state'], 'state': {'entity_id': 'geo_id', 'traffic_flow': 'num', 'traffic_occupancy': 'num', 'traffic_speed': 'num'}}, 'data_col': ['traffic_flow', 'traffic_occupancy', 'traffic_speed'], 'weight_col': 'cost', 'data_files': ['PEMSD8'], 'geo_file': 'PEMSD8', 'rel_file': 'PEMSD8', 'output_dim': 3, 'time_intervals': 300, 'init_weight_inf_or_zero': 'zero', 'set_weight_link_or_dist': 'link', 'calculate_weight_adj': False, 'weight_adj_epsilon': 0.1}
self.scaler_type  minmax01
2024-07-25 10:53:32,804 - INFO - Loaded file PEMSD8.geo, num_nodes=170
2024-07-25 10:53:32,813 - INFO - set_weight_link_or_dist: link
2024-07-25 10:53:32,813 - INFO - init_weight_inf_or_zero: zero
2024-07-25 10:53:32,814 - INFO - Loaded file PEMSD8.rel, shape=(170, 170)
2024-07-25 10:53:32,814 - INFO - Loading file PEMSD8.dyna
2024-07-25 10:53:34,282 - INFO - Loaded file PEMSD8.dyna, shape=(17856, 170, 3)
2024-07-25 10:53:39,402 - INFO - Dataset created
2024-07-25 10:53:39,403 - INFO - x shape: (17797, 48, 170, 3), y shape: (17797, 12, 170, 3)
2024-07-25 10:53:39,557 - INFO - train	x: (12458, 48, 170, 3), y: (12458, 12, 170, 3)
2024-07-25 10:53:39,557 - INFO - eval	x: (1780, 48, 170, 3), y: (1780, 12, 170, 3)
2024-07-25 10:53:39,557 - INFO - test	x: (3559, 48, 170, 3), y: (3559, 12, 170, 3)
2024-07-25 10:55:47,761 - INFO - Saved at ./libcity/cache/dataset_cache/point_based_PEMSD8_48_12_0.7_0.1_minmax01_32_False_False_False_True.npz
2024-07-25 10:55:48,076 - INFO - MinMax01Scaler max: 1147.0, min: 0.0
2024-07-25 10:55:48,076 - INFO - NoneScaler
2024-07-25 10:55:51,649 - INFO - HierAttnLstm(
  (lstm_cells): ModuleList(
    (0): LSTMCell(510, 128)
    (1-2): 2 x LSTMCell(128, 128)
  )
  (hidden_state_pooling): ModuleList(
    (0-1): 2 x SelfAttentionPooling(
      (W): Linear(in_features=128, out_features=1, bias=True)
    )
  )
  (cell_state_pooling): ModuleList(
    (0-1): 2 x SelfAttentionPooling(
      (W): Linear(in_features=128, out_features=1, bias=True)
    )
  )
  (self_attention): SelfAttention(
    (ut_dense): Sequential(
      (0): Linear(in_features=128, out_features=128, bias=True)
      (1): Tanh()
    )
    (et_dense): Linear(in_features=128, out_features=3, bias=True)
    (softmax): Softmax(dim=-1)
  )
  (fc_layer): Sequential(
    (0): Linear(in_features=384, out_features=512, bias=True)
    (1): ReLU()
    (2): Linear(in_features=512, out_features=510, bias=True)
  )
)
2024-07-25 10:55:51,650 - INFO - lstm_cells.0.weight_ih	torch.Size([512, 510])	cuda:0	True
2024-07-25 10:55:51,650 - INFO - lstm_cells.0.weight_hh	torch.Size([512, 128])	cuda:0	True
2024-07-25 10:55:51,650 - INFO - lstm_cells.0.bias_ih	torch.Size([512])	cuda:0	True
2024-07-25 10:55:51,650 - INFO - lstm_cells.0.bias_hh	torch.Size([512])	cuda:0	True
2024-07-25 10:55:51,650 - INFO - lstm_cells.1.weight_ih	torch.Size([512, 128])	cuda:0	True
2024-07-25 10:55:51,650 - INFO - lstm_cells.1.weight_hh	torch.Size([512, 128])	cuda:0	True
2024-07-25 10:55:51,650 - INFO - lstm_cells.1.bias_ih	torch.Size([512])	cuda:0	True
2024-07-25 10:55:51,650 - INFO - lstm_cells.1.bias_hh	torch.Size([512])	cuda:0	True
2024-07-25 10:55:51,650 - INFO - lstm_cells.2.weight_ih	torch.Size([512, 128])	cuda:0	True
2024-07-25 10:55:51,650 - INFO - lstm_cells.2.weight_hh	torch.Size([512, 128])	cuda:0	True
2024-07-25 10:55:51,650 - INFO - lstm_cells.2.bias_ih	torch.Size([512])	cuda:0	True
2024-07-25 10:55:51,650 - INFO - lstm_cells.2.bias_hh	torch.Size([512])	cuda:0	True
2024-07-25 10:55:51,650 - INFO - hidden_state_pooling.0.W.weight	torch.Size([1, 128])	cuda:0	True
2024-07-25 10:55:51,650 - INFO - hidden_state_pooling.0.W.bias	torch.Size([1])	cuda:0	True
2024-07-25 10:55:51,651 - INFO - hidden_state_pooling.1.W.weight	torch.Size([1, 128])	cuda:0	True
2024-07-25 10:55:51,651 - INFO - hidden_state_pooling.1.W.bias	torch.Size([1])	cuda:0	True
2024-07-25 10:55:51,651 - INFO - cell_state_pooling.0.W.weight	torch.Size([1, 128])	cuda:0	True
2024-07-25 10:55:51,651 - INFO - cell_state_pooling.0.W.bias	torch.Size([1])	cuda:0	True
2024-07-25 10:55:51,651 - INFO - cell_state_pooling.1.W.weight	torch.Size([1, 128])	cuda:0	True
2024-07-25 10:55:51,651 - INFO - cell_state_pooling.1.W.bias	torch.Size([1])	cuda:0	True
2024-07-25 10:55:51,651 - INFO - self_attention.ut_dense.0.weight	torch.Size([128, 128])	cuda:0	True
2024-07-25 10:55:51,651 - INFO - self_attention.ut_dense.0.bias	torch.Size([128])	cuda:0	True
2024-07-25 10:55:51,651 - INFO - self_attention.et_dense.weight	torch.Size([3, 128])	cuda:0	True
2024-07-25 10:55:51,651 - INFO - self_attention.et_dense.bias	torch.Size([3])	cuda:0	True
2024-07-25 10:55:51,651 - INFO - fc_layer.0.weight	torch.Size([512, 384])	cuda:0	True
2024-07-25 10:55:51,651 - INFO - fc_layer.0.bias	torch.Size([512])	cuda:0	True
2024-07-25 10:55:51,651 - INFO - fc_layer.2.weight	torch.Size([510, 512])	cuda:0	True
2024-07-25 10:55:51,651 - INFO - fc_layer.2.bias	torch.Size([510])	cuda:0	True
2024-07-25 10:55:51,651 - INFO - Total parameter numbers: 1068037
2024-07-25 10:55:51,651 - INFO - You select `adam` optimizer.
2024-07-25 10:55:51,652 - WARNING - Received none train loss func and will use the loss func defined in the model.
2024-07-25 10:55:51,652 - INFO - Start training ...
2024-07-25 10:55:51,652 - INFO - num_batches:390
2024-07-25 10:59:24,105 - INFO - epoch complete!
2024-07-25 10:59:24,105 - INFO - evaluating now!
2024-07-25 10:59:33,155 - INFO - Epoch [0/100] train_loss: 21.8610, val_loss: 12.8843, lr: 0.010000, 221.50s
2024-07-25 10:59:33,178 - INFO - Saved model at 0
2024-07-25 10:59:33,178 - INFO - Val loss decrease from inf to 12.8843, saving to ./libcity/cache/00011/model_cache/HierAttnLstm_PEMSD8_epoch0.tar
2024-07-25 11:03:07,342 - INFO - epoch complete!
2024-07-25 11:03:07,342 - INFO - evaluating now!
2024-07-25 11:03:16,497 - INFO - Epoch [1/100] train_loss: 11.0501, val_loss: 11.8731, lr: 0.010000, 223.32s
2024-07-25 11:03:16,522 - INFO - Saved model at 1
2024-07-25 11:03:16,522 - INFO - Val loss decrease from 12.8843 to 11.8731, saving to ./libcity/cache/00011/model_cache/HierAttnLstm_PEMSD8_epoch1.tar
2024-07-25 11:06:49,204 - INFO - epoch complete!
2024-07-25 11:06:49,205 - INFO - evaluating now!
2024-07-25 11:06:58,367 - INFO - Epoch [2/100] train_loss: 10.0097, val_loss: 11.8965, lr: 0.010000, 221.84s
2024-07-25 11:10:30,917 - INFO - epoch complete!
2024-07-25 11:10:30,917 - INFO - evaluating now!
2024-07-25 11:10:40,106 - INFO - Epoch [3/100] train_loss: 9.6115, val_loss: 11.3273, lr: 0.010000, 221.74s
2024-07-25 11:10:40,130 - INFO - Saved model at 3
2024-07-25 11:10:40,130 - INFO - Val loss decrease from 11.8731 to 11.3273, saving to ./libcity/cache/00011/model_cache/HierAttnLstm_PEMSD8_epoch3.tar
2024-07-25 11:14:13,483 - INFO - epoch complete!
2024-07-25 11:14:13,483 - INFO - evaluating now!
2024-07-25 11:14:22,737 - INFO - Epoch [4/100] train_loss: 9.4180, val_loss: 11.2037, lr: 0.010000, 222.61s
2024-07-25 11:14:22,761 - INFO - Saved model at 4
2024-07-25 11:14:22,762 - INFO - Val loss decrease from 11.3273 to 11.2037, saving to ./libcity/cache/00011/model_cache/HierAttnLstm_PEMSD8_epoch4.tar
2024-07-25 11:17:56,516 - INFO - epoch complete!
2024-07-25 11:17:56,517 - INFO - evaluating now!
2024-07-25 11:18:05,721 - INFO - Epoch [5/100] train_loss: 9.3606, val_loss: 11.0799, lr: 0.010000, 222.96s
2024-07-25 11:18:05,743 - INFO - Saved model at 5
2024-07-25 11:18:05,743 - INFO - Val loss decrease from 11.2037 to 11.0799, saving to ./libcity/cache/00011/model_cache/HierAttnLstm_PEMSD8_epoch5.tar
2024-07-25 11:21:38,501 - INFO - epoch complete!
2024-07-25 11:21:38,501 - INFO - evaluating now!
2024-07-25 11:21:47,502 - INFO - Epoch [6/100] train_loss: 9.0387, val_loss: 10.9093, lr: 0.010000, 221.76s
2024-07-25 11:21:47,525 - INFO - Saved model at 6
2024-07-25 11:21:47,525 - INFO - Val loss decrease from 11.0799 to 10.9093, saving to ./libcity/cache/00011/model_cache/HierAttnLstm_PEMSD8_epoch6.tar
2024-07-25 11:25:22,331 - INFO - epoch complete!
2024-07-25 11:25:22,331 - INFO - evaluating now!
2024-07-25 11:25:31,531 - INFO - Epoch [7/100] train_loss: 9.0160, val_loss: 11.4973, lr: 0.010000, 224.01s
2024-07-25 11:29:03,886 - INFO - epoch complete!
2024-07-25 11:29:03,886 - INFO - evaluating now!
2024-07-25 11:29:12,858 - INFO - Epoch [8/100] train_loss: 9.0483, val_loss: 10.6088, lr: 0.010000, 221.33s
2024-07-25 11:29:12,881 - INFO - Saved model at 8
2024-07-25 11:29:12,881 - INFO - Val loss decrease from 10.9093 to 10.6088, saving to ./libcity/cache/00011/model_cache/HierAttnLstm_PEMSD8_epoch8.tar
2024-07-25 11:32:47,142 - INFO - epoch complete!
2024-07-25 11:32:47,142 - INFO - evaluating now!
2024-07-25 11:32:56,210 - INFO - Epoch [9/100] train_loss: 8.9094, val_loss: 10.6538, lr: 0.010000, 223.33s
2024-07-25 11:36:28,897 - INFO - epoch complete!
2024-07-25 11:36:28,897 - INFO - evaluating now!
2024-07-25 11:36:38,054 - INFO - Epoch [10/100] train_loss: 8.8560, val_loss: 10.4721, lr: 0.010000, 221.84s
2024-07-25 11:36:38,077 - INFO - Saved model at 10
2024-07-25 11:36:38,077 - INFO - Val loss decrease from 10.6088 to 10.4721, saving to ./libcity/cache/00011/model_cache/HierAttnLstm_PEMSD8_epoch10.tar
2024-07-25 11:40:11,945 - INFO - epoch complete!
2024-07-25 11:40:11,945 - INFO - evaluating now!
2024-07-25 11:40:21,044 - INFO - Epoch [11/100] train_loss: 8.8325, val_loss: 10.5869, lr: 0.010000, 222.97s
2024-07-25 11:43:53,467 - INFO - epoch complete!
2024-07-25 11:43:53,467 - INFO - evaluating now!
2024-07-25 11:44:02,508 - INFO - Epoch [12/100] train_loss: 8.8007, val_loss: 10.6257, lr: 0.010000, 221.46s
2024-07-25 11:47:34,578 - INFO - epoch complete!
2024-07-25 11:47:34,578 - INFO - evaluating now!
2024-07-25 11:47:43,653 - INFO - Epoch [13/100] train_loss: 8.7854, val_loss: 10.3183, lr: 0.010000, 221.14s
2024-07-25 11:47:43,677 - INFO - Saved model at 13
2024-07-25 11:47:43,677 - INFO - Val loss decrease from 10.4721 to 10.3183, saving to ./libcity/cache/00011/model_cache/HierAttnLstm_PEMSD8_epoch13.tar
2024-07-25 11:51:15,490 - INFO - epoch complete!
2024-07-25 11:51:15,491 - INFO - evaluating now!
2024-07-25 11:51:24,596 - INFO - Epoch [14/100] train_loss: 8.7743, val_loss: 10.5893, lr: 0.010000, 220.92s
2024-07-25 11:54:56,901 - INFO - epoch complete!
2024-07-25 11:54:56,901 - INFO - evaluating now!
2024-07-25 11:55:05,907 - INFO - Epoch [15/100] train_loss: 8.6851, val_loss: 10.3282, lr: 0.010000, 221.31s
2024-07-25 11:58:37,989 - INFO - epoch complete!
2024-07-25 11:58:37,989 - INFO - evaluating now!
2024-07-25 11:58:47,043 - INFO - Epoch [16/100] train_loss: 8.7386, val_loss: 10.5910, lr: 0.010000, 221.14s
2024-07-25 12:02:22,100 - INFO - epoch complete!
2024-07-25 12:02:22,100 - INFO - evaluating now!
2024-07-25 12:02:31,212 - INFO - Epoch [17/100] train_loss: 8.6974, val_loss: 10.1880, lr: 0.010000, 224.17s
2024-07-25 12:02:31,236 - INFO - Saved model at 17
2024-07-25 12:02:31,236 - INFO - Val loss decrease from 10.3183 to 10.1880, saving to ./libcity/cache/00011/model_cache/HierAttnLstm_PEMSD8_epoch17.tar
2024-07-25 12:06:03,028 - INFO - epoch complete!
2024-07-25 12:06:03,029 - INFO - evaluating now!
2024-07-25 12:06:12,168 - INFO - Epoch [18/100] train_loss: 8.7334, val_loss: 10.4648, lr: 0.010000, 220.93s
2024-07-25 12:09:43,206 - INFO - epoch complete!
2024-07-25 12:09:43,207 - INFO - evaluating now!
2024-07-25 12:09:52,451 - INFO - Epoch [19/100] train_loss: 8.5532, val_loss: 10.5506, lr: 0.010000, 220.28s
2024-07-25 12:13:24,219 - INFO - epoch complete!
2024-07-25 12:13:24,219 - INFO - evaluating now!
2024-07-25 12:13:33,635 - INFO - Epoch [20/100] train_loss: 8.6544, val_loss: 10.8836, lr: 0.010000, 221.18s
2024-07-25 12:17:06,768 - INFO - epoch complete!
2024-07-25 12:17:06,768 - INFO - evaluating now!
2024-07-25 12:17:16,041 - INFO - Epoch [21/100] train_loss: 8.6457, val_loss: 10.4567, lr: 0.010000, 222.41s
2024-07-25 12:20:50,109 - INFO - epoch complete!
2024-07-25 12:20:50,110 - INFO - evaluating now!
2024-07-25 12:20:59,400 - INFO - Epoch [22/100] train_loss: 8.6483, val_loss: 10.2735, lr: 0.010000, 223.36s
2024-07-25 12:20:59,400 - WARNING - Early stopping at epoch: 22
2024-07-25 12:20:59,401 - INFO - Trained totally 23 epochs, average train time is 212.923s, average eval time is 9.142s
2024-07-25 12:20:59,416 - INFO - Loaded model at 17
2024-07-25 12:20:59,417 - INFO - Saved model at ./libcity/cache/00011/model_cache/HierAttnLstm_PEMSD8.m
2024-07-25 12:20:59,439 - INFO - Start evaluating ...
2024-07-25 12:21:21,217 - INFO - Note that you select the single mode to evaluate!
2024-07-25 12:21:21,220 - INFO - Evaluate result is saved at ./libcity/cache/00011/evaluate_cache\2024_07_25_12_21_21_HierAttnLstm_PEMSD8.csv
2024-07-25 12:21:21,230 - INFO - 
         MAE         MAPE         MSE  ...  masked_RMSE        R2      EVAR
1   9.235795  1334343.750  500.869263  ...    22.355217  0.969985  0.970047
2   9.233959  1334642.000  500.626923  ...    22.349785  0.969986  0.970049
3   9.232053  1334668.750  500.373840  ...    22.344109  0.969988  0.970051
4   9.230100  1334668.750  500.111084  ...    22.338215  0.969991  0.970053
5   9.227873  1334787.625  499.814667  ...    22.331577  0.969995  0.970057
6   9.225478  1335086.375  499.514557  ...    22.324854  0.969999  0.970062
7   9.223145  1335174.500  499.222076  ...    22.318287  0.970004  0.970066
8   9.220728  1335231.500  498.929626  ...    22.311720  0.970008  0.970070
9   9.232571  1334386.875  499.705688  ...    22.329201  0.969948  0.970014
10  9.253860  1333388.750  501.144592  ...    22.361557  0.969849  0.969917
11  9.283810  1331937.125  503.226685  ...    22.408245  0.969710  0.969781
12  9.322719  1330433.500  505.978302  ...    22.469847  0.969531  0.969606

[12 rows x 10 columns]

Standard Error:
