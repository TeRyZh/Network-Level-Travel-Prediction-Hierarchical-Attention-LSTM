Command:
python run_model.py --task traffic_state_pred --model HierAttnLstm --dataset PEMS_BAY --config_file HierAttnLstm_OW_12 --exp_id 00003

Standard Output:
2024-07-25 02:40:53,824 - INFO - Log directory: ./libcity/log
2024-07-25 02:40:53,825 - INFO - Begin pipeline, task=traffic_state_pred, model_name=HierAttnLstm, dataset_name=PEMS_BAY, exp_id=00003
2024-07-25 02:40:53,825 - INFO - {'task': 'traffic_state_pred', 'model': 'HierAttnLstm', 'dataset': 'PEMS_BAY', 'saved_model': True, 'train': True, 'exp_id': '00003', 'seed': 0, 'input_window': 48, 'output_window': 12, 'device': device(type='cuda', index=0), 'hidden_size': 128, 'num_layers': 3, 'dropout': 0.1, 'natt_hops': 3, 'nfc': 512, 'max_up_len': 96, 'dataset_class': 'TrafficStatePointDataset', 'executor': 'TrafficStateExecutor', 'evaluator': 'TrafficStateEvaluator', 'batch_size': 32, 'cache_dataset': True, 'num_workers': 0, 'pad_with_last_sample': True, 'train_rate': 0.7, 'eval_rate': 0.1, 'scaler': 'minmax01', 'load_external': False, 'normal_external': False, 'ext_scaler': 'none', 'add_time_in_day': False, 'add_day_in_week': False, 'robustness_test': False, 'noise_type': 'gaussian', 'disturb_rate': 0.5, 'noise_mean': [5], 'noise_SD': [10], 'gpu': True, 'gpu_id': 0, 'max_epoch': 100, 'train_loss': 'none', 'epoch': 0, 'learner': 'adam', 'learning_rate': 0.01, 'weight_decay': 0, 'lr_epsilon': 1e-08, 'lr_beta1': 0.9, 'lr_beta2': 0.999, 'lr_alpha': 0.99, 'lr_momentum': 0, 'lr_decay': False, 'lr_scheduler': 'multisteplr', 'lr_decay_ratio': 0.1, 'steps': [5, 20, 40, 70], 'step_size': 10, 'lr_T_max': 30, 'lr_eta_min': 0, 'lr_patience': 10, 'lr_threshold': 0.0001, 'clip_grad_norm': False, 'max_grad_norm': 1.0, 'use_early_stop': True, 'patience': 5, 'log_level': 'INFO', 'log_every': 1, 'load_best_epoch': True, 'hyper_tune': False, 'metrics': ['MAE', 'MAPE', 'MSE', 'RMSE', 'masked_MAE', 'masked_MAPE', 'masked_MSE', 'masked_RMSE', 'R2', 'EVAR'], 'evaluator_mode': 'single', 'save_mode': ['csv'], 'geo': {'including_types': ['Point'], 'Point': {}}, 'rel': {'including_types': ['geo'], 'geo': {'cost': 'num'}}, 'dyna': {'including_types': ['state'], 'state': {'entity_id': 'geo_id', 'traffic_speed': 'num'}}, 'data_col': ['traffic_speed'], 'weight_col': 'cost', 'data_files': ['PEMS_BAY'], 'geo_file': 'PEMS_BAY', 'rel_file': 'PEMS_BAY', 'output_dim': 1, 'time_intervals': 300, 'init_weight_inf_or_zero': 'inf', 'set_weight_link_or_dist': 'dist', 'calculate_weight_adj': True, 'weight_adj_epsilon': 0.1}
self.scaler_type  minmax01
2024-07-25 02:40:53,844 - INFO - Loaded file PEMS_BAY.geo, num_nodes=325
2024-07-25 02:40:53,860 - INFO - set_weight_link_or_dist: dist
2024-07-25 02:40:53,860 - INFO - init_weight_inf_or_zero: inf
2024-07-25 02:40:53,869 - INFO - Loaded file PEMS_BAY.rel, shape=(325, 325)
2024-07-25 02:40:53,869 - INFO - Start Calculate the weight by Gauss kernel!
2024-07-25 02:40:53,870 - INFO - Loading file PEMS_BAY.dyna
2024-07-25 02:41:01,923 - INFO - Loaded file PEMS_BAY.dyna, shape=(52116, 325, 1)
2024-07-25 02:41:58,370 - INFO - Dataset created
2024-07-25 02:41:58,370 - INFO - x shape: (52057, 48, 325, 1), y shape: (52057, 12, 325, 1)
2024-07-25 02:41:58,631 - INFO - train	x: (36440, 48, 325, 1), y: (36440, 12, 325, 1)
2024-07-25 02:41:58,631 - INFO - eval	x: (5206, 48, 325, 1), y: (5206, 12, 325, 1)
2024-07-25 02:41:58,631 - INFO - test	x: (10411, 48, 325, 1), y: (10411, 12, 325, 1)
2024-07-25 02:47:40,450 - INFO - Saved at ./libcity/cache/dataset_cache/point_based_PEMS_BAY_48_12_0.7_0.1_minmax01_32_False_False_False_True.npz
2024-07-25 02:47:41,097 - INFO - MinMax01Scaler max: 85.1, min: 0.0
2024-07-25 02:47:41,097 - INFO - NoneScaler
2024-07-25 02:47:46,886 - INFO - HierAttnLstm(
  (lstm_cells): ModuleList(
    (0): LSTMCell(325, 128)
    (1-2): 2 x LSTMCell(128, 128)
  )
  (hidden_state_pooling): ModuleList(
    (0-1): 2 x SelfAttentionPooling(
      (W): Linear(in_features=128, out_features=1, bias=True)
    )
  )
  (cell_state_pooling): ModuleList(
    (0-1): 2 x SelfAttentionPooling(
      (W): Linear(in_features=128, out_features=1, bias=True)
    )
  )
  (self_attention): SelfAttention(
    (ut_dense): Sequential(
      (0): Linear(in_features=128, out_features=128, bias=True)
      (1): Tanh()
    )
    (et_dense): Linear(in_features=128, out_features=3, bias=True)
    (softmax): Softmax(dim=-1)
  )
  (fc_layer): Sequential(
    (0): Linear(in_features=384, out_features=512, bias=True)
    (1): ReLU()
    (2): Linear(in_features=512, out_features=325, bias=True)
  )
)
2024-07-25 02:47:46,887 - INFO - lstm_cells.0.weight_ih	torch.Size([512, 325])	cuda:0	True
2024-07-25 02:47:46,887 - INFO - lstm_cells.0.weight_hh	torch.Size([512, 128])	cuda:0	True
2024-07-25 02:47:46,887 - INFO - lstm_cells.0.bias_ih	torch.Size([512])	cuda:0	True
2024-07-25 02:47:46,887 - INFO - lstm_cells.0.bias_hh	torch.Size([512])	cuda:0	True
2024-07-25 02:47:46,887 - INFO - lstm_cells.1.weight_ih	torch.Size([512, 128])	cuda:0	True
2024-07-25 02:47:46,887 - INFO - lstm_cells.1.weight_hh	torch.Size([512, 128])	cuda:0	True
2024-07-25 02:47:46,887 - INFO - lstm_cells.1.bias_ih	torch.Size([512])	cuda:0	True
2024-07-25 02:47:46,887 - INFO - lstm_cells.1.bias_hh	torch.Size([512])	cuda:0	True
2024-07-25 02:47:46,887 - INFO - lstm_cells.2.weight_ih	torch.Size([512, 128])	cuda:0	True
2024-07-25 02:47:46,887 - INFO - lstm_cells.2.weight_hh	torch.Size([512, 128])	cuda:0	True
2024-07-25 02:47:46,887 - INFO - lstm_cells.2.bias_ih	torch.Size([512])	cuda:0	True
2024-07-25 02:47:46,887 - INFO - lstm_cells.2.bias_hh	torch.Size([512])	cuda:0	True
2024-07-25 02:47:46,888 - INFO - hidden_state_pooling.0.W.weight	torch.Size([1, 128])	cuda:0	True
2024-07-25 02:47:46,888 - INFO - hidden_state_pooling.0.W.bias	torch.Size([1])	cuda:0	True
2024-07-25 02:47:46,888 - INFO - hidden_state_pooling.1.W.weight	torch.Size([1, 128])	cuda:0	True
2024-07-25 02:47:46,888 - INFO - hidden_state_pooling.1.W.bias	torch.Size([1])	cuda:0	True
2024-07-25 02:47:46,888 - INFO - cell_state_pooling.0.W.weight	torch.Size([1, 128])	cuda:0	True
2024-07-25 02:47:46,888 - INFO - cell_state_pooling.0.W.bias	torch.Size([1])	cuda:0	True
2024-07-25 02:47:46,888 - INFO - cell_state_pooling.1.W.weight	torch.Size([1, 128])	cuda:0	True
2024-07-25 02:47:46,888 - INFO - cell_state_pooling.1.W.bias	torch.Size([1])	cuda:0	True
2024-07-25 02:47:46,888 - INFO - self_attention.ut_dense.0.weight	torch.Size([128, 128])	cuda:0	True
2024-07-25 02:47:46,888 - INFO - self_attention.ut_dense.0.bias	torch.Size([128])	cuda:0	True
2024-07-25 02:47:46,888 - INFO - self_attention.et_dense.weight	torch.Size([3, 128])	cuda:0	True
2024-07-25 02:47:46,888 - INFO - self_attention.et_dense.bias	torch.Size([3])	cuda:0	True
2024-07-25 02:47:46,888 - INFO - fc_layer.0.weight	torch.Size([512, 384])	cuda:0	True
2024-07-25 02:47:46,888 - INFO - fc_layer.0.bias	torch.Size([512])	cuda:0	True
2024-07-25 02:47:46,888 - INFO - fc_layer.2.weight	torch.Size([325, 512])	cuda:0	True
2024-07-25 02:47:46,888 - INFO - fc_layer.2.bias	torch.Size([325])	cuda:0	True
2024-07-25 02:47:46,889 - INFO - Total parameter numbers: 878412
2024-07-25 02:47:46,889 - INFO - You select `adam` optimizer.
2024-07-25 02:47:46,889 - WARNING - Received none train loss func and will use the loss func defined in the model.
2024-07-25 02:47:46,889 - INFO - Start training ...
2024-07-25 02:47:46,889 - INFO - num_batches:1139
2024-07-25 02:58:01,808 - INFO - epoch complete!
2024-07-25 02:58:01,808 - INFO - evaluating now!
2024-07-25 02:58:27,592 - INFO - Epoch [0/100] train_loss: 5.5652, val_loss: 4.5584, lr: 0.010000, 640.70s
2024-07-25 02:58:27,615 - INFO - Saved model at 0
2024-07-25 02:58:27,616 - INFO - Val loss decrease from inf to 4.5584, saving to ./libcity/cache/00003/model_cache/HierAttnLstm_PEMS_BAY_epoch0.tar
2024-07-25 03:08:40,811 - INFO - epoch complete!
2024-07-25 03:08:40,811 - INFO - evaluating now!
2024-07-25 03:09:06,977 - INFO - Epoch [1/100] train_loss: 3.4085, val_loss: 3.1503, lr: 0.010000, 639.36s
2024-07-25 03:09:06,998 - INFO - Saved model at 1
2024-07-25 03:09:06,998 - INFO - Val loss decrease from 4.5584 to 3.1503, saving to ./libcity/cache/00003/model_cache/HierAttnLstm_PEMS_BAY_epoch1.tar
2024-07-25 03:19:19,172 - INFO - epoch complete!
2024-07-25 03:19:19,172 - INFO - evaluating now!
2024-07-25 03:19:45,271 - INFO - Epoch [2/100] train_loss: 2.8923, val_loss: 2.8634, lr: 0.010000, 638.27s
2024-07-25 03:19:45,294 - INFO - Saved model at 2
2024-07-25 03:19:45,294 - INFO - Val loss decrease from 3.1503 to 2.8634, saving to ./libcity/cache/00003/model_cache/HierAttnLstm_PEMS_BAY_epoch2.tar
2024-07-25 03:29:57,578 - INFO - epoch complete!
2024-07-25 03:29:57,578 - INFO - evaluating now!
2024-07-25 03:30:24,060 - INFO - Epoch [3/100] train_loss: 2.6321, val_loss: 2.8246, lr: 0.010000, 638.77s
2024-07-25 03:30:24,091 - INFO - Saved model at 3
2024-07-25 03:30:24,091 - INFO - Val loss decrease from 2.8634 to 2.8246, saving to ./libcity/cache/00003/model_cache/HierAttnLstm_PEMS_BAY_epoch3.tar
2024-07-25 03:40:34,157 - INFO - epoch complete!
2024-07-25 03:40:34,157 - INFO - evaluating now!
2024-07-25 03:41:00,206 - INFO - Epoch [4/100] train_loss: 2.5432, val_loss: 3.1381, lr: 0.010000, 636.11s
2024-07-25 03:51:13,240 - INFO - epoch complete!
2024-07-25 03:51:13,240 - INFO - evaluating now!
2024-07-25 03:51:39,469 - INFO - Epoch [5/100] train_loss: 2.4867, val_loss: 2.6248, lr: 0.010000, 639.26s
2024-07-25 03:51:39,490 - INFO - Saved model at 5
2024-07-25 03:51:39,490 - INFO - Val loss decrease from 2.8246 to 2.6248, saving to ./libcity/cache/00003/model_cache/HierAttnLstm_PEMS_BAY_epoch5.tar
2024-07-25 04:01:51,407 - INFO - epoch complete!
2024-07-25 04:01:51,408 - INFO - evaluating now!
2024-07-25 04:02:17,682 - INFO - Epoch [6/100] train_loss: 2.4500, val_loss: 2.6224, lr: 0.010000, 638.19s
2024-07-25 04:02:17,702 - INFO - Saved model at 6
2024-07-25 04:02:17,702 - INFO - Val loss decrease from 2.6248 to 2.6224, saving to ./libcity/cache/00003/model_cache/HierAttnLstm_PEMS_BAY_epoch6.tar
2024-07-25 04:12:32,355 - INFO - epoch complete!
2024-07-25 04:12:32,355 - INFO - evaluating now!
2024-07-25 04:12:58,338 - INFO - Epoch [7/100] train_loss: 2.4288, val_loss: 2.7332, lr: 0.010000, 640.63s
2024-07-25 04:23:13,326 - INFO - epoch complete!
2024-07-25 04:23:13,326 - INFO - evaluating now!
2024-07-25 04:23:39,573 - INFO - Epoch [8/100] train_loss: 2.4162, val_loss: 2.6113, lr: 0.010000, 641.23s
2024-07-25 04:23:39,593 - INFO - Saved model at 8
2024-07-25 04:23:39,594 - INFO - Val loss decrease from 2.6224 to 2.6113, saving to ./libcity/cache/00003/model_cache/HierAttnLstm_PEMS_BAY_epoch8.tar
2024-07-25 04:33:54,671 - INFO - epoch complete!
2024-07-25 04:33:54,672 - INFO - evaluating now!
2024-07-25 04:34:20,339 - INFO - Epoch [9/100] train_loss: 2.4084, val_loss: 2.5909, lr: 0.010000, 640.75s
2024-07-25 04:34:20,376 - INFO - Saved model at 9
2024-07-25 04:34:20,376 - INFO - Val loss decrease from 2.6113 to 2.5909, saving to ./libcity/cache/00003/model_cache/HierAttnLstm_PEMS_BAY_epoch9.tar
2024-07-25 04:44:31,701 - INFO - epoch complete!
2024-07-25 04:44:31,701 - INFO - evaluating now!
2024-07-25 04:44:57,718 - INFO - Epoch [10/100] train_loss: 2.3748, val_loss: 2.5772, lr: 0.010000, 637.34s
2024-07-25 04:44:57,738 - INFO - Saved model at 10
2024-07-25 04:44:57,739 - INFO - Val loss decrease from 2.5909 to 2.5772, saving to ./libcity/cache/00003/model_cache/HierAttnLstm_PEMS_BAY_epoch10.tar
2024-07-25 04:55:12,309 - INFO - epoch complete!
2024-07-25 04:55:12,309 - INFO - evaluating now!
2024-07-25 04:55:38,274 - INFO - Epoch [11/100] train_loss: 2.3700, val_loss: 2.5641, lr: 0.010000, 640.53s
2024-07-25 04:55:38,295 - INFO - Saved model at 11
2024-07-25 04:55:38,295 - INFO - Val loss decrease from 2.5772 to 2.5641, saving to ./libcity/cache/00003/model_cache/HierAttnLstm_PEMS_BAY_epoch11.tar
2024-07-25 05:05:48,756 - INFO - epoch complete!
2024-07-25 05:05:48,756 - INFO - evaluating now!
2024-07-25 05:06:14,670 - INFO - Epoch [12/100] train_loss: 2.3717, val_loss: 2.5943, lr: 0.010000, 636.38s
2024-07-25 05:16:27,541 - INFO - epoch complete!
2024-07-25 05:16:27,541 - INFO - evaluating now!
2024-07-25 05:16:53,854 - INFO - Epoch [13/100] train_loss: 2.3634, val_loss: 2.5881, lr: 0.010000, 639.18s
2024-07-25 05:27:05,930 - INFO - epoch complete!
2024-07-25 05:27:05,931 - INFO - evaluating now!
2024-07-25 05:27:32,183 - INFO - Epoch [14/100] train_loss: 2.3475, val_loss: 2.5997, lr: 0.010000, 638.33s
2024-07-25 05:37:44,856 - INFO - epoch complete!
2024-07-25 05:37:44,856 - INFO - evaluating now!
2024-07-25 05:38:10,934 - INFO - Epoch [15/100] train_loss: 2.3489, val_loss: 2.6852, lr: 0.010000, 638.75s
2024-07-25 05:48:25,192 - INFO - epoch complete!
2024-07-25 05:48:25,193 - INFO - evaluating now!
2024-07-25 05:48:51,858 - INFO - Epoch [16/100] train_loss: 2.5551, val_loss: 5.1527, lr: 0.010000, 640.92s
2024-07-25 05:48:51,858 - WARNING - Early stopping at epoch: 16
2024-07-25 05:48:51,858 - INFO - Trained totally 17 epochs, average train time is 612.972s, average eval time is 26.128s
2024-07-25 05:48:51,873 - INFO - Loaded model at 11
2024-07-25 05:48:51,874 - INFO - Saved model at ./libcity/cache/00003/model_cache/HierAttnLstm_PEMS_BAY.m
2024-07-25 05:48:51,893 - INFO - Start evaluating ...
2024-07-25 05:49:53,129 - INFO - Note that you select the single mode to evaluate!
2024-07-25 05:49:53,132 - INFO - Evaluate result is saved at ./libcity/cache/00003/evaluate_cache\2024_07_25_05_49_53_HierAttnLstm_PEMS_BAY.csv
2024-07-25 05:49:53,143 - INFO - 
         MAE          MAPE        MSE  ...  masked_RMSE        R2      EVAR
1   2.587921  426946.28125  28.539703  ...     5.315729  0.694144  0.697922
2   2.587666  426946.25000  28.533432  ...     5.315139  0.694180  0.697955
3   2.587462  426946.34375  28.528950  ...     5.314718  0.694206  0.697979
4   2.587318  426946.25000  28.526318  ...     5.314470  0.694221  0.697992
5   2.587209  426946.34375  28.524670  ...     5.314315  0.694230  0.697999
6   2.587118  426946.34375  28.523615  ...     5.314216  0.694236  0.698004
7   2.587059  426946.34375  28.522840  ...     5.314143  0.694241  0.698007
8   2.587017  426946.28125  28.522188  ...     5.314082  0.694245  0.698011
9   2.616125  426869.43750  29.013988  ...     5.360168  0.688970  0.692327
10  2.628803  426795.28125  29.298647  ...     5.386666  0.685915  0.689416
11  2.649144  426697.71875  29.731308  ...     5.426692  0.681274  0.684835
12  2.673283  426583.87500  30.249098  ...     5.474209  0.675722  0.679616

[12 rows x 10 columns]

Standard Error:
